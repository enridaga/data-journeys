digraph "" {
	numpy -> "python-nltk-sentiment-analysis.ipynb"	[label=importedBy];
	"np(0)" -> numpy	[label=assignedFrom];
	"np(0)" -> "python-nltk-sentiment-analysis.ipynb"	[label=appearsIn];
	pandas -> "python-nltk-sentiment-analysis.ipynb"	[label=importedBy];
	"pd(0)" -> "python-nltk-sentiment-analysis.ipynb"	[label=appearsIn];
	"pd(0)" -> pandas	[label=assignedFrom];
	"sklearn.model_selection" -> "python-nltk-sentiment-analysis.ipynb"	[label=importedBy];
	train_test_split -> "sklearn.model_selection"	[label=importedBy];
	"train_test_split(0)" -> "python-nltk-sentiment-analysis.ipynb"	[label=appearsIn];
	"train_test_split(0)" -> train_test_split	[label=assignedFrom];
	nltk -> "python-nltk-sentiment-analysis.ipynb"	[label=importedBy];
	"nltk(0)" -> "python-nltk-sentiment-analysis.ipynb"	[label=appearsIn];
	"nltk(0)" -> nltk	[label=assignedFrom];
	"nltk.corpus" -> "python-nltk-sentiment-analysis.ipynb"	[label=importedBy];
	stopwords -> "nltk.corpus"	[label=importedBy];
	"stopwords(0)" -> "python-nltk-sentiment-analysis.ipynb"	[label=appearsIn];
	"stopwords(0)" -> stopwords	[label=assignedFrom];
	"nltk.classify" -> "python-nltk-sentiment-analysis.ipynb"	[label=importedBy];
	SklearnClassifier -> "nltk.classify"	[label=importedBy];
	"SklearnClassifier(0)" -> "python-nltk-sentiment-analysis.ipynb"	[label=appearsIn];
	"SklearnClassifier(0)" -> SklearnClassifier	[label=assignedFrom];
	wordcloud -> "python-nltk-sentiment-analysis.ipynb"	[label=importedBy];
	WordCloud -> wordcloud	[label=importedBy];
	"WordCloud(0)" -> "python-nltk-sentiment-analysis.ipynb"	[label=appearsIn];
	"WordCloud(0)" -> WordCloud	[label=assignedFrom];
	STOPWORDS -> wordcloud	[label=importedBy];
	"STOPWORDS(0)" -> "python-nltk-sentiment-analysis.ipynb"	[label=appearsIn];
	"STOPWORDS(0)" -> STOPWORDS	[label=assignedFrom];
	"matplotlib.pyplot" -> "python-nltk-sentiment-analysis.ipynb"	[label=importedBy];
	"plt(0)" -> "python-nltk-sentiment-analysis.ipynb"	[label=appearsIn];
	"plt(0)" -> "matplotlib.pyplot"	[label=assignedFrom];
	subprocess -> "python-nltk-sentiment-analysis.ipynb"	[label=importedBy];
	check_output -> subprocess	[label=importedBy];
	"check_output(0)" -> "python-nltk-sentiment-analysis.ipynb"	[label=appearsIn];
	"check_output(0)" -> check_output	[label=assignedFrom];
	"data(0)$0" -> "pd(0)"	[label=read_csv];
	"data(0)$0" -> "../input/Sentiment.csv(0)"	[label=read_csv];
	"../input/Sentiment.csv(0)" -> "python-nltk-sentiment-analysis.ipynb"	[label=appearsIn];
	"data(0)$1" -> "data(0)$0"	[label=assignedFrom];
	"data(0)$1" -> "[<_ast.Constant object at 0x7fd4c048ee20>, <_ast.Constant object at 0x7fd4c048e760>](0)"	[label=assignedFrom];
	"[<_ast.Constant object at 0x7fd4c048ee20>, <_ast.Constant object at 0x7fd4c048e760>](0)" -> "python-nltk-sentiment-analysis.ipynb"	[label=appearsIn];
	"train(0)$0" -> "data(0)$1"	[label=train_test_split];
	"train(0)$0" -> "0.1(0)"	[label=train_test_split];
	"0.1(0)" -> "python-nltk-sentiment-analysis.ipynb"	[label=appearsIn];
	"test(0)$0" -> "data(0)$1"	[label=train_test_split];
	"test(0)$0" -> "0.1(0)"	[label=train_test_split];
	"train(0)$1" -> "train(0)$0"	[label=assignedFrom];
	"train(0)$1" -> "train(0)$1"	[label=assignedFrom];
	"train(0)$1" -> "Neutral(0)"	[label=assignedFrom];
	"Neutral(0)" -> "python-nltk-sentiment-analysis.ipynb"	[label=appearsIn];
	"train_pos(0)$0" -> "train(0)$1"	[label=assignedFrom];
	"train_pos(0)$0" -> "sentiment(0)"	[label=assignedFrom];
	"train_pos(0)$0" -> "Positive(0)"	[label=assignedFrom];
	"sentiment(0)" -> "python-nltk-sentiment-analysis.ipynb"	[label=appearsIn];
	"Positive(0)" -> "python-nltk-sentiment-analysis.ipynb"	[label=appearsIn];
	"train_pos(0)$1" -> "train_pos(0)$0"	[label=assignedFrom];
	"train_pos(0)$1" -> "text(0)"	[label=assignedFrom];
	"text(0)" -> "python-nltk-sentiment-analysis.ipynb"	[label=appearsIn];
	"train_neg(0)$0" -> "train(0)$1"	[label=assignedFrom];
	"train_neg(0)$0" -> "sentiment(0)"	[label=assignedFrom];
	"train_neg(0)$0" -> "Negative(0)"	[label=assignedFrom];
	"Negative(0)" -> "python-nltk-sentiment-analysis.ipynb"	[label=appearsIn];
	"train_neg(0)$1" -> "text(0)"	[label=assignedFrom];
	"train_neg(0)$1" -> "train_neg(0)$0"	[label=assignedFrom];
	"data(1)" -> "wordcloud_draw[0]"	[label=_argToVar];
	"color(1)" -> "wordcloud_draw[1]"	[label=_argToVar];
	"words(1)$0" -> "data(1)"	[label=join];
	"words(1)$0" -> " (1)"	[label=join];
	"cleaned_word(1)$0" -> "words(1)$0"	[label=join];
	"cleaned_word(1)$0" -> " (1)"	[label=join];
	"cleaned_word(1)$0" -> "word(1)"	[label=join];
	"cleaned_word(1)$0" -> "http(1)"	[label=join];
	"cleaned_word(1)$0" -> "@(1)"	[label=join];
	"cleaned_word(1)$0" -> "#(1)"	[label=join];
	"cleaned_word(1)$0" -> "RT(1)"	[label=join];
	"wordcloud(1)$0" -> "color(1)"	[label=generate];
	"wordcloud(1)$0" -> "cleaned_word(1)$0"	[label=generate];
	"wordcloud(1)$0" -> "WordCloud(1)"	[label=generate];
	"wordcloud(1)$0" -> "STOPWORDS(1)"	[label=generate];
	"wordcloud(1)$0" -> "2500(1)"	[label=generate];
	"wordcloud(1)$0" -> "2000(1)"	[label=generate];
	"plt(1)$0" -> "plt(1)"	[label=figure];
	"plt(1)$0" -> "1(1)"	[label=figure];
	"plt(1)$1" -> "wordcloud(1)$0"	[label=imshow];
	"plt(1)$1" -> "plt(1)$0"	[label=imshow];
	"plt(1)$2" -> "plt(1)$1"	[label=axis];
	"plt(1)$2" -> "off(1)"	[label=axis];
	"plt(1)$3" -> "plt(1)$2"	[label=show];
	"Positive words(0)" -> "python-nltk-sentiment-analysis.ipynb"	[label=appearsIn];
	"print[52/0]" -> "Positive words(0)"	[label=print];
	"wordcloud_draw[53/0]" -> "train_pos(0)$1"	[label=wordcloud_draw];
	"wordcloud_draw[53/0]" -> "white(0)"	[label=wordcloud_draw];
	"white(0)" -> "python-nltk-sentiment-analysis.ipynb"	[label=appearsIn];
	"Negative words(0)" -> "python-nltk-sentiment-analysis.ipynb"	[label=appearsIn];
	"print[54/0]" -> "Negative words(0)"	[label=print];
	"wordcloud_draw[55/0]" -> "train_neg(0)$1"	[label=wordcloud_draw];
	"[](0)" -> "python-nltk-sentiment-analysis.ipynb"	[label=appearsIn];
	"tweets(0)$0" -> "[](0)"	[label=assignedFrom];
	"stopwords_set(0)$0" -> "stopwords(0)"	[label=set];
	"stopwords_set(0)$0" -> "english(0)"	[label=set];
	"english(0)" -> "python-nltk-sentiment-analysis.ipynb"	[label=appearsIn];
	"index(0)" -> "python-nltk-sentiment-analysis.ipynb"	[label=appearsIn];
	"index(0)" -> "train(0)$1"	[label=iteratorOf];
	"row(0)" -> "python-nltk-sentiment-analysis.ipynb"	[label=appearsIn];
	"row(0)" -> "train(0)$1"	[label=iteratorOf];
	"e(0)" -> "python-nltk-sentiment-analysis.ipynb"	[label=appearsIn];
	"words_filtered(0)$0" -> "row(0)"	[label=assignedFrom];
	"words_filtered(0)$0" -> "e(0)"	[label=assignedFrom];
	"words_filtered(0)$0" -> "len(0)"	[label=assignedFrom];
	"words_filtered(0)$0" -> "3(0)"	[label=assignedFrom];
	"len(0)" -> "python-nltk-sentiment-analysis.ipynb"	[label=appearsIn];
	"3(0)" -> "python-nltk-sentiment-analysis.ipynb"	[label=appearsIn];
	"word(0)" -> "python-nltk-sentiment-analysis.ipynb"	[label=appearsIn];
	"words_cleaned(0)$0" -> "words_filtered(0)$0"	[label=assignedFrom];
	"words_cleaned(0)$0" -> "word(0)"	[label=assignedFrom];
	"words_cleaned(0)$0" -> "http(0)"	[label=assignedFrom];
	"words_cleaned(0)$0" -> "@(0)"	[label=assignedFrom];
	"words_cleaned(0)$0" -> "#(0)"	[label=assignedFrom];
	"words_cleaned(0)$0" -> "RT(0)"	[label=assignedFrom];
	"http(0)" -> "python-nltk-sentiment-analysis.ipynb"	[label=appearsIn];
	"@(0)" -> "python-nltk-sentiment-analysis.ipynb"	[label=appearsIn];
	"#(0)" -> "python-nltk-sentiment-analysis.ipynb"	[label=appearsIn];
	"RT(0)" -> "python-nltk-sentiment-analysis.ipynb"	[label=appearsIn];
	"words_without_stopwords(0)$0" -> "stopwords_set(0)$0"	[label=assignedFrom];
	"words_without_stopwords(0)$0" -> "word(0)"	[label=assignedFrom];
	"words_without_stopwords(0)$0" -> "words_cleaned(0)$0"	[label=assignedFrom];
	"tweets(0)$1" -> "tweets(0)$0"	[label=append];
	"tweets(0)$1" -> "row(0)"	[label=append];
	"tweets(0)$1" -> "words_without_stopwords(0)$0"	[label=append];
	"test_pos(0)$0" -> "test(0)$0"	[label=assignedFrom];
	"test_pos(0)$0" -> "sentiment(0)"	[label=assignedFrom];
	"test_pos(0)$0" -> "Positive(0)"	[label=assignedFrom];
	"test_pos(0)$1" -> "text(0)"	[label=assignedFrom];
	"test_pos(0)$1" -> "test_pos(0)$0"	[label=assignedFrom];
	"test_neg(0)$0" -> "test(0)$0"	[label=assignedFrom];
	"test_neg(0)$0" -> "sentiment(0)"	[label=assignedFrom];
	"test_neg(0)$0" -> "Negative(0)"	[label=assignedFrom];
	"test_neg(0)$1" -> "text(0)"	[label=assignedFrom];
	"test_neg(0)$1" -> "test_neg(0)$0"	[label=assignedFrom];
	"tweets(2)" -> "get_words_in_tweets[0]"	[label=_argToVar];
	"all(2)$0" -> "[](2)"	[label=assignedFrom];
	"words(2)" -> "tweets(2)"	[label=iteratorOf];
	"sentiment(2)" -> "tweets(2)"	[label=iteratorOf];
	"all(2)$1" -> "all(2)$0"	[label=extend];
	"all(2)$1" -> "words(2)"	[label=extend];
	"wordlist(3)" -> "get_word_features[0]"	[label=_argToVar];
	"wordlist(3)$0" -> "wordlist(3)$0"	[label=FreqDist];
	"wordlist(3)$0" -> "nltk(3)"	[label=FreqDist];
	"features(3)$0" -> "wordlist(3)$0"	[label=keys];
	"get_words_in_tweets(0)" -> "python-nltk-sentiment-analysis.ipynb"	[label=appearsIn];
	"w_features(0)$0" -> "tweets(0)$1"	[label=get_word_features];
	"w_features(0)$0" -> "get_words_in_tweets(0)"	[label=get_word_features];
	"document(4)" -> "extract_features[0]"	[label=_argToVar];
	"document_words(4)$0" -> "document(4)"	[label=set];
	"word(4)" -> "w_features(4)"	[label=iteratorOf];
	"features(4)$0" -> "document_words(4)$0"	[label=assignedFrom];
	"features(4)$0" -> "word(4)"	[label=assignedFrom];
	"features(4)$0" -> "features(4)"	[label=assignedFrom];
	"wordcloud_draw[93/0]" -> "w_features(0)$0"	[label=wordcloud_draw];
	"training_set(0)$0" -> "nltk(0)"	[label=apply_features];
	"training_set(0)$0" -> "tweets(0)$1"	[label=apply_features];
	"training_set(0)$0" -> "extract_features(0)"	[label=apply_features];
	"extract_features(0)" -> "python-nltk-sentiment-analysis.ipynb"	[label=appearsIn];
	"classifier(0)$0" -> "nltk(0)"	[label=train];
	"classifier(0)$0" -> "training_set(0)$0"	[label=train];
	"0(0)" -> "python-nltk-sentiment-analysis.ipynb"	[label=appearsIn];
	"neg_cnt(0)$0" -> "0(0)"	[label=assignedFrom];
	"pos_cnt(0)$0" -> "0(0)"	[label=assignedFrom];
	"obj(0)" -> "python-nltk-sentiment-analysis.ipynb"	[label=appearsIn];
	"obj(0)" -> "test_pos(0)$1"	[label=iteratorOf];
	"obj(0)" -> "test_neg(0)$1"	[label=iteratorOf];
	"res(0)$0" -> "extract_features(0)"	[label=classify];
	"res(0)$0" -> "classifier(0)$0"	[label=classify];
	"res(0)$0" -> "obj(0)"	[label=classify];
	"neg_cnt(0)$1" -> "neg_cnt(0)$0"	[label=Add];
	"neg_cnt(0)$1" -> "1(0)"	[label=Add];
	"1(0)" -> "python-nltk-sentiment-analysis.ipynb"	[label=appearsIn];
	"res(0)$1" -> "extract_features(0)"	[label=classify];
	"res(0)$1" -> "classifier(0)$0"	[label=classify];
	"res(0)$1" -> "obj(0)"	[label=classify];
	"pos_cnt(0)$1" -> "pos_cnt(0)$0"	[label=Add];
	"pos_cnt(0)$1" -> "1(0)"	[label=Add];
	"[Negative]: \%s/\%s (0)" -> "python-nltk-sentiment-analysis.ipynb"	[label=appearsIn];
	"print[109/0]" -> "len(0)"	[label=print];
	"print[109/0]" -> "test_neg(0)$1"	[label=print];
	"print[109/0]" -> "neg_cnt(0)$1"	[label=print];
	"print[109/0]" -> "[Negative]: \%s/\%s (0)"	[label=print];
	"[Positive]: \%s/\%s (0)" -> "python-nltk-sentiment-analysis.ipynb"	[label=appearsIn];
	"print[110/0]" -> "len(0)"	[label=print];
	"print[110/0]" -> "test_pos(0)$1"	[label=print];
	"print[110/0]" -> "pos_cnt(0)$1"	[label=print];
	"print[110/0]" -> "[Positive]: \%s/\%s (0)"	[label=print];
}
