digraph "" {
	numpy -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=importedBy];
	"np(0)" -> numpy	[label=assignedFrom];
	"np(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=appearsIn];
	pandas -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=importedBy];
	"pd(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=appearsIn];
	"pd(0)" -> pandas	[label=assignedFrom];
	os -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=importedBy];
	"os(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=appearsIn];
	"os(0)" -> os	[label=assignedFrom];
	tqdm -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=importedBy];
	tqdm -> tqdm	[label=importedBy];
	"tqdm(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=appearsIn];
	"tqdm(0)" -> tqdm	[label=assignedFrom];
	"tqdm(0)$0" -> "tqdm(0)"	[label=pandas];
	"comment_text(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=appearsIn];
	"TEXT_COL(0)$0" -> "comment_text(0)"	[label=assignedFrom];
	"../input/fasttext-crawl-300d-2m/crawl-300d-2M.vec(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=appearsIn];
	"EMB_PATH(0)$0" -> "../input/fasttext-crawl-300d-2m/crawl-300d-2M.vec(0)"	[label=assignedFrom];
	"train(0)$0" -> "pd(0)"	[label=read_csv];
	"train(0)$0" -> "../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv(0)"	[label=read_csv];
	"train(0)$0" -> "id(0)"	[label=read_csv];
	"../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=appearsIn];
	"id(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=appearsIn];
	"test(0)$0" -> "pd(0)"	[label=read_csv];
	"test(0)$0" -> "id(0)"	[label=read_csv];
	"test(0)$0" -> "../input/jigsaw-unintended-bias-in-toxicity-classification/test.csv(0)"	[label=read_csv];
	"../input/jigsaw-unintended-bias-in-toxicity-classification/test.csv(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=appearsIn];
	"word(1)" -> "get_coefs[0]"	[label=_argToVar];
	"embed_dir(2)" -> "load_embeddings[0]"	[label=_argToVar];
	"embedding_index(2)$0" -> "embed_dir(2)"	[label=dict];
	"embedding_index(2)$0" -> "get_coefs(2)"	[label=dict];
	"embedding_index(2)$0" -> "o(2)"	[label=dict];
	"embedding_index(2)$0" -> " (2)"	[label=dict];
	"embedding_index(2)$0" -> "tqdm(2)"	[label=dict];
	"embedding_index(2)$0" -> "open(2)"	[label=dict];
	"word_index(3)" -> "build_embedding_matrix[0]"	[label=_argToVar];
	"embeddings_index(3)" -> "build_embedding_matrix[1]"	[label=_argToVar];
	"max_features(3)" -> "build_embedding_matrix[2]"	[label=_argToVar];
	"lower(3)" -> "build_embedding_matrix[3]"	[label=_argToVar];
	"verbose(3)" -> "build_embedding_matrix[4]"	[label=_argToVar];
	"embedding_matrix(3)$0" -> "max_features(3)"	[label=zeros];
	"embedding_matrix(3)$0" -> "np(3)"	[label=zeros];
	"embedding_matrix(3)$0" -> "300(3)"	[label=zeros];
	"word(3)" -> "word_index(3)"	[label=iteratorOf];
	"word(3)" -> "verbose(3)"	[label=iteratorOf];
	"word(3)" -> "tqdm(3)"	[label=iteratorOf];
	"i(3)" -> "word_index(3)"	[label=iteratorOf];
	"i(3)" -> "verbose(3)"	[label=iteratorOf];
	"i(3)" -> "tqdm(3)"	[label=iteratorOf];
	"word(3)$0" -> "word(3)"	[label=lower];
	"embedding_vector(3)$0" -> "embeddings_index(3)"	[label=assignedFrom];
	"embedding_vector(3)$0" -> "word(3)$0"	[label=assignedFrom];
	"embedding_vector(3)$1" -> "embeddings_index(3)"	[label=assignedFrom];
	"embedding_vector(3)$1" -> "unknown(3)"	[label=assignedFrom];
	"embedding_matrix(3)$1" -> "embedding_matrix(3)$0"	[label=assignedFrom];
	"embedding_matrix(3)$1" -> "embedding_vector(3)$1"	[label=assignedFrom];
	"word_index(4)" -> "build_matrix[0]"	[label=_argToVar];
	"embeddings_index(4)" -> "build_matrix[1]"	[label=_argToVar];
	"embedding_matrix(4)$0" -> "word_index(4)"	[label=zeros];
	"embedding_matrix(4)$0" -> "np(4)"	[label=zeros];
	"embedding_matrix(4)$0" -> "len(4)"	[label=zeros];
	"embedding_matrix(4)$0" -> "1(4)"	[label=zeros];
	"embedding_matrix(4)$0" -> "300(4)"	[label=zeros];
	"word(4)" -> "word_index(4)"	[label=iteratorOf];
	"i(4)" -> "word_index(4)"	[label=iteratorOf];
	"embedding_matrix(4)$1" -> "embeddings_index(4)"	[label=assignedFrom];
	"embedding_matrix(4)$1" -> "embedding_matrix(4)$0"	[label=assignedFrom];
	"embedding_matrix(4)$1" -> "word(4)"	[label=assignedFrom];
	"embedding_matrix(4)$2" -> "embeddings_index(4)"	[label=assignedFrom];
	"embedding_matrix(4)$2" -> "embedding_matrix(4)$1"	[label=assignedFrom];
	"embedding_matrix(4)$2" -> "unknown(4)"	[label=assignedFrom];
	"keras.preprocessing.text" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=importedBy];
	Tokenizer -> "keras.preprocessing.text"	[label=importedBy];
	"Tokenizer(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=appearsIn];
	"Tokenizer(0)" -> Tokenizer	[label=assignedFrom];
	"keras.preprocessing.sequence" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=importedBy];
	pad_sequences -> "keras.preprocessing.sequence"	[label=importedBy];
	"pad_sequences(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=appearsIn];
	"pad_sequences(0)" -> pad_sequences	[label=assignedFrom];
	gc -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=importedBy];
	"gc(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=appearsIn];
	"gc(0)" -> gc	[label=assignedFrom];
	"220(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=appearsIn];
	"maxlen(0)$0" -> "220(0)"	[label=assignedFrom];
	"100000(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=appearsIn];
	"max_features(0)$0" -> "100000(0)"	[label=assignedFrom];
	"300(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=appearsIn];
	"embed_size(0)$0" -> "300(0)"	[label=assignedFrom];
	"tokenizer(0)$0" -> "max_features(0)$0"	[label=Tokenizer];
	"tokenizer(0)$0" -> "True(0)"	[label=Tokenizer];
	"True(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=appearsIn];
	"fitting tokenizer(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=appearsIn];
	"print[50/0]" -> "fitting tokenizer(0)"	[label=print];
	"tokenizer(0)$1" -> "TEXT_COL(0)$0"	[label=fit_on_texts];
	"tokenizer(0)$1" -> "train(0)$0"	[label=fit_on_texts];
	"tokenizer(0)$1" -> "test(0)$0"	[label=fit_on_texts];
	"tokenizer(0)$1" -> "tokenizer(0)$0"	[label=fit_on_texts];
	"tokenizer(0)$1" -> "list(0)"	[label=fit_on_texts];
	"list(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=appearsIn];
	"word_index(0)$0" -> "tokenizer(0)$1"	[label=assignedFrom];
	"X_train(0)$0" -> "TEXT_COL(0)$0"	[label=texts_to_sequences];
	"X_train(0)$0" -> "train(0)$0"	[label=texts_to_sequences];
	"X_train(0)$0" -> "tokenizer(0)$1"	[label=texts_to_sequences];
	"X_train(0)$0" -> "list(0)"	[label=texts_to_sequences];
	"y_train(0)$0" -> "train(0)$0"	[label=assignedFrom];
	"y_train(0)$0" -> "target(0)"	[label=assignedFrom];
	"target(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=appearsIn];
	"X_test(0)$0" -> "TEXT_COL(0)$0"	[label=texts_to_sequences];
	"X_test(0)$0" -> "test(0)$0"	[label=texts_to_sequences];
	"X_test(0)$0" -> "tokenizer(0)$1"	[label=texts_to_sequences];
	"X_test(0)$0" -> "list(0)"	[label=texts_to_sequences];
	"X_train(0)$1" -> "maxlen(0)$0"	[label=pad_sequences];
	"X_train(0)$1" -> "X_train(0)$0"	[label=pad_sequences];
	"X_test(0)$1" -> "maxlen(0)$0"	[label=pad_sequences];
	"X_test(0)$1" -> "X_test(0)$0"	[label=pad_sequences];
	"gc(0)$0" -> "gc(0)"	[label=collect];
	"embedding_matrix(0)$0" -> "word_index(0)$0"	[label=build_matrix];
	"embedding_matrix(0)$0" -> "embeddings_index(0)"	[label=build_matrix];
	"embeddings_index(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=appearsIn];
	"gc(0)$1" -> "gc(0)$0"	[label=collect];
	keras -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=importedBy];
	backend -> keras	[label=importedBy];
	"K(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=appearsIn];
	"K(0)" -> backend	[label=assignedFrom];
	"K(0)" -> "keras.backend"	[label=assignedFrom];
	"keras.backend" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=importedBy];
	"keras.engine.topology" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=importedBy];
	Layer -> "keras.engine.topology"	[label=importedBy];
	"Layer(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=appearsIn];
	"Layer(0)" -> Layer	[label=assignedFrom];
	initializers -> keras	[label=importedBy];
	"initializers(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=appearsIn];
	"initializers(0)" -> initializers	[label=assignedFrom];
	regularizers -> keras	[label=importedBy];
	"regularizers(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=appearsIn];
	"regularizers(0)" -> regularizers	[label=assignedFrom];
	constraints -> keras	[label=importedBy];
	"constraints(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=appearsIn];
	"constraints(0)" -> constraints	[label=assignedFrom];
	optimizers -> keras	[label=importedBy];
	"optimizers(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=appearsIn];
	"optimizers(0)" -> optimizers	[label=assignedFrom];
	layers -> keras	[label=importedBy];
	"layers(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=appearsIn];
	"layers(0)" -> layers	[label=assignedFrom];
	"self(6)" -> "__init__[0]"	[label=_argToVar];
	"step_dim(6)" -> "__init__[1]"	[label=_argToVar];
	"W_regularizer(6)" -> "__init__[2]"	[label=_argToVar];
	"b_regularizer(6)" -> "__init__[3]"	[label=_argToVar];
	"W_constraint(6)" -> "__init__[4]"	[label=_argToVar];
	"b_constraint(6)" -> "__init__[5]"	[label=_argToVar];
	"bias(6)" -> "__init__[6]"	[label=_argToVar];
	"self(6)$0" -> "self(6)"	[label=assignedFrom];
	"self(6)$0" -> "True(6)"	[label=assignedFrom];
	"self(6)$1" -> "self(6)$0"	[label=get];
	"self(6)$1" -> "initializers(6)"	[label=get];
	"self(6)$1" -> "glorot_uniform(6)"	[label=get];
	"self(6)$2" -> "W_regularizer(6)"	[label=get];
	"self(6)$2" -> "self(6)$1"	[label=get];
	"self(6)$2" -> "regularizers(6)"	[label=get];
	"self(6)$3" -> "b_regularizer(6)"	[label=get];
	"self(6)$3" -> "self(6)$2"	[label=get];
	"self(6)$3" -> "regularizers(6)"	[label=get];
	"self(6)$4" -> "W_constraint(6)"	[label=get];
	"self(6)$4" -> "self(6)$3"	[label=get];
	"self(6)$4" -> "constraints(6)"	[label=get];
	"self(6)$5" -> "b_constraint(6)"	[label=get];
	"self(6)$5" -> "self(6)$4"	[label=get];
	"self(6)$5" -> "constraints(6)"	[label=get];
	"self(6)$6" -> "bias(6)"	[label=assignedFrom];
	"self(6)$6" -> "self(6)$5"	[label=assignedFrom];
	"self(6)$7" -> "step_dim(6)"	[label=assignedFrom];
	"self(6)$7" -> "self(6)$6"	[label=assignedFrom];
	"self(6)$8" -> "self(6)$7"	[label=assignedFrom];
	"self(6)$8" -> "0(6)"	[label=assignedFrom];
	"super(6)$0" -> "super(6)"	[label=__init__];
	"self(7)" -> "build[0]"	[label=_argToVar];
	"input_shape(7)" -> "build[1]"	[label=_argToVar];
	"self(7)$0" -> "self(7)"	[label=add_weight];
	"self(7)$0" -> "input_shape(7)"	[label=add_weight];
	"self(7)$0" -> "self(7)$0"	[label=add_weight];
	"self(7)$0" -> "1(7)"	[label=add_weight];
	"self(7)$0" -> "{}_W(7)"	[label=add_weight];
	"self(7)$1" -> "input_shape(7)"	[label=assignedFrom];
	"self(7)$1" -> "self(7)$0"	[label=assignedFrom];
	"self(7)$1" -> "1(7)"	[label=assignedFrom];
	"self(7)$2" -> "input_shape(7)"	[label=add_weight];
	"self(7)$2" -> "1(7)"	[label=add_weight];
	"self(7)$2" -> "self(7)$1"	[label=add_weight];
	"self(7)$2" -> "self(7)$2"	[label=add_weight];
	"self(7)$2" -> "zero(7)"	[label=add_weight];
	"self(7)$2" -> "{}_b(7)"	[label=add_weight];
	"self(7)$3" -> "self(7)$2"	[label=assignedFrom];
	"self(7)$3" -> "None(7)"	[label=assignedFrom];
	"self(7)$4" -> "self(7)$3"	[label=assignedFrom];
	"self(7)$4" -> "True(7)"	[label=assignedFrom];
	"self(8)" -> "compute_mask[0]"	[label=_argToVar];
	"input(8)" -> "compute_mask[1]"	[label=_argToVar];
	"input_mask(8)" -> "compute_mask[2]"	[label=_argToVar];
	"self(9)" -> "call[0]"	[label=_argToVar];
	"x(9)" -> "call[1]"	[label=_argToVar];
	"mask(9)" -> "call[2]"	[label=_argToVar];
	"features_dim(9)$0" -> "self(9)"	[label=assignedFrom];
	"step_dim(9)$0" -> "self(9)"	[label=assignedFrom];
	"eij(9)$0" -> "self(9)"	[label=reshape];
	"eij(9)$0" -> "x(9)"	[label=reshape];
	"eij(9)$0" -> "features_dim(9)$0"	[label=reshape];
	"eij(9)$0" -> "step_dim(9)$0"	[label=reshape];
	"eij(9)$0" -> "K(9)"	[label=reshape];
	"eij(9)$0" -> "1(9)"	[label=reshape];
	"eij(9)$1" -> "self(9)"	[label=Add];
	"eij(9)$1" -> "eij(9)$0"	[label=Add];
	"eij(9)$2" -> "K(9)"	[label=tanh];
	"eij(9)$2" -> "eij(9)$2"	[label=tanh];
	"a(9)$0" -> "K(9)"	[label=exp];
	"a(9)$0" -> "eij(9)$2"	[label=exp];
	"a(9)$1" -> "mask(9)"	[label=Mult];
	"a(9)$1" -> "K(9)"	[label=Mult];
	"a(9)$1" -> "a(9)$0"	[label=Mult];
	"a(9)$2" -> "K(9)"	[label=Div];
	"a(9)$2" -> "1(9)"	[label=Div];
	"a(9)$2" -> "a(9)$1"	[label=Div];
	"a(9)$2" -> "a(9)$2"	[label=Div];
	"a(9)$2" -> "True(9)"	[label=Div];
	"a(9)$3" -> "K(9)"	[label=expand_dims];
	"a(9)$3" -> "a(9)$3"	[label=expand_dims];
	"weighted_input(9)$0" -> "x(9)"	[label=Mult];
	"weighted_input(9)$0" -> "a(9)$3"	[label=Mult];
	"self(10)" -> "compute_output_shape[0]"	[label=_argToVar];
	"input_shape(10)" -> "compute_output_shape[1]"	[label=_argToVar];
	"keras.layers" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=importedBy];
	"L(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=appearsIn];
	"L(0)" -> "keras.layers"	[label=assignedFrom];
	"keras.models" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=importedBy];
	Model -> "keras.models"	[label=importedBy];
	"Model(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=appearsIn];
	"Model(0)" -> Model	[label=assignedFrom];
	"keras.optimizers" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=importedBy];
	Adam -> "keras.optimizers"	[label=importedBy];
	"Adam(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=appearsIn];
	"Adam(0)" -> Adam	[label=assignedFrom];
	"verbose(11)" -> "build_model[0]"	[label=_argToVar];
	"compile(11)" -> "build_model[1]"	[label=_argToVar];
	"sequence_input(11)$0" -> "L(11)"	[label=Input];
	"sequence_input(11)$0" -> "maxlen(11)"	[label=Input];
	"sequence_input(11)$0" -> "int32(11)"	[label=Input];
	"embedding_layer(11)$0" -> "L(11)"	[label=Embedding];
	"embedding_layer(11)$0" -> "maxlen(11)"	[label=Embedding];
	"embedding_layer(11)$0" -> "len(11)"	[label=Embedding];
	"embedding_layer(11)$0" -> "word_index(11)"	[label=Embedding];
	"embedding_layer(11)$0" -> "1(11)"	[label=Embedding];
	"embedding_layer(11)$0" -> "300(11)"	[label=Embedding];
	"embedding_layer(11)$0" -> "[<_ast.Name object at 0x7fd4c04d8040>](11)"	[label=Embedding];
	"embedding_layer(11)$0" -> "False(11)"	[label=Embedding];
	"x(11)$0" -> "sequence_input(11)$0"	[label=embedding_layer];
	"x(11)$1" -> "L(11)"	[label=assignedFrom];
	"x(11)$1" -> "x(11)$1"	[label=assignedFrom];
	"x(11)$1" -> "0.2(11)"	[label=assignedFrom];
	"x(11)$2" -> "L(11)"	[label=assignedFrom];
	"x(11)$2" -> "x(11)$2"	[label=assignedFrom];
	"x(11)$2" -> "64(11)"	[label=assignedFrom];
	"x(11)$2" -> "True(11)"	[label=assignedFrom];
	"att(11)$0" -> "maxlen(11)"	[label=assignedFrom];
	"att(11)$0" -> "x(11)$2"	[label=assignedFrom];
	"att(11)$0" -> "Attention(11)"	[label=assignedFrom];
	"avg_pool1(11)$0" -> "L(11)"	[label=assignedFrom];
	"avg_pool1(11)$0" -> "x(11)$2"	[label=assignedFrom];
	"max_pool1(11)$0" -> "L(11)"	[label=assignedFrom];
	"max_pool1(11)$0" -> "x(11)$2"	[label=assignedFrom];
	"x(11)$3" -> "L(11)"	[label=concatenate];
	"x(11)$3" -> "[<_ast.Name object at 0x7fd4c04d8fd0>, <_ast.Name object at 0x7fd4c04d80d0>, <_ast.Name object at 0x7fd4c04d8c10>](11)"	[label=concatenate];
	"preds(11)$0" -> "L(11)"	[label=assignedFrom];
	"preds(11)$0" -> "1(11)"	[label=assignedFrom];
	"preds(11)$0" -> "x(11)$3"	[label=assignedFrom];
	"preds(11)$0" -> "sigmoid(11)"	[label=assignedFrom];
	"model(11)$0" -> "sequence_input(11)$0"	[label=Model];
	"model(11)$0" -> "preds(11)$0"	[label=Model];
	"model(11)$1" -> "model(11)$0"	[label=summary];
	"model(11)$2" -> "model(11)$1"	[label=compile];
	"sklearn.model_selection" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=importedBy];
	KFold -> "sklearn.model_selection"	[label=importedBy];
	"KFold(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=appearsIn];
	"KFold(0)" -> KFold	[label=assignedFrom];
	"splits(0)$0" -> "y_train(0)$0"	[label=list];
	"splits(0)$0" -> "X_train(0)$1"	[label=list];
	"splits(0)$0" -> "KFold(0)"	[label=list];
	"splits(0)$0" -> "5(0)"	[label=list];
	"5(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=appearsIn];
	"keras.callbacks" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=importedBy];
	EarlyStopping -> "keras.callbacks"	[label=importedBy];
	"EarlyStopping(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=appearsIn];
	"EarlyStopping(0)" -> EarlyStopping	[label=assignedFrom];
	ModelCheckpoint -> "keras.callbacks"	[label=importedBy];
	"ModelCheckpoint(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=appearsIn];
	"ModelCheckpoint(0)" -> ModelCheckpoint	[label=assignedFrom];
	"2048(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=appearsIn];
	"BATCH_SIZE(0)$0" -> "2048(0)"	[label=assignedFrom];
	"100(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=appearsIn];
	"NUM_EPOCHS(0)$0" -> "100(0)"	[label=assignedFrom];
	"oof_preds(0)$0" -> "np(0)"	[label=zeros];
	"oof_preds(0)$0" -> "X_train(0)$1"	[label=zeros];
	"oof_preds(0)$0" -> "0(0)"	[label=zeros];
	"0(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=appearsIn];
	"test_preds(0)$0" -> "np(0)"	[label=zeros];
	"test_preds(0)$0" -> "X_test(0)$1"	[label=zeros];
	"test_preds(0)$0" -> "0(0)"	[label=zeros];
	"[<_ast.Constant object at 0x7fd4902ab2b0>, <_ast.Constant object at 0x7fd4902ab460>, <_ast.Constant object at 0x7fd4902ab250>, <_\
ast.Constant object at 0x7fd4902ab310>, <_ast.Constant object at 0x7fd4902ab850>](0)" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=appearsIn];
	"fold(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=appearsIn];
	"fold(0)" -> "[<_ast.Constant object at 0x7fd4902ab2b0>, <_ast.Constant object at 0x7fd4902ab460>, <_ast.Constant object at 0x7fd4902ab250>, <_\
ast.Constant object at 0x7fd4902ab310>, <_ast.Constant object at 0x7fd4902ab850>](0)"	[label=iteratorOf];
	"K(0)$0" -> "K(0)"	[label=clear_session];
	"tr_ind(0)$0" -> "splits(0)$0"	[label=assignedFrom];
	"tr_ind(0)$0" -> "fold(0)"	[label=assignedFrom];
	"val_ind(0)$0" -> "splits(0)$0"	[label=assignedFrom];
	"val_ind(0)$0" -> "fold(0)"	[label=assignedFrom];
	"gru_(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=appearsIn];
	"ckpt(0)$0" -> "True(0)"	[label=ModelCheckpoint];
	"ckpt(0)$0" -> "fold(0)"	[label=ModelCheckpoint];
	"ckpt(0)$0" -> "gru_(0)"	[label=ModelCheckpoint];
	"ckpt(0)$0" -> ".hdf5(0)"	[label=ModelCheckpoint];
	".hdf5(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=appearsIn];
	"val_loss(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=appearsIn];
	"es(0)$0" -> "val_loss(0)"	[label=EarlyStopping];
	"es(0)$0" -> "min(0)"	[label=EarlyStopping];
	"es(0)$0" -> "1(0)"	[label=EarlyStopping];
	"es(0)$0" -> "3(0)"	[label=EarlyStopping];
	"min(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=appearsIn];
	"1(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=appearsIn];
	"3(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=appearsIn];
	"model(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=appearsIn];
	"model(0)$0" -> "y_train(0)$0"	[label=fit];
	"model(0)$0" -> "X_train(0)$1"	[label=fit];
	"model(0)$0" -> "tr_ind(0)$0"	[label=fit];
	"model(0)$0" -> "model(0)"	[label=fit];
	"model(0)$0" -> "0.5(0)"	[label=fit];
	"0.5(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=appearsIn];
	"oof_preds(0)$1" -> "X_train(0)$1"	[label=Add];
	"oof_preds(0)$1" -> "oof_preds(0)$0"	[label=Add];
	"oof_preds(0)$1" -> "0(0)"	[label=Add];
	"oof_preds(0)$1" -> "val_ind(0)$0"	[label=Add];
	"oof_preds(0)$1" -> "model(0)$0"	[label=Add];
	"test_preds(0)$1" -> "X_test(0)$1"	[label=Add];
	"test_preds(0)$1" -> "0(0)"	[label=Add];
	"test_preds(0)$1" -> "test_preds(0)$0"	[label=Add];
	"test_preds(0)$1" -> "model(0)$0"	[label=Add];
	"test_preds(0)$2" -> "5(0)"	[label=Div];
	"test_preds(0)$2" -> "test_preds(0)$1"	[label=Div];
	"sklearn.metrics" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=importedBy];
	roc_auc_score -> "sklearn.metrics"	[label=importedBy];
	"roc_auc_score(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=appearsIn];
	"roc_auc_score(0)" -> roc_auc_score	[label=assignedFrom];
	"roc_auc_score[206/0]" -> "y_train(0)$0"	[label=roc_auc_score];
	"roc_auc_score[206/0]" -> "0.5(0)"	[label=roc_auc_score];
	"roc_auc_score[206/0]" -> "oof_preds(0)$1"	[label=roc_auc_score];
	"submission(0)$0" -> "pd(0)"	[label=read_csv];
	"submission(0)$0" -> "id(0)"	[label=read_csv];
	"submission(0)$0" -> "../input/jigsaw-unintended-bias-in-toxicity-classification/sample_submission.csv(0)"	[label=read_csv];
	"../input/jigsaw-unintended-bias-in-toxicity-classification/sample_submission.csv(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=appearsIn];
	"submission(0)$1" -> "test_preds(0)$2"	[label=assignedFrom];
	"submission(0)$1" -> "submission(0)$0"	[label=assignedFrom];
	"submission(0)$2" -> "submission(0)$1"	[label=reset_index];
	"submission(0)$3" -> "submission(0)$2"	[label=head];
	"submission(0)$4" -> "submission(0)$3"	[label=to_csv];
	"submission(0)$4" -> "submission.csv(0)"	[label=to_csv];
	"submission.csv(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb"	[label=appearsIn];
}
