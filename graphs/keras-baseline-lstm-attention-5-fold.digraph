digraph { 
"numpy" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "import"]
"np(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "appears"]
"np(0)" -> "numpy" [label = "assign"]
"pandas" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "import"]
"pd(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "appears"]
"pd(0)" -> "pandas" [label = "assign"]
"os" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "import"]
"os(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "appears"]
"os(0)" -> "os" [label = "assign"]
"tqdm" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "import"]
"tqdm" -> "tqdm" [label = "import"]
"tqdm(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "appears"]
"tqdm(0)" -> "tqdm" [label = "assign"]
"tqdm(0)$0" -> "tqdm(0)" [label = "pandas"]
"comment_text(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "appears"]
"TEXT_COL(0)$0" -> "comment_text(0)" [label = "assign"]
"../input/fasttext-crawl-300d-2m/crawl-300d-2M.vec(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "appears"]
"EMB_PATH(0)$0" -> "../input/fasttext-crawl-300d-2m/crawl-300d-2M.vec(0)" [label = "assign"]
"train(0)$0" -> "pd(0)" [label = "read_csv"]
"../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "appears"]
"train(0)$0" -> "../input/jigsaw-unintended-bias-in-toxicity-classification/train.csv(0)" [label = "read_csv"]
"id(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "appears"]
"train(0)$0" -> "id(0)" [label = "read_csv"]
"test(0)$0" -> "pd(0)" [label = "read_csv"]
"../input/jigsaw-unintended-bias-in-toxicity-classification/test.csv(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "appears"]
"test(0)$0" -> "../input/jigsaw-unintended-bias-in-toxicity-classification/test.csv(0)" [label = "read_csv"]
"test(0)$0" -> "id(0)" [label = "read_csv"]
"word(1)" -> "get_coefs[0]" [label = "_argToVar"]
"embed_dir(2)" -> "load_embeddings[0]" [label = "_argToVar"]
"embedding_index(2)$0" -> "get_coefs(2)" [label = "dict"]
"embedding_index(2)$0" -> "o(2)" [label = "dict"]
"embedding_index(2)$0" -> " (2)" [label = "dict"]
"embedding_index(2)$0" -> "o(2)" [label = "dict"]
"embedding_index(2)$0" -> "tqdm(2)" [label = "dict"]
"embedding_index(2)$0" -> "open(2)" [label = "dict"]
"embedding_index(2)$0" -> "embed_dir(2)" [label = "dict"]
"word_index(3)" -> "build_embedding_matrix[0]" [label = "_argToVar"]
"embeddings_index(3)" -> "build_embedding_matrix[1]" [label = "_argToVar"]
"max_features(3)" -> "build_embedding_matrix[2]" [label = "_argToVar"]
"lower(3)" -> "build_embedding_matrix[3]" [label = "_argToVar"]
"verbose(3)" -> "build_embedding_matrix[4]" [label = "_argToVar"]
"embedding_matrix(3)$0" -> "np(3)" [label = "zeros"]
"embedding_matrix(3)$0" -> "max_features(3)" [label = "zeros"]
"embedding_matrix(3)$0" -> "300(3)" [label = "zeros"]
"word(3)" -> "tqdm(3)" [label = "Iter"]
"i(3)" -> "tqdm(3)" [label = "Iter"]
"word(3)" -> "word_index(3)" [label = "Iter"]
"i(3)" -> "word_index(3)" [label = "Iter"]
"word(3)" -> "verbose(3)" [label = "Iter"]
"i(3)" -> "verbose(3)" [label = "Iter"]
"word(3)$0" -> "word(3)" [label = "lower"]
"embedding_vector(3)$0" -> "embeddings_index(3)" [label = "assign"]
"embedding_vector(3)$0" -> "word(3)$0" [label = "assign"]
"embedding_vector(3)$1" -> "embeddings_index(3)" [label = "assign"]
"embedding_vector(3)$1" -> "unknown(3)" [label = "assign"]
"embedding_matrix(3)$1" -> "embedding_matrix(3)$0" [label = "assign"]
"embedding_matrix(3)$1" -> "embedding_vector(3)$1" [label = "assign"]
"word_index(4)" -> "build_matrix[0]" [label = "_argToVar"]
"embeddings_index(4)" -> "build_matrix[1]" [label = "_argToVar"]
"embedding_matrix(4)$0" -> "np(4)" [label = "zeros"]
"embedding_matrix(4)$0" -> "len(4)" [label = "zeros"]
"embedding_matrix(4)$0" -> "word_index(4)" [label = "zeros"]
"embedding_matrix(4)$0" -> "1(4)" [label = "zeros"]
"embedding_matrix(4)$0" -> "300(4)" [label = "zeros"]
"word(4)" -> "word_index(4)" [label = "Iter"]
"i(4)" -> "word_index(4)" [label = "Iter"]
"embedding_matrix(4)$1" -> "embedding_matrix(4)$0" [label = "assign"]
"embedding_matrix(4)$1" -> "embeddings_index(4)" [label = "assign"]
"embedding_matrix(4)$1" -> "word(4)" [label = "assign"]
"embedding_matrix(4)$2" -> "embedding_matrix(4)$1" [label = "assign"]
"embedding_matrix(4)$2" -> "embeddings_index(4)" [label = "assign"]
"embedding_matrix(4)$2" -> "unknown(4)" [label = "assign"]
"keras.preprocessing.text" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "import"]
"Tokenizer" -> "keras.preprocessing.text" [label = "import"]
"Tokenizer(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "appears"]
"Tokenizer(0)" -> "Tokenizer" [label = "assign"]
"keras.preprocessing.sequence" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "import"]
"pad_sequences" -> "keras.preprocessing.sequence" [label = "import"]
"pad_sequences(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "appears"]
"pad_sequences(0)" -> "pad_sequences" [label = "assign"]
"gc" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "import"]
"gc(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "appears"]
"gc(0)" -> "gc" [label = "assign"]
"220(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "appears"]
"maxlen(0)$0" -> "220(0)" [label = "assign"]
"100000(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "appears"]
"max_features(0)$0" -> "100000(0)" [label = "assign"]
"300(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "appears"]
"embed_size(0)$0" -> "300(0)" [label = "assign"]
"tokenizer(0)$0" -> "max_features(0)$0" [label = "Tokenizer"]
"fitting tokenizer(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "appears"]
"print[0]" -> "fitting tokenizer(0)" [label = "print"]
"tokenizer(0)$1" -> "tokenizer(0)$0" [label = "fit_on_texts"]
"list(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "appears"]
"tokenizer(0)$1" -> "list(0)" [label = "fit_on_texts"]
"tokenizer(0)$1" -> "train(0)$0" [label = "fit_on_texts"]
"tokenizer(0)$1" -> "TEXT_COL(0)$0" [label = "fit_on_texts"]
"tokenizer(0)$1" -> "list(0)" [label = "fit_on_texts"]
"tokenizer(0)$1" -> "test(0)$0" [label = "fit_on_texts"]
"tokenizer(0)$1" -> "TEXT_COL(0)$0" [label = "fit_on_texts"]
"word_index(0)$0" -> "tokenizer(0)$1" [label = "assign"]
"X_train(0)$0" -> "tokenizer(0)$1" [label = "texts_to_sequences"]
"X_train(0)$0" -> "list(0)" [label = "texts_to_sequences"]
"X_train(0)$0" -> "train(0)$0" [label = "texts_to_sequences"]
"X_train(0)$0" -> "TEXT_COL(0)$0" [label = "texts_to_sequences"]
"y_train(0)$0" -> "train(0)$0" [label = "assign"]
"target(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "appears"]
"y_train(0)$0" -> "target(0)" [label = "assign"]
"X_test(0)$0" -> "tokenizer(0)$1" [label = "texts_to_sequences"]
"X_test(0)$0" -> "list(0)" [label = "texts_to_sequences"]
"X_test(0)$0" -> "test(0)$0" [label = "texts_to_sequences"]
"X_test(0)$0" -> "TEXT_COL(0)$0" [label = "texts_to_sequences"]
"X_train(0)$1" -> "X_train(0)$0" [label = "pad_sequences"]
"X_train(0)$1" -> "maxlen(0)$0" [label = "pad_sequences"]
"X_test(0)$1" -> "X_test(0)$0" [label = "pad_sequences"]
"X_test(0)$1" -> "maxlen(0)$0" [label = "pad_sequences"]
"gc(0)$0" -> "gc(0)" [label = "collect"]
"embedding_matrix(0)$0" -> "word_index(0)$0" [label = "build_matrix"]
"embeddings_index(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "appears"]
"embedding_matrix(0)$0" -> "embeddings_index(0)" [label = "build_matrix"]
"gc(0)$1" -> "gc(0)$0" [label = "collect"]
"keras" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "import"]
"backend" -> "keras" [label = "import"]
"K(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "appears"]
"K(0)" -> "backend" [label = "assign"]
"keras.engine.topology" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "import"]
"Layer" -> "keras.engine.topology" [label = "import"]
"Layer(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "appears"]
"Layer(0)" -> "Layer" [label = "assign"]
"keras" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "import"]
"initializers" -> "keras" [label = "import"]
"initializers(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "appears"]
"initializers(0)" -> "initializers" [label = "assign"]
"regularizers" -> "keras" [label = "import"]
"regularizers(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "appears"]
"regularizers(0)" -> "regularizers" [label = "assign"]
"constraints" -> "keras" [label = "import"]
"constraints(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "appears"]
"constraints(0)" -> "constraints" [label = "assign"]
"optimizers" -> "keras" [label = "import"]
"optimizers(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "appears"]
"optimizers(0)" -> "optimizers" [label = "assign"]
"layers" -> "keras" [label = "import"]
"layers(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "appears"]
"layers(0)" -> "layers" [label = "assign"]
"self(6)" -> "__init__[0]" [label = "_argToVar"]
"step_dim(6)" -> "__init__[1]" [label = "_argToVar"]
"W_regularizer(6)" -> "__init__[2]" [label = "_argToVar"]
"b_regularizer(6)" -> "__init__[3]" [label = "_argToVar"]
"W_constraint(6)" -> "__init__[4]" [label = "_argToVar"]
"b_constraint(6)" -> "__init__[5]" [label = "_argToVar"]
"bias(6)" -> "__init__[6]" [label = "_argToVar"]
"self(6)$0" -> "self(6)" [label = "get"]
"self(6)$0" -> "initializers(6)" [label = "get"]
"self(6)$0" -> "glorot_uniform(6)" [label = "get"]
"self(6)$1" -> "self(6)$0" [label = "get"]
"self(6)$1" -> "regularizers(6)" [label = "get"]
"self(6)$1" -> "W_regularizer(6)" [label = "get"]
"self(6)$2" -> "self(6)$1" [label = "get"]
"self(6)$2" -> "regularizers(6)" [label = "get"]
"self(6)$2" -> "b_regularizer(6)" [label = "get"]
"self(6)$3" -> "self(6)$2" [label = "get"]
"self(6)$3" -> "constraints(6)" [label = "get"]
"self(6)$3" -> "W_constraint(6)" [label = "get"]
"self(6)$4" -> "self(6)$3" [label = "get"]
"self(6)$4" -> "constraints(6)" [label = "get"]
"self(6)$4" -> "b_constraint(6)" [label = "get"]
"self(6)$5" -> "self(6)$4" [label = "assign"]
"self(6)$5" -> "bias(6)" [label = "assign"]
"self(6)$6" -> "self(6)$5" [label = "assign"]
"self(6)$6" -> "step_dim(6)" [label = "assign"]
"self(6)$7" -> "self(6)$6" [label = "assign"]
"self(6)$7" -> "0(6)" [label = "assign"]
"super(6)$0" -> "super(6)" [label = "__init__"]
"self(7)" -> "build[0]" [label = "_argToVar"]
"input_shape(7)" -> "build[1]" [label = "_argToVar"]
"self(7)$0" -> "self(7)" [label = "add_weight"]
"self(7)$0" -> "self(7)" [label = "add_weight"]
"self(7)$0" -> "input_shape(7)" [label = "add_weight"]
"self(7)$0" -> "1(7)" [label = "add_weight"]
"self(7)$0" -> "self(7)$0" [label = "add_weight"]
"self(7)$0" -> "{}_W(7)" [label = "add_weight"]
"self(7)$0" -> "self(7)$0" [label = "add_weight"]
"self(7)$0" -> "self(7)$0" [label = "add_weight"]
"self(7)$0" -> "self(7)$0" [label = "add_weight"]
"self(7)$1" -> "self(7)$0" [label = "assign"]
"self(7)$1" -> "input_shape(7)" [label = "assign"]
"self(7)$1" -> "1(7)" [label = "assign"]
"self(7)$2" -> "self(7)$1" [label = "add_weight"]
"self(7)$2" -> "self(7)$1" [label = "add_weight"]
"self(7)$2" -> "input_shape(7)" [label = "add_weight"]
"self(7)$2" -> "1(7)" [label = "add_weight"]
"self(7)$2" -> "zero(7)" [label = "add_weight"]
"self(7)$2" -> "{}_b(7)" [label = "add_weight"]
"self(7)$2" -> "self(7)$2" [label = "add_weight"]
"self(7)$2" -> "self(7)$2" [label = "add_weight"]
"self(7)$2" -> "self(7)$2" [label = "add_weight"]
"self(8)" -> "compute_mask[0]" [label = "_argToVar"]
"input(8)" -> "compute_mask[1]" [label = "_argToVar"]
"input_mask(8)" -> "compute_mask[2]" [label = "_argToVar"]
"self(9)" -> "call[0]" [label = "_argToVar"]
"x(9)" -> "call[1]" [label = "_argToVar"]
"mask(9)" -> "call[2]" [label = "_argToVar"]
"features_dim(9)$0" -> "self(9)" [label = "assign"]
"step_dim(9)$0" -> "self(9)" [label = "assign"]
"eij(9)$0" -> "K(9)" [label = "reshape"]
"eij(9)$0" -> "K(9)" [label = "reshape"]
"eij(9)$0" -> "K(9)" [label = "reshape"]
"eij(9)$0" -> "x(9)" [label = "reshape"]
"eij(9)$0" -> "1(9)" [label = "reshape"]
"eij(9)$0" -> "features_dim(9)$0" [label = "reshape"]
"eij(9)$0" -> "K(9)" [label = "reshape"]
"eij(9)$0" -> "self(9)" [label = "reshape"]
"eij(9)$0" -> "features_dim(9)$0" [label = "reshape"]
"eij(9)$0" -> "1(9)" [label = "reshape"]
"eij(9)$0" -> "1(9)" [label = "reshape"]
"eij(9)$0" -> "step_dim(9)$0" [label = "reshape"]
"eij(9)$1" -> "self(9)" [label = "Add"]
"eij(9)$1" -> "eij(9)$0" [label = "Add"]
"eij(9)$2" -> "K(9)" [label = "tanh"]
"eij(9)$2" -> "eij(9)$2" [label = "tanh"]
"a(9)$0" -> "K(9)" [label = "exp"]
"a(9)$0" -> "eij(9)$2" [label = "exp"]
"a(9)$1" -> "K(9)" [label = "Mult"]
"a(9)$1" -> "a(9)$0" [label = "Mult"]
"a(9)$1" -> "mask(9)" [label = "Mult"]
"a(9)$1" -> "a(9)$0" [label = "Mult"]
"a(9)$1" -> "K(9)" [label = "Mult"]
"a(9)$1" -> "a(9)$0" [label = "Mult"]
"a(9)$2" -> "K(9)" [label = "Div"]
"a(9)$2" -> "a(9)$1" [label = "Div"]
"a(9)$2" -> "K(9)" [label = "Div"]
"a(9)$2" -> "a(9)$1" [label = "Div"]
"a(9)$2" -> "a(9)$2" [label = "Div"]
"a(9)$2" -> "a(9)$1" [label = "Div"]
"a(9)$2" -> "1(9)" [label = "Div"]
"a(9)$2" -> "a(9)$1" [label = "Div"]
"a(9)$2" -> "K(9)" [label = "Div"]
"a(9)$2" -> "a(9)$1" [label = "Div"]
"a(9)$2" -> "K(9)" [label = "Div"]
"a(9)$2" -> "a(9)$1" [label = "Div"]
"a(9)$3" -> "K(9)" [label = "expand_dims"]
"a(9)$3" -> "a(9)$3" [label = "expand_dims"]
"weighted_input(9)$0" -> "x(9)" [label = "Mult"]
"weighted_input(9)$0" -> "a(9)$3" [label = "Mult"]
"self(10)" -> "compute_output_shape[0]" [label = "_argToVar"]
"input_shape(10)" -> "compute_output_shape[1]" [label = "_argToVar"]
"keras.layers" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "import"]
"L(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "appears"]
"L(0)" -> "keras.layers" [label = "assign"]
"keras.models" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "import"]
"Model" -> "keras.models" [label = "import"]
"Model(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "appears"]
"Model(0)" -> "Model" [label = "assign"]
"keras.optimizers" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "import"]
"Adam" -> "keras.optimizers" [label = "import"]
"Adam(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "appears"]
"Adam(0)" -> "Adam" [label = "assign"]
"verbose(11)" -> "build_model[0]" [label = "_argToVar"]
"compile(11)" -> "build_model[1]" [label = "_argToVar"]
"sequence_input(11)$0" -> "L(11)" [label = "Input"]
"sequence_input(11)$0" -> "maxlen(11)" [label = "Input"]
"sequence_input(11)$0" -> "int32(11)" [label = "Input"]
"embedding_layer(11)$0" -> "L(11)" [label = "Embedding"]
"embedding_layer(11)$0" -> "len(11)" [label = "Embedding"]
"embedding_layer(11)$0" -> "word_index(11)" [label = "Embedding"]
"embedding_layer(11)$0" -> "1(11)" [label = "Embedding"]
"embedding_layer(11)$0" -> "300(11)" [label = "Embedding"]
"embedding_layer(11)$0" -> "[<_ast.Name object at 0x105e2a7d0>](11)" [label = "Embedding"]
"embedding_layer(11)$0" -> "maxlen(11)" [label = "Embedding"]
"x(11)$0" -> "sequence_input(11)$0" [label = "embedding_layer"]
"x(11)$1" -> "L(11)" [label = "assign"]
"x(11)$1" -> "0.2(11)" [label = "assign"]
"x(11)$1" -> "x(11)$1" [label = "assign"]
"x(11)$2" -> "L(11)" [label = "assign"]
"x(11)$2" -> "L(11)" [label = "assign"]
"x(11)$2" -> "64(11)" [label = "assign"]
"x(11)$2" -> "x(11)$2" [label = "assign"]
"att(11)$0" -> "Attention(11)" [label = "assign"]
"att(11)$0" -> "maxlen(11)" [label = "assign"]
"att(11)$0" -> "x(11)$2" [label = "assign"]
"avg_pool1(11)$0" -> "L(11)" [label = "assign"]
"avg_pool1(11)$0" -> "x(11)$2" [label = "assign"]
"max_pool1(11)$0" -> "L(11)" [label = "assign"]
"max_pool1(11)$0" -> "x(11)$2" [label = "assign"]
"x(11)$3" -> "L(11)" [label = "concatenate"]
"x(11)$3" -> "[<_ast.Name object at 0x1066dd2d0>, <_ast.Name object at 0x1066dd410>, <_ast.Name object at 0x1066dd350>](11)" [label = "concatenate"]
"preds(11)$0" -> "L(11)" [label = "assign"]
"preds(11)$0" -> "1(11)" [label = "assign"]
"preds(11)$0" -> "sigmoid(11)" [label = "assign"]
"preds(11)$0" -> "x(11)$3" [label = "assign"]
"model(11)$0" -> "sequence_input(11)$0" [label = "Model"]
"model(11)$0" -> "preds(11)$0" [label = "Model"]
"model(11)$1" -> "model(11)$0" [label = "summary"]
"model(11)$2" -> "model(11)$1" [label = "compile"]
"sklearn.model_selection" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "import"]
"KFold" -> "sklearn.model_selection" [label = "import"]
"KFold(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "appears"]
"KFold(0)" -> "KFold" [label = "assign"]
"splits(0)$0" -> "KFold(0)" [label = "list"]
"5(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "appears"]
"splits(0)$0" -> "5(0)" [label = "list"]
"splits(0)$0" -> "X_train(0)$1" [label = "list"]
"splits(0)$0" -> "y_train(0)$0" [label = "list"]
"keras.callbacks" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "import"]
"EarlyStopping" -> "keras.callbacks" [label = "import"]
"EarlyStopping(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "appears"]
"EarlyStopping(0)" -> "EarlyStopping" [label = "assign"]
"ModelCheckpoint" -> "keras.callbacks" [label = "import"]
"ModelCheckpoint(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "appears"]
"ModelCheckpoint(0)" -> "ModelCheckpoint" [label = "assign"]
"keras.backend" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "import"]
"K(0)" -> "keras.backend" [label = "assign"]
"numpy" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "import"]
"np(0)" -> "numpy" [label = "assign"]
"2048(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "appears"]
"BATCH_SIZE(0)$0" -> "2048(0)" [label = "assign"]
"100(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "appears"]
"NUM_EPOCHS(0)$0" -> "100(0)" [label = "assign"]
"oof_preds(0)$0" -> "np(0)" [label = "zeros"]
"oof_preds(0)$0" -> "X_train(0)$1" [label = "zeros"]
"0(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "appears"]
"oof_preds(0)$0" -> "0(0)" [label = "zeros"]
"test_preds(0)$0" -> "np(0)" [label = "zeros"]
"test_preds(0)$0" -> "X_test(0)$1" [label = "zeros"]
"test_preds(0)$0" -> "0(0)" [label = "zeros"]
"[<_ast.Num object at 0x105b34990>, <_ast.Num object at 0x105b34ed0>, <_ast.Num object at 0x105b34310>, <_ast.Num object at 0x105b34790>, <_ast.Num object at 0x105b34150>](0)" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "appears"]
"fold(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "appears"]
"fold(0)" -> "[<_ast.Num object at 0x105b34990>, <_ast.Num object at 0x105b34ed0>, <_ast.Num object at 0x105b34310>, <_ast.Num object at 0x105b34790>, <_ast.Num object at 0x105b34150>](0)" [label = "Iter"]
"K(0)$0" -> "K(0)" [label = "clear_session"]
"tr_ind(0)$0" -> "splits(0)$0" [label = "assign"]
"val_ind(0)$0" -> "splits(0)$0" [label = "assign"]
"tr_ind(0)$0" -> "fold(0)" [label = "assign"]
"val_ind(0)$0" -> "fold(0)" [label = "assign"]
"gru_(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "appears"]
"ckpt(0)$0" -> "gru_(0)" [label = "ModelCheckpoint"]
"ckpt(0)$0" -> "fold(0)" [label = "ModelCheckpoint"]
".hdf5(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "appears"]
"ckpt(0)$0" -> ".hdf5(0)" [label = "ModelCheckpoint"]
"val_loss(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "appears"]
"es(0)$0" -> "val_loss(0)" [label = "EarlyStopping"]
"min(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "appears"]
"es(0)$0" -> "min(0)" [label = "EarlyStopping"]
"1(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "appears"]
"es(0)$0" -> "1(0)" [label = "EarlyStopping"]
"3(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "appears"]
"es(0)$0" -> "3(0)" [label = "EarlyStopping"]
"model(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "appears"]
"model(0)$0" -> "model(0)" [label = "fit"]
"model(0)$0" -> "X_train(0)$1" [label = "fit"]
"model(0)$0" -> "tr_ind(0)$0" [label = "fit"]
"model(0)$0" -> "y_train(0)$0" [label = "fit"]
"model(0)$0" -> "tr_ind(0)$0" [label = "fit"]
"0.5(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "appears"]
"model(0)$0" -> "0.5(0)" [label = "fit"]
"oof_preds(0)$1" -> "model(0)$0" [label = "Add"]
"oof_preds(0)$1" -> "oof_preds(0)$0" [label = "Add"]
"oof_preds(0)$1" -> "X_train(0)$1" [label = "Add"]
"oof_preds(0)$1" -> "oof_preds(0)$0" [label = "Add"]
"oof_preds(0)$1" -> "val_ind(0)$0" [label = "Add"]
"oof_preds(0)$1" -> "oof_preds(0)$0" [label = "Add"]
"oof_preds(0)$1" -> "0(0)" [label = "Add"]
"oof_preds(0)$1" -> "oof_preds(0)$0" [label = "Add"]
"test_preds(0)$1" -> "model(0)$0" [label = "Add"]
"test_preds(0)$1" -> "test_preds(0)$0" [label = "Add"]
"test_preds(0)$1" -> "X_test(0)$1" [label = "Add"]
"test_preds(0)$1" -> "test_preds(0)$0" [label = "Add"]
"test_preds(0)$1" -> "0(0)" [label = "Add"]
"test_preds(0)$1" -> "test_preds(0)$0" [label = "Add"]
"test_preds(0)$2" -> "5(0)" [label = "Div"]
"test_preds(0)$2" -> "test_preds(0)$1" [label = "Div"]
"sklearn.metrics" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "import"]
"roc_auc_score" -> "sklearn.metrics" [label = "import"]
"roc_auc_score(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "appears"]
"roc_auc_score(0)" -> "roc_auc_score" [label = "assign"]
"roc_auc_score[0]" -> "y_train(0)$0" [label = "roc_auc_score"]
"roc_auc_score[1]" -> "0.5(0)" [label = "roc_auc_score"]
"roc_auc_score[2]" -> "oof_preds(0)$1" [label = "roc_auc_score"]
"submission(0)$0" -> "pd(0)" [label = "read_csv"]
"../input/jigsaw-unintended-bias-in-toxicity-classification/sample_submission.csv(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "appears"]
"submission(0)$0" -> "../input/jigsaw-unintended-bias-in-toxicity-classification/sample_submission.csv(0)" [label = "read_csv"]
"submission(0)$0" -> "id(0)" [label = "read_csv"]
"submission(0)$1" -> "submission(0)$0" [label = "assign"]
"submission(0)$1" -> "test_preds(0)$2" [label = "assign"]
"submission(0)$2" -> "submission(0)$1" [label = "reset_index"]
"submission(0)$3" -> "submission(0)$2" [label = "head"]
"submission(0)$4" -> "submission(0)$3" [label = "to_csv"]
"submission.csv(0)" -> "keras-baseline-lstm-attention-5-fold.ipynb" [label = "appears"]
"submission(0)$4" -> "submission.csv(0)" [label = "to_csv"]
}