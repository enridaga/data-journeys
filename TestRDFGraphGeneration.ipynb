{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rdflib in ./dj-py3.9/lib/python3.9/site-packages (5.0.0)\n",
      "Requirement already satisfied: pygraphviz in ./dj-py3.9/lib/python3.9/site-packages (1.6)\n",
      "Requirement already satisfied: pyparsing in ./dj-py3.9/lib/python3.9/site-packages (from rdflib) (2.4.7)\n",
      "Requirement already satisfied: isodate in ./dj-py3.9/lib/python3.9/site-packages (from rdflib) (0.6.0)\n",
      "Requirement already satisfied: six in ./dj-py3.9/lib/python3.9/site-packages (from rdflib) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the '/Users/ed4565/Development/data-journeys/dj-py3.9/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install rdflib pygraphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import networkx.drawing, networkx.drawing.nx_agraph as ag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "import pandas as pd\n",
      "\n",
      "    \n",
      "\n",
      "# Load data\n",
      "\n",
      "melbourne_file_path = '../input/melbourne-housing-snapshot/melb_data.csv'\n",
      "\n",
      "melbourne_data = pd.read_csv(melbourne_file_path) \n",
      "\n",
      "# Filter rows with missing values\n",
      "\n",
      "melbourne_data = melbourne_data.dropna(axis=0)\n",
      "\n",
      "# Choose target and features\n",
      "\n",
      "y = melbourne_data.Price\n",
      "\n",
      "melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'BuildingArea', \n",
      "\n",
      "                        'YearBuilt', 'Lattitude', 'Longtitude']\n",
      "\n",
      "X = melbourne_data[melbourne_features]\n",
      "\n",
      "\n",
      "\n",
      "from sklearn.model_selection import train_test_split\n",
      "\n",
      "\n",
      "\n",
      "# split data into training and validation data, for both features and target\n",
      "\n",
      "# The split is based on a random number generator. Supplying a numeric value to\n",
      "\n",
      "# the random_state argument guarantees we get the same split every time we\n",
      "\n",
      "# run this script.\n",
      "\n",
      "train_X, val_X, train_y, val_y = train_test_split(X, y,random_state = 0)\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "\n",
      "from sklearn.metrics import mean_absolute_error\n",
      "\n",
      "\n",
      "\n",
      "forest_model = RandomForestRegressor(random_state=1)\n",
      "\n",
      "forest_model.fit(train_X, train_y)\n",
      "\n",
      "melb_preds = forest_model.predict(val_X)\n",
      "\n",
      "print(mean_absolute_error(val_y, melb_preds))\n",
      "\n",
      "<ast.Expr object at 0x132abebe0> ['print', 'mean_absolute_error', 'val_y', 'melb_preds']\n",
      "strict digraph \"\" {\n",
      "\tpandas -> \"sources/random-forests\"\t[label=importedBy];\n",
      "\t\"pd(0)\" -> pandas\t[label=assignedFrom];\n",
      "\t\"pd(0)\" -> \"sources/random-forests\"\t[label=appearsIn];\n",
      "\t\"../input/melbourne-housing-snapshot/melb_data.csv(0)\" -> \"sources/random-forests\"\t[label=appearsIn];\n",
      "\t\"melbourne_file_path(0)$0\" -> \"../input/melbourne-housing-snapshot/melb_data.csv(0)\"\t[label=assignedFrom];\n",
      "\t\"melbourne_data(0)$0\" -> \"pd(0)\"\t[label=read_csv];\n",
      "\t\"melbourne_data(0)$0\" -> \"melbourne_file_path(0)$0\"\t[label=read_csv];\n",
      "\t\"melbourne_data(0)$1\" -> \"melbourne_data(0)$0\"\t[label=dropna];\n",
      "\t\"melbourne_data(0)$1\" -> \"0(0)\"\t[label=dropna];\n",
      "\t\"0(0)\" -> \"sources/random-forests\"\t[label=appearsIn];\n",
      "\t\"y(0)$0\" -> \"melbourne_data(0)$1\"\t[label=assignedFrom];\n",
      "\t\"[<ast.Constant object at 0x132abfa90>, <ast.Constant object at 0x132abfa60>, <ast.Constant object at 0x132abfa30>, <ast.Constant \\\n",
      "object at 0x132abfa00>, <ast.Constant object at 0x132abf9d0>, <ast.Constant object at 0x132abf9a0>, <ast.Constant object at 0x132abf970>](\\\n",
      "0)\" -> \"sources/random-forests\"\t[label=appearsIn];\n",
      "\t\"melbourne_features(0)$0\" -> \"[<ast.Constant object at 0x132abfa90>, <ast.Constant object at 0x132abfa60>, <ast.Constant object at 0x132abfa30>, <ast.Constant \\\n",
      "object at 0x132abfa00>, <ast.Constant object at 0x132abf9d0>, <ast.Constant object at 0x132abf9a0>, <ast.Constant object at 0x132abf970>](\\\n",
      "0)\"\t[label=assignedFrom];\n",
      "\t\"X(0)$0\" -> \"melbourne_data(0)$1\"\t[label=assignedFrom];\n",
      "\t\"X(0)$0\" -> \"melbourne_features(0)$0\"\t[label=assignedFrom];\n",
      "\t\"sklearn.model_selection\" -> \"sources/random-forests\"\t[label=importedBy];\n",
      "\ttrain_test_split -> \"sklearn.model_selection\"\t[label=importedBy];\n",
      "\t\"train_test_split(0)\" -> \"sources/random-forests\"\t[label=appearsIn];\n",
      "\t\"train_test_split(0)\" -> train_test_split\t[label=assignedFrom];\n",
      "\t\"train_X(0)$0\" -> \"0(0)\"\t[label=train_test_split];\n",
      "\t\"train_X(0)$0\" -> \"y(0)$0\"\t[label=train_test_split];\n",
      "\t\"train_X(0)$0\" -> \"X(0)$0\"\t[label=train_test_split];\n",
      "\t\"val_X(0)$0\" -> \"0(0)\"\t[label=train_test_split];\n",
      "\t\"val_X(0)$0\" -> \"y(0)$0\"\t[label=train_test_split];\n",
      "\t\"val_X(0)$0\" -> \"X(0)$0\"\t[label=train_test_split];\n",
      "\t\"train_y(0)$0\" -> \"0(0)\"\t[label=train_test_split];\n",
      "\t\"train_y(0)$0\" -> \"y(0)$0\"\t[label=train_test_split];\n",
      "\t\"train_y(0)$0\" -> \"X(0)$0\"\t[label=train_test_split];\n",
      "\t\"val_y(0)$0\" -> \"0(0)\"\t[label=train_test_split];\n",
      "\t\"val_y(0)$0\" -> \"y(0)$0\"\t[label=train_test_split];\n",
      "\t\"val_y(0)$0\" -> \"X(0)$0\"\t[label=train_test_split];\n",
      "\t\"sklearn.ensemble\" -> \"sources/random-forests\"\t[label=importedBy];\n",
      "\tRandomForestRegressor -> \"sklearn.ensemble\"\t[label=importedBy];\n",
      "\t\"RandomForestRegressor(0)\" -> \"sources/random-forests\"\t[label=appearsIn];\n",
      "\t\"RandomForestRegressor(0)\" -> RandomForestRegressor\t[label=assignedFrom];\n",
      "\t\"sklearn.metrics\" -> \"sources/random-forests\"\t[label=importedBy];\n",
      "\tmean_absolute_error -> \"sklearn.metrics\"\t[label=importedBy];\n",
      "\t\"mean_absolute_error(0)\" -> \"sources/random-forests\"\t[label=appearsIn];\n",
      "\t\"mean_absolute_error(0)\" -> mean_absolute_error\t[label=assignedFrom];\n",
      "\t\"1(0)\" -> \"sources/random-forests\"\t[label=appearsIn];\n",
      "\t\"forest_model(0)$0\" -> \"1(0)\"\t[label=RandomForestRegressor];\n",
      "\t\"forest_model(0)$1\" -> \"train_X(0)$0\"\t[label=fit];\n",
      "\t\"forest_model(0)$1\" -> \"train_y(0)$0\"\t[label=fit];\n",
      "\t\"forest_model(0)$1\" -> \"forest_model(0)$0\"\t[label=fit];\n",
      "\t\"melb_preds(0)$0\" -> \"val_X(0)$0\"\t[label=predict];\n",
      "\t\"melb_preds(0)$0\" -> \"forest_model(0)$1\"\t[label=predict];\n",
      "\t\"print[53/0]\" -> \"val_y(0)$0\"\t[label=print];\n",
      "\t\"print[53/0]\" -> \"mean_absolute_error(0)\"\t[label=print];\n",
      "\t\"print[53/0]\" -> \"melb_preds(0)$0\"\t[label=print];\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import datajourney as DJ\n",
    "#f=\"simple-notebook.py\"\n",
    "f=\"sources/random-forests.py\"\n",
    "src = open(f, \"r\").read()\n",
    "print(src)\n",
    "# Generate digraph from source\n",
    "collector = DJ.FindDependencies(f[:-3])\n",
    "collector.collect(src)\n",
    "gs = collector.getStringCollected()\n",
    "print(gs)\n",
    "o = open( f[:-2] + \"digraph\", \"w\")\n",
    "o.write(gs)\n",
    "o.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@prefix dj: <http://purl.org/dj/> .\n",
      "@prefix k: <http://purl.org/dj/kaggle/> .\n",
      "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
      "\n",
      "<http://purl.org/dj/kaggle/sources/random-forests> a k:Notebook .\n",
      "\n",
      "<http://purl.org/dj/kaggle/sources/random-forests#1322649418> rdfs:label \"train_test_split(0)\" ;\n",
      "    dj:appearsIn <http://purl.org/dj/kaggle/sources/random-forests#1717504232> ;\n",
      "    dj:assignedFrom <http://purl.org/dj/python/lib/964298441> .\n",
      "\n",
      "<http://purl.org/dj/kaggle/sources/random-forests#1989675282> rdfs:label \"RandomForestRegressor(0)\" ;\n",
      "    dj:appearsIn <http://purl.org/dj/kaggle/sources/random-forests#1717504232> ;\n",
      "    dj:assignedFrom <http://purl.org/dj/python/lib/1541671057> .\n",
      "\n",
      "<http://purl.org/dj/kaggle/sources/random-forests#417137581> rdfs:label \"print[53/0]\" ;\n",
      "    dj:print <http://purl.org/dj/kaggle/sources/random-forests#1722550378>,\n",
      "        <http://purl.org/dj/kaggle/sources/random-forests#324600561>,\n",
      "        <http://purl.org/dj/kaggle/sources/random-forests#764675315> .\n",
      "\n",
      "<http://purl.org/dj/kaggle/sources/random-forests#1013319129> rdfs:label \"forest_model(0)$0\" ;\n",
      "    dj:RandomForestRegressor <http://purl.org/dj/kaggle/sources/random-forests#29950131> .\n",
      "\n",
      "<http://purl.org/dj/kaggle/sources/random-forests#1013384666> rdfs:label \"forest_model(0)$1\" ;\n",
      "    dj:fit <http://purl.org/dj/kaggle/sources/random-forests#1013319129>,\n",
      "        <http://purl.org/dj/kaggle/sources/random-forests#477168555>,\n",
      "        <http://purl.org/dj/kaggle/sources/random-forests#490144716> .\n",
      "\n",
      "<http://purl.org/dj/kaggle/sources/random-forests#1257178776> rdfs:label \"melbourne_data(0)$0\" ;\n",
      "    dj:read_csv <http://purl.org/dj/kaggle/sources/random-forests#2019035306>,\n",
      "        <http://purl.org/dj/kaggle/sources/random-forests#80085334> .\n",
      "\n",
      "<http://purl.org/dj/kaggle/sources/random-forests#1722550378> rdfs:label \"mean_absolute_error(0)\" ;\n",
      "    dj:appearsIn <http://purl.org/dj/kaggle/sources/random-forests#1717504232> ;\n",
      "    dj:assignedFrom <http://purl.org/dj/python/lib/1307576297> .\n",
      "\n",
      "<http://purl.org/dj/kaggle/sources/random-forests#1867778141> rdfs:label \"melbourne_features(0)$0\" ;\n",
      "    dj:assignedFrom <http://purl.org/dj/kaggle/sources/random-forests#3353958250> .\n",
      "\n",
      "<http://purl.org/dj/kaggle/sources/random-forests#2019035306> rdfs:label \"melbourne_file_path(0)$0\" ;\n",
      "    dj:assignedFrom <http://purl.org/dj/kaggle/sources/random-forests#58004286> .\n",
      "\n",
      "<http://purl.org/dj/kaggle/sources/random-forests#29950131> rdfs:label \"1(0)\" ;\n",
      "    dj:appearsIn <http://purl.org/dj/kaggle/sources/random-forests#1717504232> .\n",
      "\n",
      "<http://purl.org/dj/kaggle/sources/random-forests#311624400> rdfs:label \"val_X(0)$0\" ;\n",
      "    dj:train_test_split <http://purl.org/dj/kaggle/sources/random-forests#29687986>,\n",
      "        <http://purl.org/dj/kaggle/sources/random-forests#76611886>,\n",
      "        <http://purl.org/dj/kaggle/sources/random-forests#89588047> .\n",
      "\n",
      "<http://purl.org/dj/kaggle/sources/random-forests#324600561> rdfs:label \"val_y(0)$0\" ;\n",
      "    dj:train_test_split <http://purl.org/dj/kaggle/sources/random-forests#29687986>,\n",
      "        <http://purl.org/dj/kaggle/sources/random-forests#76611886>,\n",
      "        <http://purl.org/dj/kaggle/sources/random-forests#89588047> .\n",
      "\n",
      "<http://purl.org/dj/kaggle/sources/random-forests#3353958250> rdfs:label \"[<ast.Constant object at 0x132abfa90>, <ast.Constant object at 0x132abfa60>, <ast.Constant object at 0x132abfa30>, <ast.Constant object at 0x132abfa00>, <ast.Constant object at 0x132abf9d0>, <ast.Constant object at 0x132abf9a0>, <ast.Constant object at 0x132abf970>](0)\" ;\n",
      "    dj:appearsIn <http://purl.org/dj/kaggle/sources/random-forests#1717504232> .\n",
      "\n",
      "<http://purl.org/dj/kaggle/sources/random-forests#477168555> rdfs:label \"train_X(0)$0\" ;\n",
      "    dj:train_test_split <http://purl.org/dj/kaggle/sources/random-forests#29687986>,\n",
      "        <http://purl.org/dj/kaggle/sources/random-forests#76611886>,\n",
      "        <http://purl.org/dj/kaggle/sources/random-forests#89588047> .\n",
      "\n",
      "<http://purl.org/dj/kaggle/sources/random-forests#490144716> rdfs:label \"train_y(0)$0\" ;\n",
      "    dj:train_test_split <http://purl.org/dj/kaggle/sources/random-forests#29687986>,\n",
      "        <http://purl.org/dj/kaggle/sources/random-forests#76611886>,\n",
      "        <http://purl.org/dj/kaggle/sources/random-forests#89588047> .\n",
      "\n",
      "<http://purl.org/dj/kaggle/sources/random-forests#58004286> rdfs:label \"../input/melbourne-housing-snapshot/melb_data.csv(0)\" ;\n",
      "    dj:appearsIn <http://purl.org/dj/kaggle/sources/random-forests#1717504232> .\n",
      "\n",
      "<http://purl.org/dj/kaggle/sources/random-forests#764675315> rdfs:label \"melb_preds(0)$0\" ;\n",
      "    dj:predict <http://purl.org/dj/kaggle/sources/random-forests#1013384666>,\n",
      "        <http://purl.org/dj/kaggle/sources/random-forests#311624400> .\n",
      "\n",
      "<http://purl.org/dj/kaggle/sources/random-forests#80085334> rdfs:label \"pd(0)\" ;\n",
      "    dj:appearsIn <http://purl.org/dj/kaggle/sources/random-forests#1717504232> ;\n",
      "    dj:assignedFrom <http://purl.org/dj/python/lib/144966264> .\n",
      "\n",
      "<http://purl.org/dj/python/lib/1307576297> rdfs:label \"mean_absolute_error\" ;\n",
      "    dj:importedBy <http://purl.org/dj/python/lib/816055830> .\n",
      "\n",
      "<http://purl.org/dj/python/lib/144966264> rdfs:label \"pandas\" ;\n",
      "    dj:importedBy <http://purl.org/dj/kaggle/sources/random-forests#1717504232> .\n",
      "\n",
      "<http://purl.org/dj/python/lib/1541671057> rdfs:label \"RandomForestRegressor\" ;\n",
      "    dj:importedBy <http://purl.org/dj/python/lib/919996010> .\n",
      "\n",
      "<http://purl.org/dj/python/lib/1865222485> rdfs:label \"sklearn.model_selection\" ;\n",
      "    dj:importedBy <http://purl.org/dj/kaggle/sources/random-forests#1717504232> .\n",
      "\n",
      "<http://purl.org/dj/python/lib/816055830> rdfs:label \"sklearn.metrics\" ;\n",
      "    dj:importedBy <http://purl.org/dj/kaggle/sources/random-forests#1717504232> .\n",
      "\n",
      "<http://purl.org/dj/python/lib/919996010> rdfs:label \"sklearn.ensemble\" ;\n",
      "    dj:importedBy <http://purl.org/dj/kaggle/sources/random-forests#1717504232> .\n",
      "\n",
      "<http://purl.org/dj/python/lib/964298441> rdfs:label \"train_test_split\" ;\n",
      "    dj:importedBy <http://purl.org/dj/python/lib/1865222485> .\n",
      "\n",
      "<http://purl.org/dj/kaggle/sources/random-forests#1257244313> rdfs:label \"melbourne_data(0)$1\" ;\n",
      "    dj:dropna <http://purl.org/dj/kaggle/sources/random-forests#1257178776>,\n",
      "        <http://purl.org/dj/kaggle/sources/random-forests#29687986> .\n",
      "\n",
      "<http://purl.org/dj/kaggle/sources/random-forests#76611886> rdfs:label \"X(0)$0\" ;\n",
      "    dj:assignedFrom <http://purl.org/dj/kaggle/sources/random-forests#1257244313>,\n",
      "        <http://purl.org/dj/kaggle/sources/random-forests#1867778141> .\n",
      "\n",
      "<http://purl.org/dj/kaggle/sources/random-forests#89588047> rdfs:label \"y(0)$0\" ;\n",
      "    dj:assignedFrom <http://purl.org/dj/kaggle/sources/random-forests#1257244313> .\n",
      "\n",
      "<http://purl.org/dj/kaggle/sources/random-forests#29687986> rdfs:label \"0(0)\" ;\n",
      "    dj:appearsIn <http://purl.org/dj/kaggle/sources/random-forests#1717504232> .\n",
      "\n",
      "<http://purl.org/dj/kaggle/sources/random-forests#1717504232> rdfs:label \"sources/random-forests\" .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # Read digraph \n",
    "g = ag.read_dot( f[:-2] + \"digraph\")\n",
    "\n",
    "\n",
    "# # Generate RDF\n",
    "ns = f[:-3]\n",
    "rdfg = DJ.toRDF(ns, g)\n",
    "s=rdfg.serialize(format=\"turtle\").decode(\"utf-8\")\n",
    "\n",
    "o = open( f[:-2] + \"ttl\", \"w\")\n",
    "o.write(s)\n",
    "o.close()\n",
    "\n",
    "# Read and print ttl\n",
    "o = open( f[:-2] + \"ttl\", \"r\" )\n",
    "print(o.read())\n",
    "o.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'images/sources/random-forests.png'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from graphviz import Source\n",
    "src = Source(gs)\n",
    "src.format = \"png\"\n",
    "src.render(\"images/\" + f[:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: ieee-gb-2-make-amount-useful-again-Copy1.digraph\n",
      "read dot\n",
      "ERROR Exception: decoding to str: need a bytes-like object, NoneType found [ieee-gb-2-make-amount-useful-again-Copy1.digraph]\n",
      "1  are broken\n"
     ]
    }
   ],
   "source": [
    "import rdflib\n",
    "import datajourney as DJ\n",
    "import networkx.drawing, networkx.drawing.nx_agraph as ag\n",
    "import pygraphviz\n",
    "\n",
    "indir = \"./sources/\"\n",
    "graphsdir = \"./test/\"\n",
    "\n",
    "# Test noebooks with errors\n",
    "n = 'ieee-gb-2-make-amount-useful-again-Copy1.digraph' # digraphs broken when '%' in node name\n",
    "\n",
    "graph_files = [n]\n",
    "rdf_all_graph = rdflib.Graph()\n",
    "broken=[]\n",
    "for f in graph_files:\n",
    "    with open(graphsdir + f) as notebook:\n",
    "        print(\"Processing: {0}\".format(f))\n",
    "        try:\n",
    "            print('read dot')\n",
    "            stri = \" \".join([l for l in notebook]) \n",
    "            stri.replace\n",
    "            g = ag.from_agraph(pygraphviz.AGraph(stri))\n",
    "            print('done')\n",
    "            n = f[:-7]\n",
    "            rdfg = DJ.toRDF2(n[:-1], g)\n",
    "            rdf_all_graph = rdf_all_graph + rdfg\n",
    "        except Exception as err:\n",
    "            print(\"ERROR Exception: {0} [{1}]\".format(err, f))\n",
    "            broken.append(f)\n",
    "# Remove broken digraph files from the input\n",
    "print(str(len(broken)), \" are broken\")\n",
    "graph_files = [f for f in graph_files if f not in broken]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes: [1, 2, '\\\\%Y - \\\\%M - \\\\%S']\n",
      "edges: [(1, 2), ('\\\\%Y - \\\\%M - \\\\%S', 2)]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'outdir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-14d572fc50fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nodes:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"edges:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutdir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"___percent.\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"digraph\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_agraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dot'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'outdir' is not defined"
     ]
    }
   ],
   "source": [
    "# Build a digraph manually\n",
    "import networkx as nx\n",
    "dg = nx.DiGraph()\n",
    "dg.add_edge(1, 2, label=\"import\")\n",
    "dg.add_edge(\"\\%Y - \\%M - \\%S\", 2, label=\"import\")\n",
    "print(\"nodes:\", str(dg.nodes))\n",
    "print(\"edges:\", str(dg.edges))\n",
    "ag.write_dot(dg, outdir + \"___percent.\" + \"digraph\")\n",
    "tag = ag.to_agraph(dg)\n",
    "tag.layout(prog='dot')\n",
    "stri = tag.draw(format='dot')\n",
    "print(stri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the DiGraph method\n",
    "\n",
    "#!/usr/local/bin/python3.7\n",
    "import datajourney as DJ\n",
    "import json as J\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from graphviz import Source\n",
    "import pygraphviz\n",
    "import networkx.drawing, networkx.drawing.nx_agraph as ag\n",
    "\n",
    "outdir=\"test/\"\n",
    "imgdir=\"images/\"\n",
    "indir=\"sources/\"\n",
    "\n",
    "f=\"ieee-gb-2-make-amount-useful-again.py\"\n",
    "files = [\n",
    "    \"1st-place-reproduction-10feats-dev\",\n",
    "\"a-beginner-guide-for-sale-data-prediction\",\n",
    "\"a-complete-ml-pipeline-fast-ai\",\n",
    "\"a-detailed-regression-guide-with-house-pricing\",\n",
    "\"a-quick-simple-eda\",\n",
    "\"a-visual-and-insightful-journey-donorschoose\",\n",
    "\"airbnb-the-amsterdam-story-with-interactive-maps\",\n",
    "\"all-that-you-need-to-know-about-the-android-market\",\n",
    "\"almost-complete-feature-engineering-ieee-data\",\n",
    "\"an-interactive-deep-dive-into-survey-results\",\n",
    "\"analyzing-soccer-player-faces\",\n",
    "\"aptos-eye-preprocessing-in-diabetic-retinopathy\",\n",
    "\"ashrae-divide-and-conquer\",\n",
    "\"ashrae-energy-prediction-using-stratified-kfold\",\n",
    "\"ashrae-great-energy-predictor-iii-eda-model\",\n",
    "\"ashrae-half-and-half\",\n",
    "\"ashrae-kfold-lightgbm-without-leak-1-08\",\n",
    "\"ashrae-stacked-regression-lasso-ridge-lgbm\",\n",
    "\"automated-feature-engineering-basics\",\n",
    "\"baseline-u-net-model-part-1\",\n",
    "\"beginner-s-tutorial-python\",\n",
    "\"benchmark\",\n",
    "\"bert-and-bidaf\",\n",
    "\"bert-the-spam-detector-that-uses-just-10-words\",\n",
    "\"bird-eye-view-of-two-sigma-nn-approach\",\n",
    "\"black-friday-data-exploration\",\n",
    "\"bond-calculaltion-lb-0-82\",\n",
    "\"bond-calculation-lb-0-82\",\n",
    "\"breaking-lb-fresh-start\",\n",
    "\"breastcancer\",\n",
    "\"brute-force-feature-engineering\",\n",
    "\"cannabis-species-eda-and-models-pipeline\",\n",
    "\"careervillage-org-recommendation-engine\",\n",
    "\"cis-fraud-detection-visualize-feature-engineering\",\n",
    "\"cleaning-up-market-data-errors-and-stock-splits\",\n",
    "\"comprehensive-python-and-d3-js-favorita-analytics\",\n",
    "\"cp2410-assignment1-ryanwong\",\n",
    "\"credit-fraud-dealing-with-imbalanced-datasets\",\n",
    "\"creditcard-fraud-analysis\",\n",
    "\"data-cleaning-challenge-parsing-dates\",\n",
    "\"data-mining-project\",\n",
    "\"data-preparation-exploration\",\n",
    "\"dataset-preprocessing\",\n",
    "\"decision-boundaries-visualised-via-python-plotly\",\n",
    "\"dog-breed-pretrained-keras-models-lb-0-3\",\n",
    "\"ds-bowl-start-here-a-gentle-introduction\",\n",
    "\"dynamics-of-new-york-city-animation\",\n",
    "\"eachtype\",\n",
    "\"eda-and-models\",\n",
    "\"eda-ensemble-model-top-10-percentile\",\n",
    "\"eda-feat-engineering-encode-conquer\",\n",
    "\"eda-understanding-the-dataset-with-3d-plots\",\n",
    "\"eda-weird-images-with-new-updates\",\n",
    "\"efficientnetb5-with-keras-aptos-2019\",\n",
    "\"elo-eda-and-models\",\n",
    "\"end-to-end-project-with-python\",\n",
    "\"exploration-to-quench-chennai-s-thirst\",\n",
    "\"exploratory-analysis-and-predictions\",\n",
    "\"exploratory-study-on-feature-selection\",\n",
    "\"exploratory-study-on-ml-algorithms\",\n",
    "\"extensive-usa-youtube-eda\",\n",
    "\"fake-detect-basic\",\n",
    "\"fast-pdf-calculation-with-correlation-matrix\",\n",
    "\"feature-ranking-rfe-random-forest-linear-models\",\n",
    "\"feature-selection-and-data-visualization\",\n",
    "\"fraud-complete-eda\",\n",
    "\"how-to-get-upvotes-for-a-kernel-on-kaggle\",\n",
    "\"how-to-preprocessing-for-glove-part1-eda\",\n",
    "\"how-top-lb-got-their-score-use-titanic-to-learn\",\n",
    "\"humpback-whale-id-data-and-aug-exploration\",\n",
    "\"ieee-cv-options\",\n",
    "\"ieee-fe-with-some-eda\",\n",
    "\"ieee-gb-2-make-amount-useful-again\",\n",
    "\"ieee-lgbm-with-groupkfold-cv\",\n",
    "\"ieee-transaction-columns-reference\",\n",
    "\"imdb-review-deep-model-94-89-accuracy\",\n",
    "\"improve-your-score-with-some-text-preprocessing\",\n",
    "\"improve-your-score-with-text-preprocessing-v2\",\n",
    "\"insightful-eda-modeling-lgbm-hyperopt\",\n",
    "\"instacart-simple-data-exploration\",\n",
    "\"interactive-d3-js-visualisations-in-kaggle-kernels\",\n",
    "\"introduction-to-feature-selection\",\n",
    "\"introduction-to-manual-feature-engineering\",\n",
    "\"introduction-to-manual-feature-engineering-p2\",\n",
    "\"jiazhen-to-armamut-via-gurchetan1000-0-56\",\n",
    "\"kannada-mnist\",\n",
    "\"keras-nn-with-embeddings-for-cat-features-1-15\",\n",
    "\"keras-unet-with-eda\",\n",
    "\"light-gbm-with-complete-eda\",\n",
    "\"lstm-sentiment-analysis-keras\",\n",
    "\"mask-rcnn-detailed-starter-code\",\n",
    "\"model-stacking-feature-engineering-and-eda\",\n",
    "\"molecular-properties-eda-and-models\",\n",
    "\"more-text-cleaning-to-increase-word-coverage\",\n",
    "\"neural-network-with-mae-objective-0-01381\",\n",
    "\"ny-stock-price-prediction-rnn-lstm-gru\",\n",
    "\"nyct-from-a-to-z-with-xgboost-tutorial\",\n",
    "\"psychology-of-a-professional-athlete\",\n",
    "\"public-version-text-cleaning-vocab-65\",\n",
    "\"python-target-encoding-for-categorical-features\",\n",
    "\"quickdraw-baseline-lstm-reading-and-submission\",\n",
    "\"recommender-systems-in-python-101\",\n",
    "\"reducing-dataframe-memory-size-by-65\",\n",
    "\"reducing-memory-size-for-ieee\",\n",
    "\"road-to-viz-expert-1-unusual-tools\",\n",
    "\"rsna-ih-detection-eda\",\n",
    "\"russia-usa-india-and-other-countries\",\n",
    "\"s-p-500-time-series-forecasting-with-prophet\",\n",
    "\"santa-finances-a-closer-look-at-the-costs\",\n",
    "\"santander-customer-transaction-eda\",\n",
    "\"santander-lightgbm-baseline-lb-0-899\",\n",
    "\"save-the-energy-for-the-future-3-predictions\",\n",
    "\"sign-language-mnist\",\n",
    "\"simple-eda-text-preprocessing-jigsaw\",\n",
    "\"simple-exploration-notebook-ashrae\",\n",
    "\"simple-exploratory-data-analysis-passnyc\",\n",
    "\"simple-lgbm-solution\",\n",
    "\"simple-lstm-pytorch-version\",\n",
    "\"simple-lstm-with-identity-parameters-fastai\",\n",
    "\"simple-neural-net-for-time-series-classification\",\n",
    "\"simple-tutorial-for-beginners\",\n",
    "\"spending-for-ms-in-data-science-worth-it\",\n",
    "\"spooky-nlp-and-topic-modelling-tutorial\",\n",
    "\"stacking-house-prices-walkthrough-to-top-5\",\n",
    "\"strategy-evaluation-what-helps-and-by-how-much\",\n",
    "\"ted-data-analysis\",\n",
    "\"the-hitchhiker-s-guide-to-the-kaggle\",\n",
    "\"the-perfect-score-script\",\n",
    "\"time-series-analysis\",\n",
    "\"time-series-basics-exploring-traditional-ts\",\n",
    "\"titanic-random-forest-82-78\",\n",
    "\"titanic-tutorial\",\n",
    "\"top-3-nlp-libraries-tutorial-nltk-spacy-gensim\",\n",
    "\"topic-7-unsupervised-learning-pca-and-clustering\",\n",
    "\"training-mask-r-cnn-to-be-a-fashionista-lb-0-07\",\n",
    "\"transfer-learning-with-vgg-16-cnn-aug-lb-0-1712\",\n",
    "\"two-sigma-renthop-eda\",\n",
    "\"u-net-model-with-submission\",\n",
    "\"uncover-target-correlations-with-bernoulli-mixture\",\n",
    "\"unet-starter-kernel-pytorch-lb-0-88\",\n",
    "\"unet-with-resnet34-encoder-pytorch\",\n",
    "\"user-data-exploration\",\n",
    "\"using-meta-features-to-improve-model\",\n",
    "\"validation-feature-selection-interpretation-etc\",\n",
    "\"where-do-the-robots-drive\",\n",
    "\"winning-solutions-of-kaggle-competitions\",\n",
    "\"yet-another-deepfake-starter\"\n",
    "]\n",
    "for f in  files:\n",
    "    src = open(indir + f + \".py\", \"r\").read()\n",
    "    # print(src)\n",
    "    collector = DJ.FindDependencies(f[:-3])\n",
    "    collector.collect(src)\n",
    "    # Method 1\n",
    "    dg = collector.getDiGraph()\n",
    "    ag.write_dot(dg, outdir + f[:-3] + \"._1_\" + \".digraph\")\n",
    "    \n",
    "    # Method 2\n",
    "    stri = collector.getStringCollected()\n",
    "    o = open(outdir + f[:-3] + \"._2_\" + \".digraph\", \"w\")\n",
    "    o.write(stri)\n",
    "    \n",
    "    # Method Old\n",
    "    stri = collector.getStringCollected_Old()\n",
    "    o = open(outdir + f[:-3] + \"._0_\" + \".digraph\", \"w\")\n",
    "    o.write(stri)\n",
    "\n",
    "    \n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
