digraph "" {
	numpy -> "text-modelling-in-pytorch.ipynb"	[label=importedBy];
	"np(0)" -> numpy	[label=assignedFrom];
	"np(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	pandas -> "text-modelling-in-pytorch.ipynb"	[label=importedBy];
	"pd(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"pd(0)" -> pandas	[label=assignedFrom];
	"matplotlib.pyplot" -> "text-modelling-in-pytorch.ipynb"	[label=importedBy];
	"plt(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"plt(0)" -> "matplotlib.pyplot"	[label=assignedFrom];
	seaborn -> "text-modelling-in-pytorch.ipynb"	[label=importedBy];
	"sns(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"sns(0)" -> seaborn	[label=assignedFrom];
	"nltk.tokenize" -> "text-modelling-in-pytorch.ipynb"	[label=importedBy];
	TweetTokenizer -> "nltk.tokenize"	[label=importedBy];
	"TweetTokenizer(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"TweetTokenizer(0)" -> TweetTokenizer	[label=assignedFrom];
	datetime -> "text-modelling-in-pytorch.ipynb"	[label=importedBy];
	"datetime(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"datetime(0)" -> datetime	[label=assignedFrom];
	lightgbm -> "text-modelling-in-pytorch.ipynb"	[label=importedBy];
	"lgb(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"lgb(0)" -> lightgbm	[label=assignedFrom];
	scipy -> "text-modelling-in-pytorch.ipynb"	[label=importedBy];
	stats -> scipy	[label=importedBy];
	"stats(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"stats(0)" -> stats	[label=assignedFrom];
	"scipy.sparse" -> "text-modelling-in-pytorch.ipynb"	[label=importedBy];
	hstack -> "scipy.sparse"	[label=importedBy];
	"hstack(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"hstack(0)" -> hstack	[label=assignedFrom];
	csr_matrix -> "scipy.sparse"	[label=importedBy];
	"csr_matrix(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"csr_matrix(0)" -> csr_matrix	[label=assignedFrom];
	"sklearn.model_selection" -> "text-modelling-in-pytorch.ipynb"	[label=importedBy];
	train_test_split -> "sklearn.model_selection"	[label=importedBy];
	"train_test_split(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"train_test_split(0)" -> train_test_split	[label=assignedFrom];
	cross_val_score -> "sklearn.model_selection"	[label=importedBy];
	"cross_val_score(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"cross_val_score(0)" -> cross_val_score	[label=assignedFrom];
	wordcloud -> "text-modelling-in-pytorch.ipynb"	[label=importedBy];
	WordCloud -> wordcloud	[label=importedBy];
	"WordCloud(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"WordCloud(0)" -> WordCloud	[label=assignedFrom];
	collections -> "text-modelling-in-pytorch.ipynb"	[label=importedBy];
	Counter -> collections	[label=importedBy];
	"Counter(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"Counter(0)" -> Counter	[label=assignedFrom];
	"nltk.corpus" -> "text-modelling-in-pytorch.ipynb"	[label=importedBy];
	stopwords -> "nltk.corpus"	[label=importedBy];
	"stopwords(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"stopwords(0)" -> stopwords	[label=assignedFrom];
	"nltk.util" -> "text-modelling-in-pytorch.ipynb"	[label=importedBy];
	ngrams -> "nltk.util"	[label=importedBy];
	"ngrams(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"ngrams(0)" -> ngrams	[label=assignedFrom];
	"sklearn.feature_extraction.text" -> "text-modelling-in-pytorch.ipynb"	[label=importedBy];
	TfidfVectorizer -> "sklearn.feature_extraction.text"	[label=importedBy];
	"TfidfVectorizer(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"TfidfVectorizer(0)" -> TfidfVectorizer	[label=assignedFrom];
	"sklearn.preprocessing" -> "text-modelling-in-pytorch.ipynb"	[label=importedBy];
	StandardScaler -> "sklearn.preprocessing"	[label=importedBy];
	"StandardScaler(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"StandardScaler(0)" -> StandardScaler	[label=assignedFrom];
	"sklearn.linear_model" -> "text-modelling-in-pytorch.ipynb"	[label=importedBy];
	LogisticRegression -> "sklearn.linear_model"	[label=importedBy];
	"LogisticRegression(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"LogisticRegression(0)" -> LogisticRegression	[label=assignedFrom];
	"sklearn.svm" -> "text-modelling-in-pytorch.ipynb"	[label=importedBy];
	LinearSVC -> "sklearn.svm"	[label=importedBy];
	"LinearSVC(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"LinearSVC(0)" -> LinearSVC	[label=assignedFrom];
	"sklearn.multiclass" -> "text-modelling-in-pytorch.ipynb"	[label=importedBy];
	OneVsRestClassifier -> "sklearn.multiclass"	[label=importedBy];
	"OneVsRestClassifier(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"OneVsRestClassifier(0)" -> OneVsRestClassifier	[label=assignedFrom];
	time -> "text-modelling-in-pytorch.ipynb"	[label=importedBy];
	"time(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"time(0)" -> time	[label=assignedFrom];
	"pd(0)$0" -> "pd(0)"	[label=set_option];
	"pd(0)$0" -> "max_colwidth(0)"	[label=set_option];
	"pd(0)$0" -> "400(0)"	[label=set_option];
	"max_colwidth(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"400(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"keras.preprocessing.text" -> "text-modelling-in-pytorch.ipynb"	[label=importedBy];
	Tokenizer -> "keras.preprocessing.text"	[label=importedBy];
	"Tokenizer(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"Tokenizer(0)" -> Tokenizer	[label=assignedFrom];
	"keras.preprocessing.sequence" -> "text-modelling-in-pytorch.ipynb"	[label=importedBy];
	pad_sequences -> "keras.preprocessing.sequence"	[label=importedBy];
	"pad_sequences(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"pad_sequences(0)" -> pad_sequences	[label=assignedFrom];
	OneHotEncoder -> "sklearn.preprocessing"	[label=importedBy];
	"OneHotEncoder(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"OneHotEncoder(0)" -> OneHotEncoder	[label=assignedFrom];
	torch -> "text-modelling-in-pytorch.ipynb"	[label=importedBy];
	"torch(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"torch(0)" -> torch	[label=assignedFrom];
	"torch.nn" -> "text-modelling-in-pytorch.ipynb"	[label=importedBy];
	"nn(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"nn(0)" -> "torch.nn"	[label=assignedFrom];
	"torch.optim" -> "text-modelling-in-pytorch.ipynb"	[label=importedBy];
	"optim(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"optim(0)" -> "torch.optim"	[label=assignedFrom];
	"torch.nn.functional" -> "text-modelling-in-pytorch.ipynb"	[label=importedBy];
	"F(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"F(0)" -> "torch.nn.functional"	[label=assignedFrom];
	"torch.utils.data" -> "text-modelling-in-pytorch.ipynb"	[label=importedBy];
	Dataset -> "torch.utils.data"	[label=importedBy];
	"Dataset(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"Dataset(0)" -> Dataset	[label=assignedFrom];
	DataLoader -> "torch.utils.data"	[label=importedBy];
	"DataLoader(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"DataLoader(0)" -> DataLoader	[label=assignedFrom];
	"torch.nn.utils.rnn" -> "text-modelling-in-pytorch.ipynb"	[label=importedBy];
	pack_padded_sequence -> "torch.nn.utils.rnn"	[label=importedBy];
	"pack_padded_sequence(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"pack_padded_sequence(0)" -> pack_padded_sequence	[label=assignedFrom];
	pad_packed_sequence -> "torch.nn.utils.rnn"	[label=importedBy];
	"pad_packed_sequence(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"pad_packed_sequence(0)" -> pad_packed_sequence	[label=assignedFrom];
	"torch.autograd" -> "text-modelling-in-pytorch.ipynb"	[label=importedBy];
	Variable -> "torch.autograd"	[label=importedBy];
	"Variable(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"Variable(0)" -> Variable	[label=assignedFrom];
	"torch.utils.data(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"torch.utils.data(0)" -> "torch.utils.data"	[label=assignedFrom];
	random -> "text-modelling-in-pytorch.ipynb"	[label=importedBy];
	"random(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"random(0)" -> random	[label=assignedFrom];
	warnings -> "text-modelling-in-pytorch.ipynb"	[label=importedBy];
	"warnings(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"warnings(0)" -> warnings	[label=assignedFrom];
	"warnings(0)$0" -> "warnings(0)"	[label=filterwarnings];
	"warnings(0)$0" -> "ignore(0)"	[label=filterwarnings];
	"ignore(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	re -> "text-modelling-in-pytorch.ipynb"	[label=importedBy];
	"re(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"re(0)" -> re	[label=assignedFrom];
	"torch.optim.lr_scheduler" -> "text-modelling-in-pytorch.ipynb"	[label=importedBy];
	StepLR -> "torch.optim.lr_scheduler"	[label=importedBy];
	"StepLR(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"StepLR(0)" -> StepLR	[label=assignedFrom];
	ReduceLROnPlateau -> "torch.optim.lr_scheduler"	[label=importedBy];
	"ReduceLROnPlateau(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"ReduceLROnPlateau(0)" -> ReduceLROnPlateau	[label=assignedFrom];
	CosineAnnealingLR -> "torch.optim.lr_scheduler"	[label=importedBy];
	"CosineAnnealingLR(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"CosineAnnealingLR(0)" -> CosineAnnealingLR	[label=assignedFrom];
	"seed(1)" -> "seed_torch[0]"	[label=_argToVar];
	"random(1)$0" -> "seed(1)"	[label=seed];
	"random(1)$0" -> "random(1)"	[label=seed];
	"os(1)$0" -> "seed(1)"	[label=str];
	"os(1)$0" -> "os(1)"	[label=str];
	"np(1)$0" -> "seed(1)"	[label=seed];
	"np(1)$0" -> "np(1)"	[label=seed];
	"torch(1)$0" -> "seed(1)"	[label=manual_seed];
	"torch(1)$0" -> "torch(1)"	[label=manual_seed];
	"torch(1)$1" -> "seed(1)"	[label=manual_seed];
	"torch(1)$1" -> "torch(1)$0"	[label=manual_seed];
	"torch(1)$2" -> "torch(1)$1"	[label=assignedFrom];
	"torch(1)$2" -> "True(1)"	[label=assignedFrom];
	"train(0)$0" -> "pd(0)$0"	[label=read_csv];
	"train(0)$0" -> "../input/train.csv(0)"	[label=read_csv];
	"../input/train.csv(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"test(0)$0" -> "pd(0)$0"	[label=read_csv];
	"test(0)$0" -> "../input/test.csv(0)"	[label=read_csv];
	"../input/test.csv(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"sub(0)$0" -> "pd(0)$0"	[label=read_csv];
	"sub(0)$0" -> "../input/sample_submission.csv(0)"	[label=read_csv];
	"../input/sample_submission.csv(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	os -> "text-modelling-in-pytorch.ipynb"	[label=importedBy];
	"os(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"os(0)" -> os	[label=assignedFrom];
	"Available embeddings:(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"print[54/0]" -> "os(0)"	[label=print];
	"print[54/0]" -> "Available embeddings:(0)"	[label=print];
	"print[54/0]" -> "../input/embeddings/(0)"	[label=print];
	"../input/embeddings/(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"train(0)$1" -> "train(0)$0"	[label=value_counts];
	"train(0)$2" -> "train(0)$1"	[label=head];
	"Average word length of questions in train is {0:.0f}.(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"print[57/0]" -> "np(0)"	[label=print];
	"print[57/0]" -> "train(0)$2"	[label=print];
	"print[57/0]" -> "Average word length of questions in train is {0:.0f}.(0)"	[label=print];
	"print[57/0]" -> "question_text(0)"	[label=print];
	"print[57/0]" -> "len(0)"	[label=print];
	"print[57/0]" -> "x(0)"	[label=print];
	"question_text(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"len(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"x(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"Average word length of questions in test is {0:.0f}.(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"print[58/0]" -> "np(0)"	[label=print];
	"print[58/0]" -> "test(0)$0"	[label=print];
	"print[58/0]" -> "question_text(0)"	[label=print];
	"print[58/0]" -> "len(0)"	[label=print];
	"print[58/0]" -> "x(0)"	[label=print];
	"print[58/0]" -> "Average word length of questions in test is {0:.0f}.(0)"	[label=print];
	"Max word length of questions in train is {0:.0f}.(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"print[59/0]" -> "np(0)"	[label=print];
	"print[59/0]" -> "train(0)$2"	[label=print];
	"print[59/0]" -> "question_text(0)"	[label=print];
	"print[59/0]" -> "len(0)"	[label=print];
	"print[59/0]" -> "x(0)"	[label=print];
	"print[59/0]" -> "Max word length of questions in train is {0:.0f}.(0)"	[label=print];
	"Max word length of questions in test is {0:.0f}.(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"print[60/0]" -> "np(0)"	[label=print];
	"print[60/0]" -> "test(0)$0"	[label=print];
	"print[60/0]" -> "question_text(0)"	[label=print];
	"print[60/0]" -> "len(0)"	[label=print];
	"print[60/0]" -> "x(0)"	[label=print];
	"print[60/0]" -> "Max word length of questions in test is {0:.0f}.(0)"	[label=print];
	"Average character length of questions in train is {0:.0f}.(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"print[61/0]" -> "np(0)"	[label=print];
	"print[61/0]" -> "train(0)$2"	[label=print];
	"print[61/0]" -> "question_text(0)"	[label=print];
	"print[61/0]" -> "len(0)"	[label=print];
	"print[61/0]" -> "x(0)"	[label=print];
	"print[61/0]" -> "Average character length of questions in train is {0:.0f}.(0)"	[label=print];
	"Average character length of questions in test is {0:.0f}.(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"print[62/0]" -> "np(0)"	[label=print];
	"print[62/0]" -> "test(0)$0"	[label=print];
	"print[62/0]" -> "question_text(0)"	[label=print];
	"print[62/0]" -> "len(0)"	[label=print];
	"print[62/0]" -> "x(0)"	[label=print];
	"print[62/0]" -> "Average character length of questions in test is {0:.0f}.(0)"	[label=print];
	"[<_ast.Constant object at 0x7fd4902ab5e0>, <_ast.Constant object at 0x7fd4902abb80>, <_ast.Constant object at 0x7fd4902ab160>, <_\
ast.Constant object at 0x7fd4902abcd0>, <_ast.Constant object at 0x7fd4902ab940>, <_ast.Constant object at 0x7fd4902ab760>, <_ast.Constant \
object at 0x7fd4902abe20>, <_ast.Constant object at 0x7fd4902ab550>, <_ast.Constant object at 0x7fd4902ab430>, <_ast.Constant object \
at 0x7fd4902abf70>, <_ast.Constant object at 0x7fd4902ab4f0>, <_ast.Constant object at 0x7fd4902aba90>, <_ast.Constant object at \
0x7fd4902ab1f0>, <_ast.Constant object at 0x7fd4902ab340>, <_ast.Constant object at 0x7fd4902ab490>, <_ast.Constant object at 0x7fd4902ab670>, <_\
ast.Constant object at 0x7fd4902ab040>, <_ast.Constant object at 0x7fd4902abfa0>, <_ast.Constant object at 0x7fd4902ab3d0>, <_ast.Constant \
object at 0x7fd4902ab5b0>, <_ast.Constant object at 0x7fd4902abc70>, <_ast.Constant object at 0x7fd4902abc40>, <_ast.Constant object \
at 0x7fd4902abf40>, <_ast.Constant object at 0x7fd4902ab880>, <_ast.Constant object at 0x7fd4902ab9a0>, <_ast.Constant object at \
0x7fd4902abca0>, <_ast.Constant object at 0x7fd4902abaf0>, <_ast.Constant object at 0x7fd4902ab070>, <_ast.Constant object at 0x7fd4902ab310>, <_\
ast.Constant object at 0x7fd4902ab190>, <_ast.Constant object at 0x7fd4902ab730>, <_ast.Constant object at 0x7fd4902aba60>, <_ast.Constant \
object at 0x7fd4902ab9d0>, <_ast.Constant object at 0x7fd4902abc10>, <_ast.Constant object at 0x7fd4902ab970>, <_ast.Constant object \
at 0x7fd4902abfd0>, <_ast.Constant object at 0x7fd4902ab280>, <_ast.Constant object at 0x7fd4902abb50>, <_ast.Constant object at \
0x7fd4902ab6a0>, <_ast.Constant object at 0x7fd4902ab1c0>, <_ast.Constant object at 0x7fd4902abd30>, <_ast.Constant object at 0x7fd4902abe50>, <_\
ast.Constant object at 0x7fd4902ab0d0>, <_ast.Constant object at 0x7fd4902abeb0>, <_ast.Constant object at 0x7fd4902ab640>, <_ast.Constant \
object at 0x7fd4902aba30>, <_ast.Constant object at 0x7fd4902ab610>, <_ast.Constant object at 0x7fd4902abe80>, <_ast.Constant object \
at 0x7fd4902ab6d0>, <_ast.Constant object at 0x7fd4902ab460>, <_ast.Constant object at 0x7fd4902abdf0>, <_ast.Constant object at \
0x7fd4902ab580>, <_ast.Constant object at 0x7fd4902ab370>, <_ast.Constant object at 0x7fd4902abdc0>, <_ast.Constant object at 0x7fd4902ab8b0>, <_\
ast.Constant object at 0x7fd4902abbb0>, <_ast.Constant object at 0x7fd4902ab2b0>, <_ast.Constant object at 0x7fd4902ab400>, <_ast.Constant \
object at 0x7fd4902abbe0>, <_ast.Constant object at 0x7fd4902ab4c0>, <_ast.Constant object at 0x7fd4902ab850>, <_ast.Constant object \
at 0x7fd4902ab820>, <_ast.Constant object at 0x7fd4902ab100>, <_ast.Constant object at 0x7fd4902ab2e0>, <_ast.Constant object at \
0x7fd4902aba00>, <_ast.Constant object at 0x7fd4902ab220>, <_ast.Constant object at 0x7fd4902ab3a0>, <_ast.Constant object at 0x7fd4902abee0>, <_\
ast.Constant object at 0x7fd4902ab910>, <_ast.Constant object at 0x7fd4902abd60>, <_ast.Constant object at 0x7fd4902ab250>, <_ast.Constant \
object at 0x7fd4902ab130>, <_ast.Constant object at 0x7fd4902ab7c0>, <_ast.Constant object at 0x7fd4902ab0a0>, <_ast.Constant object \
at 0x7fd4902ab8e0>, <_ast.Constant object at 0x7fd5007f0eb0>, <_ast.Constant object at 0x7fd5007f07c0>, <_ast.Constant object at \
0x7fd5007f0df0>, <_ast.Constant object at 0x7fd5007f0460>, <_ast.Constant object at 0x7fd5007f0280>, <_ast.Constant object at 0x7fd5007f04c0>, <_\
ast.Constant object at 0x7fd5007f0fd0>, <_ast.Constant object at 0x7fd5007f0a30>, <_ast.Constant object at 0x7fd5007f0d60>, <_ast.Constant \
object at 0x7fd5007f09d0>, <_ast.Constant object at 0x7fd5007f0400>, <_ast.Constant object at 0x7fd5007f05b0>, <_ast.Constant object \
at 0x7fd5007f0550>, <_ast.Constant object at 0x7fd5007f0a60>, <_ast.Constant object at 0x7fd5007f0130>, <_ast.Constant object at \
0x7fd5007f08b0>, <_ast.Constant object at 0x7fd5007f0a00>, <_ast.Constant object at 0x7fd5007f0d90>, <_ast.Constant object at 0x7fd5007f0d00>, <_\
ast.Constant object at 0x7fd5007f0850>, <_ast.Constant object at 0x7fd5007f0880>, <_ast.Constant object at 0x7fd5007f0730>, <_ast.Constant \
object at 0x7fd5007f0610>, <_ast.Constant object at 0x7fd5007f05e0>, <_ast.Constant object at 0x7fd5007f0d30>, <_ast.Constant object \
at 0x7fd5007f0520>, <_ast.Constant object at 0x7fd5007f0580>, <_ast.Constant object at 0x7fd5007f02e0>, <_ast.Constant object at \
0x7fd5007f0af0>, <_ast.Constant object at 0x7fd5007f0ca0>, <_ast.Constant object at 0x7fd5007f0e20>, <_ast.Constant object at 0x7fd5007f0940>, <_\
ast.Constant object at 0x7fd5007f0c40>, <_ast.Constant object at 0x7fd5007f0f10>, <_ast.Constant object at 0x7fd5007f0f70>, <_ast.Constant \
object at 0x7fd5007f0640>, <_ast.Constant object at 0x7fd5007f0e50>, <_ast.Constant object at 0x7fd5007f0c10>, <_ast.Constant object \
at 0x7fd5007f0b80>, <_ast.Constant object at 0x7fd5007f02b0>, <_ast.Constant object at 0x7fd5007f0cd0>, <_ast.Constant object at \
0x7fd5007f0b20>, <_ast.Constant object at 0x7fd5007f04f0>, <_ast.Constant object at 0x7fd5007f0310>, <_ast.Constant object at 0x7fd5007f03d0>, <_\
ast.Constant object at 0x7fd5007f0910>, <_ast.Constant object at 0x7fd5007f0430>, <_ast.Constant object at 0x7fd5007f0190>, <_ast.Constant \
object at 0x7fd5007f0be0>, <_ast.Constant object at 0x7fd5007f0e80>, <_ast.Constant object at 0x7fd5007f0ac0>, <_ast.Constant object \
at 0x7fd5007f0f40>, <_ast.Constant object at 0x7fd5007f0760>, <_ast.Constant object at 0x7fd5007f09a0>, <_ast.Constant object at \
0x7fd5007f0340>](0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"puncts(0)$0" -> "[<_ast.Constant object at 0x7fd4902ab5e0>, <_ast.Constant object at 0x7fd4902abb80>, <_ast.Constant object at 0x7fd4902ab160>, <_\
ast.Constant object at 0x7fd4902abcd0>, <_ast.Constant object at 0x7fd4902ab940>, <_ast.Constant object at 0x7fd4902ab760>, <_ast.Constant \
object at 0x7fd4902abe20>, <_ast.Constant object at 0x7fd4902ab550>, <_ast.Constant object at 0x7fd4902ab430>, <_ast.Constant object \
at 0x7fd4902abf70>, <_ast.Constant object at 0x7fd4902ab4f0>, <_ast.Constant object at 0x7fd4902aba90>, <_ast.Constant object at \
0x7fd4902ab1f0>, <_ast.Constant object at 0x7fd4902ab340>, <_ast.Constant object at 0x7fd4902ab490>, <_ast.Constant object at 0x7fd4902ab670>, <_\
ast.Constant object at 0x7fd4902ab040>, <_ast.Constant object at 0x7fd4902abfa0>, <_ast.Constant object at 0x7fd4902ab3d0>, <_ast.Constant \
object at 0x7fd4902ab5b0>, <_ast.Constant object at 0x7fd4902abc70>, <_ast.Constant object at 0x7fd4902abc40>, <_ast.Constant object \
at 0x7fd4902abf40>, <_ast.Constant object at 0x7fd4902ab880>, <_ast.Constant object at 0x7fd4902ab9a0>, <_ast.Constant object at \
0x7fd4902abca0>, <_ast.Constant object at 0x7fd4902abaf0>, <_ast.Constant object at 0x7fd4902ab070>, <_ast.Constant object at 0x7fd4902ab310>, <_\
ast.Constant object at 0x7fd4902ab190>, <_ast.Constant object at 0x7fd4902ab730>, <_ast.Constant object at 0x7fd4902aba60>, <_ast.Constant \
object at 0x7fd4902ab9d0>, <_ast.Constant object at 0x7fd4902abc10>, <_ast.Constant object at 0x7fd4902ab970>, <_ast.Constant object \
at 0x7fd4902abfd0>, <_ast.Constant object at 0x7fd4902ab280>, <_ast.Constant object at 0x7fd4902abb50>, <_ast.Constant object at \
0x7fd4902ab6a0>, <_ast.Constant object at 0x7fd4902ab1c0>, <_ast.Constant object at 0x7fd4902abd30>, <_ast.Constant object at 0x7fd4902abe50>, <_\
ast.Constant object at 0x7fd4902ab0d0>, <_ast.Constant object at 0x7fd4902abeb0>, <_ast.Constant object at 0x7fd4902ab640>, <_ast.Constant \
object at 0x7fd4902aba30>, <_ast.Constant object at 0x7fd4902ab610>, <_ast.Constant object at 0x7fd4902abe80>, <_ast.Constant object \
at 0x7fd4902ab6d0>, <_ast.Constant object at 0x7fd4902ab460>, <_ast.Constant object at 0x7fd4902abdf0>, <_ast.Constant object at \
0x7fd4902ab580>, <_ast.Constant object at 0x7fd4902ab370>, <_ast.Constant object at 0x7fd4902abdc0>, <_ast.Constant object at 0x7fd4902ab8b0>, <_\
ast.Constant object at 0x7fd4902abbb0>, <_ast.Constant object at 0x7fd4902ab2b0>, <_ast.Constant object at 0x7fd4902ab400>, <_ast.Constant \
object at 0x7fd4902abbe0>, <_ast.Constant object at 0x7fd4902ab4c0>, <_ast.Constant object at 0x7fd4902ab850>, <_ast.Constant object \
at 0x7fd4902ab820>, <_ast.Constant object at 0x7fd4902ab100>, <_ast.Constant object at 0x7fd4902ab2e0>, <_ast.Constant object at \
0x7fd4902aba00>, <_ast.Constant object at 0x7fd4902ab220>, <_ast.Constant object at 0x7fd4902ab3a0>, <_ast.Constant object at 0x7fd4902abee0>, <_\
ast.Constant object at 0x7fd4902ab910>, <_ast.Constant object at 0x7fd4902abd60>, <_ast.Constant object at 0x7fd4902ab250>, <_ast.Constant \
object at 0x7fd4902ab130>, <_ast.Constant object at 0x7fd4902ab7c0>, <_ast.Constant object at 0x7fd4902ab0a0>, <_ast.Constant object \
at 0x7fd4902ab8e0>, <_ast.Constant object at 0x7fd5007f0eb0>, <_ast.Constant object at 0x7fd5007f07c0>, <_ast.Constant object at \
0x7fd5007f0df0>, <_ast.Constant object at 0x7fd5007f0460>, <_ast.Constant object at 0x7fd5007f0280>, <_ast.Constant object at 0x7fd5007f04c0>, <_\
ast.Constant object at 0x7fd5007f0fd0>, <_ast.Constant object at 0x7fd5007f0a30>, <_ast.Constant object at 0x7fd5007f0d60>, <_ast.Constant \
object at 0x7fd5007f09d0>, <_ast.Constant object at 0x7fd5007f0400>, <_ast.Constant object at 0x7fd5007f05b0>, <_ast.Constant object \
at 0x7fd5007f0550>, <_ast.Constant object at 0x7fd5007f0a60>, <_ast.Constant object at 0x7fd5007f0130>, <_ast.Constant object at \
0x7fd5007f08b0>, <_ast.Constant object at 0x7fd5007f0a00>, <_ast.Constant object at 0x7fd5007f0d90>, <_ast.Constant object at 0x7fd5007f0d00>, <_\
ast.Constant object at 0x7fd5007f0850>, <_ast.Constant object at 0x7fd5007f0880>, <_ast.Constant object at 0x7fd5007f0730>, <_ast.Constant \
object at 0x7fd5007f0610>, <_ast.Constant object at 0x7fd5007f05e0>, <_ast.Constant object at 0x7fd5007f0d30>, <_ast.Constant object \
at 0x7fd5007f0520>, <_ast.Constant object at 0x7fd5007f0580>, <_ast.Constant object at 0x7fd5007f02e0>, <_ast.Constant object at \
0x7fd5007f0af0>, <_ast.Constant object at 0x7fd5007f0ca0>, <_ast.Constant object at 0x7fd5007f0e20>, <_ast.Constant object at 0x7fd5007f0940>, <_\
ast.Constant object at 0x7fd5007f0c40>, <_ast.Constant object at 0x7fd5007f0f10>, <_ast.Constant object at 0x7fd5007f0f70>, <_ast.Constant \
object at 0x7fd5007f0640>, <_ast.Constant object at 0x7fd5007f0e50>, <_ast.Constant object at 0x7fd5007f0c10>, <_ast.Constant object \
at 0x7fd5007f0b80>, <_ast.Constant object at 0x7fd5007f02b0>, <_ast.Constant object at 0x7fd5007f0cd0>, <_ast.Constant object at \
0x7fd5007f0b20>, <_ast.Constant object at 0x7fd5007f04f0>, <_ast.Constant object at 0x7fd5007f0310>, <_ast.Constant object at 0x7fd5007f03d0>, <_\
ast.Constant object at 0x7fd5007f0910>, <_ast.Constant object at 0x7fd5007f0430>, <_ast.Constant object at 0x7fd5007f0190>, <_ast.Constant \
object at 0x7fd5007f0be0>, <_ast.Constant object at 0x7fd5007f0e80>, <_ast.Constant object at 0x7fd5007f0ac0>, <_ast.Constant object \
at 0x7fd5007f0f40>, <_ast.Constant object at 0x7fd5007f0760>, <_ast.Constant object at 0x7fd5007f09a0>, <_ast.Constant object at \
0x7fd5007f0340>](0)"	[label=assignedFrom];
	"x(2)" -> "clean_text[0]"	[label=_argToVar];
	"x(2)$0" -> "x(2)"	[label=str];
	"punct(2)" -> "puncts(2)"	[label=iteratorOf];
	"x(2)$1" -> "x(2)$0"	[label=replace];
	"x(2)$1" -> "punct(2)"	[label=replace];
	"x(2)$1" -> " (2)"	[label=replace];
	"x(3)" -> "clean_numbers[0]"	[label=_argToVar];
	"x(3)$0" -> "x(3)$0"	[label=sub];
	"x(3)$0" -> "re(3)"	[label=sub];
	"x(3)$0" -> "[0-9]{5,}(3)"	[label=sub];
	"x(3)$0" -> "#####(3)"	[label=sub];
	"x(3)$1" -> "re(3)"	[label=sub];
	"x(3)$1" -> "x(3)$1"	[label=sub];
	"x(3)$1" -> "[0-9]{4}(3)"	[label=sub];
	"x(3)$1" -> "####(3)"	[label=sub];
	"x(3)$2" -> "re(3)"	[label=sub];
	"x(3)$2" -> "x(3)$2"	[label=sub];
	"x(3)$2" -> "[0-9]{3}(3)"	[label=sub];
	"x(3)$2" -> "###(3)"	[label=sub];
	"x(3)$3" -> "re(3)"	[label=sub];
	"x(3)$3" -> "x(3)$3"	[label=sub];
	"x(3)$3" -> "[0-9]{2}(3)"	[label=sub];
	"x(3)$3" -> "##(3)"	[label=sub];
	"aren't(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"mispell_dict(0)$0" -> "aren't(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "can't(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "couldn't(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "didn't(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "doesn't(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "don't(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "hadn't(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "hasn't(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "haven't(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "he'd(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "he'll(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "he's(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "i'd(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "i'll(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "i'm(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "isn't(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "it's(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "it'll(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "i've(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "let's(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "mightn't(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "mustn't(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "shan't(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "she'd(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "she'll(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "she's(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "shouldn't(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "that's(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "there's(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "they'd(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "they'll(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "they're(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "they've(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "we'd(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "we're(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "weren't(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "we've(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "what'll(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "what're(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "what's(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "what've(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "where's(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "who'd(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "who'll(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "who're(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "who's(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "who've(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "won't(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "wouldn't(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "you'd(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "you'll(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "you're(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "you've(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "'re(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "wasn't(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "we'll(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "tryin'(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "are not(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "cannot(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "could not(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "did not(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "does not(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "do not(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "had not(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "has not(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "have not(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "he would(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "he will(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "he is(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "I would(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "I had(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "I will(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "I am(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "is not(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "it is(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "it will(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "I have(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "let us(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "might not(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "must not(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "shall not(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "she would(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "she will(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "she is(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "should not(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "that is(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "there is(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "they would(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "they will(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "they are(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "they have(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "we would(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "we are(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "were not(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "we have(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "what will(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "what are(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "what is(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "what have(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "where is(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "who would(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "who will(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "who are(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "who is(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "who have(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "will not(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "would not(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "you would(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "you will(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "you are(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "you have(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> " are(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "was not(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> " will(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "trying(0)"	[label=assignedFrom];
	"can't(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"couldn't(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"didn't(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"doesn't(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"don't(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"hadn't(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"hasn't(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"haven't(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"he'd(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"he'll(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"he's(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"i'd(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"i'll(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"i'm(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"isn't(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"it's(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"it'll(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"i've(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"let's(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"mightn't(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"mustn't(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"shan't(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"she'd(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"she'll(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"she's(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"shouldn't(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"that's(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"there's(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"they'd(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"they'll(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"they're(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"they've(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"we'd(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"we're(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"weren't(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"we've(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"what'll(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"what're(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"what's(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"what've(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"where's(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"who'd(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"who'll(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"who're(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"who's(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"who've(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"won't(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"wouldn't(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"you'd(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"you'll(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"you're(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"you've(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"'re(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"wasn't(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"we'll(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"tryin'(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"are not(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"cannot(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"could not(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"did not(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"does not(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"do not(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"had not(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"has not(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"have not(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"he would(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"he will(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"he is(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"I would(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"I had(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"I will(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"I am(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"is not(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"it is(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"it will(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"I have(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"let us(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"might not(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"must not(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"shall not(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"she would(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"she will(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"she is(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"should not(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"that is(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"there is(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"they would(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"they will(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"they are(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"they have(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"we would(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"we are(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"were not(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"we have(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"what will(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"what are(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"what is(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"what have(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"where is(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"who would(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"who will(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"who are(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"who is(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"who have(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"will not(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"would not(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"you would(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"you will(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"you are(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"you have(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	" are(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"was not(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	" will(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"trying(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"mispell_dict(4)" -> "_get_mispell[0]"	[label=_argToVar];
	"mispell_re(4)$0" -> "mispell_dict(4)"	[label=compile];
	"mispell_re(4)$0" -> "re(4)"	[label=compile];
	"mispell_re(4)$0" -> "(\%s)(4)"	[label=compile];
	"mispell_re(4)$0" -> "|(4)"	[label=compile];
	"mispellings(0)$0" -> "mispell_dict(0)$0"	[label=_get_mispell];
	"mispellings_re(0)$0" -> "mispell_dict(0)$0"	[label=_get_mispell];
	"text(5)" -> "replace_typical_misspell[0]"	[label=_argToVar];
	"match(6)" -> "replace[0]"	[label=_argToVar];
	"train(0)$3" -> "train(0)$2"	[label=apply];
	"train(0)$3" -> "question_text(0)"	[label=apply];
	"train(0)$3" -> "x(0)"	[label=apply];
	"train(0)$3" -> "clean_text(0)"	[label=apply];
	"clean_text(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"test(0)$1" -> "test(0)$0"	[label=apply];
	"test(0)$1" -> "question_text(0)"	[label=apply];
	"test(0)$1" -> "x(0)"	[label=apply];
	"test(0)$1" -> "clean_text(0)"	[label=apply];
	"train(0)$4" -> "question_text(0)"	[label=apply];
	"train(0)$4" -> "x(0)"	[label=apply];
	"train(0)$4" -> "train(0)$3"	[label=apply];
	"train(0)$4" -> "clean_numbers(0)"	[label=apply];
	"clean_numbers(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"test(0)$2" -> "question_text(0)"	[label=apply];
	"test(0)$2" -> "x(0)"	[label=apply];
	"test(0)$2" -> "test(0)$1"	[label=apply];
	"test(0)$2" -> "clean_numbers(0)"	[label=apply];
	"train(0)$5" -> "question_text(0)"	[label=apply];
	"train(0)$5" -> "x(0)"	[label=apply];
	"train(0)$5" -> "train(0)$4"	[label=apply];
	"train(0)$5" -> "replace_typical_misspell(0)"	[label=apply];
	"replace_typical_misspell(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"test(0)$3" -> "question_text(0)"	[label=apply];
	"test(0)$3" -> "x(0)"	[label=apply];
	"test(0)$3" -> "test(0)$2"	[label=apply];
	"test(0)$3" -> "replace_typical_misspell(0)"	[label=apply];
	"120000(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"max_features(0)$0" -> "120000(0)"	[label=assignedFrom];
	"True(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"tk(0)$0" -> "max_features(0)$0"	[label=Tokenizer];
	"tk(0)$0" -> "True(0)"	[label=Tokenizer];
	"tk(0)$0" -> "(0)"	[label=Tokenizer];
	"(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"list(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"full_text(0)$0" -> "question_text(0)"	[label=Add];
	"full_text(0)$0" -> "train(0)$5"	[label=Add];
	"full_text(0)$0" -> "test(0)$3"	[label=Add];
	"full_text(0)$0" -> "list(0)"	[label=Add];
	"tk(0)$1" -> "tk(0)$0"	[label=fit_on_texts];
	"tk(0)$1" -> "full_text(0)$0"	[label=fit_on_texts];
	"train_tokenized(0)$0" -> "question_text(0)"	[label=texts_to_sequences];
	"train_tokenized(0)$0" -> "train(0)$5"	[label=texts_to_sequences];
	"train_tokenized(0)$0" -> "tk(0)$1"	[label=texts_to_sequences];
	"train_tokenized(0)$0" -> "missing(0)"	[label=texts_to_sequences];
	"missing(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"test_tokenized(0)$0" -> "question_text(0)"	[label=texts_to_sequences];
	"test_tokenized(0)$0" -> "test(0)$3"	[label=texts_to_sequences];
	"test_tokenized(0)$0" -> "tk(0)$1"	[label=texts_to_sequences];
	"test_tokenized(0)$0" -> "missing(0)"	[label=texts_to_sequences];
	"train(0)$6" -> "train(0)$5"	[label=plot];
	"plt(0)$0" -> "plt(0)"	[label=yscale];
	"plt(0)$0" -> "log(0)"	[label=yscale];
	"log(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"plt(0)$1" -> "plt(0)$0"	[label=title];
	"plt(0)$1" -> "Distribution of question text length in characters(0)"	[label=title];
	"Distribution of question text length in characters(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"72(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"max_len(0)$0" -> "72(0)"	[label=assignedFrom];
	"maxlen(0)$0" -> "72(0)"	[label=assignedFrom];
	"X_train(0)$0" -> "train_tokenized(0)$0"	[label=pad_sequences];
	"X_train(0)$0" -> "max_len(0)$0"	[label=pad_sequences];
	"X_test(0)$0" -> "test_tokenized(0)$0"	[label=pad_sequences];
	"X_test(0)$0" -> "max_len(0)$0"	[label=pad_sequences];
	"y_train(0)$0" -> "train(0)$6"	[label=assignedFrom];
	"y_train(0)$0" -> "target(0)"	[label=assignedFrom];
	"target(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"x(7)" -> "sigmoid[0]"	[label=_argToVar];
	StratifiedKFold -> "sklearn.model_selection"	[label=importedBy];
	"StratifiedKFold(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"StratifiedKFold(0)" -> StratifiedKFold	[label=assignedFrom];
	"splits(0)$0" -> "True(0)"	[label=list];
	"splits(0)$0" -> "X_train(0)$0"	[label=list];
	"splits(0)$0" -> "y_train(0)$0"	[label=list];
	"splits(0)$0" -> "StratifiedKFold(0)"	[label=list];
	"splits(0)$0" -> "4(0)"	[label=list];
	"splits(0)$0" -> "10(0)"	[label=list];
	"4(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"10(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"300(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"embed_size(0)$0" -> "300(0)"	[label=assignedFrom];
	"../input/embeddings/glove.840B.300d/glove.840B.300d.txt(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"embedding_path(0)$0" -> "../input/embeddings/glove.840B.300d/glove.840B.300d.txt(0)"	[label=assignedFrom];
	"word(8)" -> "get_coefs[0]"	[label=_argToVar];
	"get_coefs(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"embedding_index(0)$0" -> "ignore(0)"	[label=dict];
	"embedding_index(0)$0" -> "embedding_path(0)$0"	[label=dict];
	"embedding_index(0)$0" -> "get_coefs(0)"	[label=dict];
	"embedding_index(0)$0" -> "o(0)"	[label=dict];
	"embedding_index(0)$0" -> " (0)"	[label=dict];
	"embedding_index(0)$0" -> "open(0)"	[label=dict];
	"embedding_index(0)$0" -> "utf-8(0)"	[label=dict];
	"o(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	" (0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"open(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"utf-8(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"0.005838499(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"emb_mean(0)$0" -> "0.005838499(0)"	[label=assignedFrom];
	"emb_mean(0)$0" -> "0.48782197(0)"	[label=assignedFrom];
	"0.48782197(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"emb_std(0)$0" -> "0.005838499(0)"	[label=assignedFrom];
	"emb_std(0)$0" -> "0.48782197(0)"	[label=assignedFrom];
	"word_index(0)$0" -> "tk(0)$1"	[label=assignedFrom];
	"nb_words(0)$0" -> "len(0)"	[label=min];
	"nb_words(0)$0" -> "max_features(0)$0"	[label=min];
	"nb_words(0)$0" -> "word_index(0)$0"	[label=min];
	"embedding_matrix(0)$0" -> "np(0)"	[label=normal];
	"embedding_matrix(0)$0" -> "embed_size(0)$0"	[label=normal];
	"embedding_matrix(0)$0" -> "emb_mean(0)$0"	[label=normal];
	"embedding_matrix(0)$0" -> "emb_std(0)$0"	[label=normal];
	"embedding_matrix(0)$0" -> "nb_words(0)$0"	[label=normal];
	"embedding_matrix(0)$0" -> "1(0)"	[label=normal];
	"1(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"word(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"word(0)" -> "word_index(0)$0"	[label=iteratorOf];
	"i(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"i(0)" -> "splits(0)$0"	[label=iteratorOf];
	"i(0)" -> "word_index(0)$0"	[label=iteratorOf];
	"i(0)" -> "enumerate(0)"	[label=iteratorOf];
	"enumerate(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"embedding_vector(0)$0" -> "embedding_index(0)$0"	[label=get];
	"embedding_vector(0)$0" -> "word(0)"	[label=get];
	"embedding_matrix(0)$1" -> "embedding_matrix(0)$0"	[label=assignedFrom];
	"embedding_matrix(0)$1" -> "embedding_vector(0)$0"	[label=assignedFrom];
	"../input/embeddings/paragram_300_sl999/paragram_300_sl999.txt(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"embedding_path(0)$1" -> "../input/embeddings/paragram_300_sl999/paragram_300_sl999.txt(0)"	[label=assignedFrom];
	"word(9)" -> "get_coefs[0]"	[label=_argToVar];
	"embedding_index(0)$1" -> "ignore(0)"	[label=dict];
	"embedding_index(0)$1" -> "len(0)"	[label=dict];
	"embedding_index(0)$1" -> "get_coefs(0)"	[label=dict];
	"embedding_index(0)$1" -> "o(0)"	[label=dict];
	"embedding_index(0)$1" -> " (0)"	[label=dict];
	"embedding_index(0)$1" -> "open(0)"	[label=dict];
	"embedding_index(0)$1" -> "utf-8(0)"	[label=dict];
	"embedding_index(0)$1" -> "embedding_path(0)$1"	[label=dict];
	"embedding_index(0)$1" -> "100(0)"	[label=dict];
	"100(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"0.0053247833(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"emb_mean(0)$1" -> "0.0053247833(0)"	[label=assignedFrom];
	"emb_mean(0)$1" -> "0.49346462(0)"	[label=assignedFrom];
	"0.49346462(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"emb_std(0)$1" -> "0.0053247833(0)"	[label=assignedFrom];
	"emb_std(0)$1" -> "0.49346462(0)"	[label=assignedFrom];
	"embedding_matrix1(0)$0" -> "np(0)"	[label=normal];
	"embedding_matrix1(0)$0" -> "embed_size(0)$0"	[label=normal];
	"embedding_matrix1(0)$0" -> "nb_words(0)$0"	[label=normal];
	"embedding_matrix1(0)$0" -> "1(0)"	[label=normal];
	"embedding_matrix1(0)$0" -> "emb_mean(0)$1"	[label=normal];
	"embedding_matrix1(0)$0" -> "emb_std(0)$1"	[label=normal];
	"embedding_vector(0)$1" -> "word(0)"	[label=get];
	"embedding_vector(0)$1" -> "embedding_index(0)$1"	[label=get];
	"embedding_matrix1(0)$1" -> "embedding_matrix1(0)$0"	[label=assignedFrom];
	"embedding_matrix1(0)$1" -> "embedding_vector(0)$1"	[label=assignedFrom];
	"embedding_matrix(0)$2" -> "np(0)"	[label=mean];
	"embedding_matrix(0)$2" -> "[<_ast.Name object at 0x7fd5008679a0>, <_ast.Name object at 0x7fd5008679d0>](0)"	[label=mean];
	"embedding_matrix(0)$2" -> "0(0)"	[label=mean];
	"[<_ast.Name object at 0x7fd5008679a0>, <_ast.Name object at 0x7fd5008679d0>](0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"0(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"self(11)" -> "__init__[0]"	[label=_argToVar];
	"feature_dim(11)" -> "__init__[1]"	[label=_argToVar];
	"step_dim(11)" -> "__init__[2]"	[label=_argToVar];
	"bias(11)" -> "__init__[3]"	[label=_argToVar];
	"super(11)$0" -> "super(11)"	[label=__init__];
	"self(11)$0" -> "self(11)"	[label=assignedFrom];
	"self(11)$0" -> "True(11)"	[label=assignedFrom];
	"self(11)$1" -> "bias(11)"	[label=assignedFrom];
	"self(11)$1" -> "self(11)$0"	[label=assignedFrom];
	"self(11)$2" -> "feature_dim(11)"	[label=assignedFrom];
	"self(11)$2" -> "self(11)$1"	[label=assignedFrom];
	"self(11)$3" -> "step_dim(11)"	[label=assignedFrom];
	"self(11)$3" -> "self(11)$2"	[label=assignedFrom];
	"self(11)$4" -> "self(11)$3"	[label=assignedFrom];
	"self(11)$4" -> "0(11)"	[label=assignedFrom];
	"weight(11)$0" -> "feature_dim(11)"	[label=zeros];
	"weight(11)$0" -> "torch(11)"	[label=zeros];
	"weight(11)$0" -> "1(11)"	[label=zeros];
	"nn(11)$0" -> "weight(11)$0"	[label=xavier_uniform_];
	"nn(11)$0" -> "nn(11)"	[label=xavier_uniform_];
	"self(11)$5" -> "self(11)$4"	[label=Parameter];
	"self(11)$5" -> "weight(11)$0"	[label=Parameter];
	"self(11)$5" -> "nn(11)$0"	[label=Parameter];
	"self(11)$6" -> "step_dim(11)"	[label=Parameter];
	"self(11)$6" -> "torch(11)"	[label=Parameter];
	"self(11)$6" -> "nn(11)$0"	[label=Parameter];
	"self(11)$6" -> "self(11)$5"	[label=Parameter];
	"self(12)" -> "forward[0]"	[label=_argToVar];
	"x(12)" -> "forward[1]"	[label=_argToVar];
	"mask(12)" -> "forward[2]"	[label=_argToVar];
	"feature_dim(12)$0" -> "self(12)"	[label=assignedFrom];
	"step_dim(12)$0" -> "self(12)"	[label=assignedFrom];
	"eij(12)$0" -> "self(12)"	[label=view];
	"eij(12)$0" -> "x(12)"	[label=view];
	"eij(12)$0" -> "feature_dim(12)$0"	[label=view];
	"eij(12)$0" -> "step_dim(12)$0"	[label=view];
	"eij(12)$0" -> "torch(12)"	[label=view];
	"eij(12)$0" -> "1(12)"	[label=view];
	"eij(12)$1" -> "self(12)"	[label=Add];
	"eij(12)$1" -> "eij(12)$0"	[label=Add];
	"eij(12)$2" -> "torch(12)"	[label=tanh];
	"eij(12)$2" -> "eij(12)$2"	[label=tanh];
	"a(12)$0" -> "torch(12)"	[label=exp];
	"a(12)$0" -> "eij(12)$2"	[label=exp];
	"a(12)$1" -> "mask(12)"	[label=Mult];
	"a(12)$1" -> "a(12)$0"	[label=Mult];
	"a(12)$2" -> "torch(12)"	[label=Add];
	"a(12)$2" -> "1(12)"	[label=Add];
	"a(12)$2" -> "a(12)$1"	[label=Add];
	"a(12)$2" -> "a(12)$2"	[label=Add];
	"a(12)$2" -> "True(12)"	[label=Add];
	"a(12)$2" -> "1e-10(12)"	[label=Add];
	"weighted_input(12)$0" -> "x(12)"	[label=Mult];
	"weighted_input(12)$0" -> "torch(12)"	[label=Mult];
	"weighted_input(12)$0" -> "1(12)"	[label=Mult];
	"weighted_input(12)$0" -> "a(12)$2"	[label=Mult];
	"self(14)" -> "__init__[0]"	[label=_argToVar];
	"super(14)$0" -> "super(14)"	[label=__init__];
	"hidden_size(14)$0" -> "128(14)"	[label=assignedFrom];
	"self(14)$0" -> "self(14)"	[label=Embedding];
	"self(14)$0" -> "nn(14)"	[label=Embedding];
	"self(14)$0" -> "max_features(14)"	[label=Embedding];
	"self(14)$0" -> "embed_size(14)"	[label=Embedding];
	"self(14)$1" -> "self(14)$0"	[label=Parameter];
	"self(14)$1" -> "nn(14)"	[label=Parameter];
	"self(14)$1" -> "torch(14)"	[label=Parameter];
	"self(14)$1" -> "embedding_matrix(14)"	[label=Parameter];
	"self(14)$2" -> "self(14)$1"	[label=assignedFrom];
	"self(14)$2" -> "False(14)"	[label=assignedFrom];
	"self(14)$3" -> "nn(14)"	[label=Dropout2d];
	"self(14)$3" -> "self(14)$2"	[label=Dropout2d];
	"self(14)$3" -> "0.1(14)"	[label=Dropout2d];
	"self(14)$4" -> "hidden_size(14)$0"	[label=LSTM];
	"self(14)$4" -> "nn(14)"	[label=LSTM];
	"self(14)$4" -> "embed_size(14)"	[label=LSTM];
	"self(14)$4" -> "self(14)$3"	[label=LSTM];
	"self(14)$4" -> "True(14)"	[label=LSTM];
	"self(14)$5" -> "hidden_size(14)$0"	[label=GRU];
	"self(14)$5" -> "nn(14)"	[label=GRU];
	"self(14)$5" -> "self(14)$4"	[label=GRU];
	"self(14)$5" -> "True(14)"	[label=GRU];
	"self(14)$5" -> "2(14)"	[label=GRU];
	"self(14)$6" -> "hidden_size(14)$0"	[label=Attention];
	"self(14)$6" -> "self(14)$5"	[label=Attention];
	"self(14)$6" -> "2(14)"	[label=Attention];
	"self(14)$6" -> "maxlen(14)"	[label=Attention];
	"self(14)$7" -> "hidden_size(14)$0"	[label=Attention];
	"self(14)$7" -> "2(14)"	[label=Attention];
	"self(14)$7" -> "self(14)$6"	[label=Attention];
	"self(14)$7" -> "maxlen(14)"	[label=Attention];
	"self(14)$8" -> "nn(14)"	[label=Linear];
	"self(14)$8" -> "self(14)$7"	[label=Linear];
	"self(14)$8" -> "1024(14)"	[label=Linear];
	"self(14)$8" -> "16(14)"	[label=Linear];
	"self(14)$9" -> "nn(14)"	[label=ReLU];
	"self(14)$9" -> "self(14)$8"	[label=ReLU];
	"self(14)$10" -> "nn(14)"	[label=Dropout];
	"self(14)$10" -> "0.1(14)"	[label=Dropout];
	"self(14)$10" -> "self(14)$9"	[label=Dropout];
	"self(14)$11" -> "nn(14)"	[label=Linear];
	"self(14)$11" -> "16(14)"	[label=Linear];
	"self(14)$11" -> "self(14)$10"	[label=Linear];
	"self(14)$11" -> "1(14)"	[label=Linear];
	"self(15)" -> "forward[0]"	[label=_argToVar];
	"x(15)" -> "forward[1]"	[label=_argToVar];
	"h_embedding(15)$0" -> "self(15)"	[label=embedding];
	"h_embedding(15)$0" -> "x(15)"	[label=embedding];
	"h_embedding(15)$1" -> "self(15)"	[label=squeeze];
	"h_embedding(15)$1" -> "h_embedding(15)$1"	[label=squeeze];
	"h_embedding(15)$1" -> "torch(15)"	[label=squeeze];
	"h_embedding(15)$1" -> "0(15)"	[label=squeeze];
	"h_lstm(15)$0" -> "self(15)"	[label=lstm];
	"h_lstm(15)$0" -> "h_embedding(15)$1"	[label=lstm];
	"_(15)$0" -> "self(15)"	[label=lstm];
	"_(15)$0" -> "h_embedding(15)$1"	[label=lstm];
	"h_gru(15)$0" -> "self(15)"	[label=gru];
	"h_gru(15)$0" -> "h_lstm(15)$0"	[label=gru];
	"_(15)$1" -> "self(15)"	[label=gru];
	"_(15)$1" -> "h_lstm(15)$0"	[label=gru];
	"h_lstm_atten(15)$0" -> "self(15)"	[label=lstm_attention];
	"h_lstm_atten(15)$0" -> "h_lstm(15)$0"	[label=lstm_attention];
	"h_gru_atten(15)$0" -> "self(15)"	[label=gru_attention];
	"h_gru_atten(15)$0" -> "h_gru(15)$0"	[label=gru_attention];
	"avg_pool(15)$0" -> "torch(15)"	[label=mean];
	"avg_pool(15)$0" -> "h_gru(15)$0"	[label=mean];
	"avg_pool(15)$0" -> "1(15)"	[label=mean];
	"max_pool(15)$0" -> "torch(15)"	[label=max];
	"max_pool(15)$0" -> "h_gru(15)$0"	[label=max];
	"max_pool(15)$0" -> "1(15)"	[label=max];
	"_(15)$2" -> "torch(15)"	[label=max];
	"_(15)$2" -> "h_gru(15)$0"	[label=max];
	"_(15)$2" -> "1(15)"	[label=max];
	"conc(15)$0" -> "torch(15)"	[label=cat];
	"conc(15)$0" -> "h_lstm_atten(15)$0"	[label=cat];
	"conc(15)$0" -> "h_gru_atten(15)$0"	[label=cat];
	"conc(15)$0" -> "avg_pool(15)$0"	[label=cat];
	"conc(15)$0" -> "1(15)"	[label=cat];
	"conc(15)$0" -> "max_pool(15)$0"	[label=cat];
	"conc(15)$1" -> "self(15)"	[label=relu];
	"conc(15)$1" -> "conc(15)$1"	[label=relu];
	"conc(15)$2" -> "self(15)"	[label=dropout];
	"conc(15)$2" -> "conc(15)$2"	[label=dropout];
	"out(15)$0" -> "self(15)"	[label=out];
	"out(15)$0" -> "conc(15)$2"	[label=out];
	"model(16)" -> "train_model[0]"	[label=_argToVar];
	"x_train(16)" -> "train_model[1]"	[label=_argToVar];
	"y_train(16)" -> "train_model[2]"	[label=_argToVar];
	"x_val(16)" -> "train_model[3]"	[label=_argToVar];
	"y_val(16)" -> "train_model[4]"	[label=_argToVar];
	"validate(16)" -> "train_model[5]"	[label=_argToVar];
	"optimizer(16)$0" -> "model(16)"	[label=Adam];
	"optimizer(16)$0" -> "torch(16)"	[label=Adam];
	"train(16)$0" -> "x_train(16)"	[label=TensorDataset];
	"train(16)$0" -> "y_train(16)"	[label=TensorDataset];
	"train(16)$0" -> "torch(16)"	[label=TensorDataset];
	"valid(16)$0" -> "x_val(16)"	[label=TensorDataset];
	"valid(16)$0" -> "y_val(16)"	[label=TensorDataset];
	"valid(16)$0" -> "torch(16)"	[label=TensorDataset];
	"train_loader(16)$0" -> "torch(16)"	[label=DataLoader];
	"train_loader(16)$0" -> "train(16)$0"	[label=DataLoader];
	"train_loader(16)$0" -> "batch_size(16)"	[label=DataLoader];
	"train_loader(16)$0" -> "True(16)"	[label=DataLoader];
	"valid_loader(16)$0" -> "torch(16)"	[label=DataLoader];
	"valid_loader(16)$0" -> "valid(16)$0"	[label=DataLoader];
	"valid_loader(16)$0" -> "batch_size(16)"	[label=DataLoader];
	"valid_loader(16)$0" -> "False(16)"	[label=DataLoader];
	"loss_fn(16)$0" -> "torch(16)"	[label=cuda];
	"loss_fn(16)$0" -> "mean(16)"	[label=cuda];
	"best_score(16)$0" -> "np(16)"	[label=assignedFrom];
	"epoch(16)" -> "range(16)"	[label=iteratorOf];
	"epoch(16)" -> "n_epochs(16)"	[label=iteratorOf];
	"start_time(16)$0" -> "time(16)"	[label=time];
	"model(16)$0" -> "model(16)"	[label=train];
	"avg_loss(16)$0" -> "0.0(16)"	[label=assignedFrom];
	"x_batch(16)" -> "train_loader(16)$0"	[label=iteratorOf];
	"x_batch(16)" -> "True(16)"	[label=iteratorOf];
	"x_batch(16)" -> "valid_loader(16)$0"	[label=iteratorOf];
	"x_batch(16)" -> "tqdm(16)"	[label=iteratorOf];
	"x_batch(16)" -> "enumerate(16)"	[label=iteratorOf];
	"x_batch(16)" -> "test_loader(16)"	[label=iteratorOf];
	"y_batch(16)" -> "train_loader(16)$0"	[label=iteratorOf];
	"y_batch(16)" -> "True(16)"	[label=iteratorOf];
	"y_batch(16)" -> "valid_loader(16)$0"	[label=iteratorOf];
	"y_batch(16)" -> "tqdm(16)"	[label=iteratorOf];
	"y_batch(16)" -> "enumerate(16)"	[label=iteratorOf];
	"y_pred(16)$0" -> "x_batch(16)"	[label=model];
	"loss(16)$0" -> "y_batch(16)"	[label=loss_fn];
	"loss(16)$0" -> "y_pred(16)$0"	[label=loss_fn];
	"optimizer(16)$1" -> "optimizer(16)$0"	[label=zero_grad];
	"loss(16)$1" -> "loss(16)$0"	[label=backward];
	"optimizer(16)$2" -> "optimizer(16)$1"	[label=step];
	"avg_loss(16)$1" -> "train_loader(16)$0"	[label=Add];
	"avg_loss(16)$1" -> "avg_loss(16)$0"	[label=Add];
	"avg_loss(16)$1" -> "loss(16)$1"	[label=Add];
	"avg_loss(16)$1" -> "len(16)"	[label=Add];
	"model(16)$1" -> "model(16)$0"	[label=eval];
	"valid_preds(16)$0" -> "np(16)"	[label=zeros];
	"valid_preds(16)$0" -> "x_val_fold(16)"	[label=zeros];
	"valid_preds(16)$0" -> "0(16)"	[label=zeros];
	"avg_val_loss(16)$0" -> "0.0(16)"	[label=assignedFrom];
	"i(16)" -> "valid_loader(16)$0"	[label=iteratorOf];
	"i(16)" -> "enumerate(16)"	[label=iteratorOf];
	"i(16)" -> "test_loader(16)"	[label=iteratorOf];
	"y_pred(16)$1" -> "x_batch(16)"	[label=detach];
	"y_pred(16)$1" -> "model(16)$1"	[label=detach];
	"avg_val_loss(16)$1" -> "valid_loader(16)$0"	[label=Add];
	"avg_val_loss(16)$1" -> "loss_fn(16)$0"	[label=Add];
	"avg_val_loss(16)$1" -> "y_batch(16)"	[label=Add];
	"avg_val_loss(16)$1" -> "len(16)"	[label=Add];
	"avg_val_loss(16)$1" -> "avg_val_loss(16)$0"	[label=Add];
	"avg_val_loss(16)$1" -> "y_pred(16)$1"	[label=Add];
	"valid_preds(16)$1" -> "valid_preds(16)$0"	[label=assignedFrom];
	"valid_preds(16)$1" -> "0(16)"	[label=assignedFrom];
	"valid_preds(16)$1" -> "y_pred(16)$1"	[label=assignedFrom];
	"valid_preds(16)$1" -> "sigmoid(16)"	[label=assignedFrom];
	"search_result(16)$0" -> "y_val(16)"	[label=threshold_search];
	"search_result(16)$0" -> "valid_preds(16)$1"	[label=threshold_search];
	"val_f1(16)$0" -> "search_result(16)$0"	[label=assignedFrom];
	"val_f1(16)$0" -> "f1(16)"	[label=assignedFrom];
	"val_f1(16)$0" -> "threshold(16)"	[label=assignedFrom];
	"val_threshold(16)$0" -> "search_result(16)$0"	[label=assignedFrom];
	"val_threshold(16)$0" -> "f1(16)"	[label=assignedFrom];
	"val_threshold(16)$0" -> "threshold(16)"	[label=assignedFrom];
	"elapsed_time(16)$0" -> "start_time(16)$0"	[label=Sub];
	"elapsed_time(16)$0" -> "time(16)"	[label=Sub];
	"print[339/12]" -> "epoch(16)"	[label=print];
	"print[339/12]" -> "n_epochs(16)"	[label=print];
	"print[339/12]" -> "avg_loss(16)$1"	[label=print];
	"print[339/12]" -> "avg_val_loss(16)$1"	[label=print];
	"print[339/12]" -> "val_f1(16)$0"	[label=print];
	"print[339/12]" -> "val_threshold(16)$0"	[label=print];
	"print[339/12]" -> "elapsed_time(16)$0"	[label=print];
	"print[339/12]" -> "Epoch {}/{} 	 loss={:.4f} 	 val_loss={:.4f} 	 val_f1={:.4f} best_t={:.2f} 	 time={:.2f}s(16)"	[label=print];
	"print[339/12]" -> "1(16)"	[label=print];
	"elapsed_time(16)$1" -> "start_time(16)$0"	[label=Sub];
	"elapsed_time(16)$1" -> "time(16)"	[label=Sub];
	"print[343/12]" -> "epoch(16)"	[label=print];
	"print[343/12]" -> "n_epochs(16)"	[label=print];
	"print[343/12]" -> "avg_loss(16)$1"	[label=print];
	"print[343/12]" -> "1(16)"	[label=print];
	"print[343/12]" -> "elapsed_time(16)$1"	[label=print];
	"print[343/12]" -> "Epoch {}/{} 	 loss={:.4f} 	 time={:.2f}s(16)"	[label=print];
	"valid_preds(16)$2" -> "np(16)"	[label=zeros];
	"valid_preds(16)$2" -> "x_val_fold(16)"	[label=zeros];
	"valid_preds(16)$2" -> "0(16)"	[label=zeros];
	"avg_val_loss(16)$2" -> "0.0(16)"	[label=assignedFrom];
	"y_pred(16)$2" -> "x_batch(16)"	[label=detach];
	"y_pred(16)$2" -> "model(16)$1"	[label=detach];
	"avg_val_loss(16)$3" -> "valid_loader(16)$0"	[label=Add];
	"avg_val_loss(16)$3" -> "loss_fn(16)$0"	[label=Add];
	"avg_val_loss(16)$3" -> "y_batch(16)"	[label=Add];
	"avg_val_loss(16)$3" -> "len(16)"	[label=Add];
	"avg_val_loss(16)$3" -> "avg_val_loss(16)$2"	[label=Add];
	"avg_val_loss(16)$3" -> "y_pred(16)$2"	[label=Add];
	"valid_preds(16)$3" -> "0(16)"	[label=assignedFrom];
	"valid_preds(16)$3" -> "sigmoid(16)"	[label=assignedFrom];
	"valid_preds(16)$3" -> "valid_preds(16)$2"	[label=assignedFrom];
	"valid_preds(16)$3" -> "y_pred(16)$2"	[label=assignedFrom];
	"print[355/4]" -> "avg_val_loss(16)$3"	[label=print];
	"print[355/4]" -> "Validation loss: (16)"	[label=print];
	"test_preds(16)$0" -> "np(16)"	[label=zeros];
	"test_preds(16)$0" -> "test_loader(16)"	[label=zeros];
	"test_preds(16)$0" -> "len(16)"	[label=zeros];
	"y_pred(16)$3" -> "x_batch(16)"	[label=detach];
	"y_pred(16)$3" -> "model(16)$1"	[label=detach];
	"test_preds(16)$1" -> "0(16)"	[label=assignedFrom];
	"test_preds(16)$1" -> "sigmoid(16)"	[label=assignedFrom];
	"test_preds(16)$1" -> "test_preds(16)$0"	[label=assignedFrom];
	"test_preds(16)$1" -> "y_pred(16)$3"	[label=assignedFrom];
	"x_test_cuda(0)$0" -> "torch(0)"	[label=cuda];
	"x_test_cuda(0)$0" -> "X_test(0)$0"	[label=cuda];
	"test(0)$4" -> "torch(0)"	[label=TensorDataset];
	"test(0)$4" -> "x_test_cuda(0)$0"	[label=TensorDataset];
	"512(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"batch_size(0)$0" -> "512(0)"	[label=assignedFrom];
	"test_loader(0)$0" -> "torch(0)"	[label=DataLoader];
	"test_loader(0)$0" -> "test(0)$4"	[label=DataLoader];
	"test_loader(0)$0" -> "batch_size(0)$0"	[label=DataLoader];
	"test_loader(0)$0" -> "False(0)"	[label=DataLoader];
	"False(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"1029(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"seed(0)$0" -> "1029(0)"	[label=assignedFrom];
	"y_true(17)" -> "threshold_search[0]"	[label=_argToVar];
	"y_proba(17)" -> "threshold_search[1]"	[label=_argToVar];
	"best_threshold(17)$0" -> "0(17)"	[label=assignedFrom];
	"best_score(17)$0" -> "0(17)"	[label=assignedFrom];
	"threshold(17)" -> "tqdm(17)"	[label=iteratorOf];
	"threshold(17)" -> "i(17)"	[label=iteratorOf];
	"threshold(17)" -> "0.01(17)"	[label=iteratorOf];
	"threshold(17)" -> "range(17)"	[label=iteratorOf];
	"threshold(17)" -> "100(17)"	[label=iteratorOf];
	"threshold(17)" -> "True(17)"	[label=iteratorOf];
	"score(17)$0" -> "y_true(17)"	[label=f1_score];
	"score(17)$0" -> "y_proba(17)"	[label=f1_score];
	"score(17)$0" -> "threshold(17)"	[label=f1_score];
	"best_threshold(17)$1" -> "threshold(17)"	[label=assignedFrom];
	"best_score(17)$1" -> "score(17)$0"	[label=assignedFrom];
	"search_result(17)$0" -> "threshold(17)"	[label=assignedFrom];
	"search_result(17)$0" -> "best_threshold(17)$1"	[label=assignedFrom];
	"search_result(17)$0" -> "best_score(17)$1"	[label=assignedFrom];
	"search_result(17)$0" -> "f1(17)"	[label=assignedFrom];
	"seed(18)" -> "seed_everything[0]"	[label=_argToVar];
	"random(18)$0" -> "seed(18)"	[label=seed];
	"random(18)$0" -> "random(18)"	[label=seed];
	"os(18)$0" -> "seed(18)"	[label=str];
	"os(18)$0" -> "os(18)"	[label=str];
	"np(18)$0" -> "seed(18)"	[label=seed];
	"np(18)$0" -> "np(18)"	[label=seed];
	"torch(18)$0" -> "seed(18)"	[label=manual_seed];
	"torch(18)$0" -> "torch(18)"	[label=manual_seed];
	"torch(18)$1" -> "seed(18)"	[label=manual_seed];
	"torch(18)$1" -> "torch(18)$0"	[label=manual_seed];
	"torch(18)$2" -> "torch(18)$1"	[label=assignedFrom];
	"torch(18)$2" -> "True(18)"	[label=assignedFrom];
	"train_preds(0)$0" -> "np(0)"	[label=zeros];
	"train_preds(0)$0" -> "len(0)"	[label=zeros];
	"train_preds(0)$0" -> "train(0)$6"	[label=zeros];
	"test_preds(0)$0" -> "np(0)"	[label=zeros];
	"test_preds(0)$0" -> "len(0)"	[label=zeros];
	"test_preds(0)$0" -> "splits(0)$0"	[label=zeros];
	"test_preds(0)$0" -> "test(0)$4"	[label=zeros];
	"5(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"n_epochs(0)$0" -> "5(0)"	[label=assignedFrom];
	tqdm -> "text-modelling-in-pytorch.ipynb"	[label=importedBy];
	tqdm -> tqdm	[label=importedBy];
	"tqdm(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"tqdm(0)" -> tqdm	[label=assignedFrom];
	"sklearn.metrics" -> "text-modelling-in-pytorch.ipynb"	[label=importedBy];
	f1_score -> "sklearn.metrics"	[label=importedBy];
	"f1_score(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"f1_score(0)" -> f1_score	[label=assignedFrom];
	"train_idx(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"train_idx(0)" -> "splits(0)$0"	[label=iteratorOf];
	"train_idx(0)" -> "enumerate(0)"	[label=iteratorOf];
	"valid_idx(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"valid_idx(0)" -> "splits(0)$0"	[label=iteratorOf];
	"valid_idx(0)" -> "enumerate(0)"	[label=iteratorOf];
	"x_train_fold(0)$0" -> "torch(0)"	[label=cuda];
	"x_train_fold(0)$0" -> "X_train(0)$0"	[label=cuda];
	"x_train_fold(0)$0" -> "train_idx(0)"	[label=cuda];
	"y_train_fold(0)$0" -> "np(0)"	[label=cuda];
	"y_train_fold(0)$0" -> "torch(0)"	[label=cuda];
	"y_train_fold(0)$0" -> "y_train(0)$0"	[label=cuda];
	"y_train_fold(0)$0" -> "train_idx(0)"	[label=cuda];
	"x_val_fold(0)$0" -> "torch(0)"	[label=cuda];
	"x_val_fold(0)$0" -> "X_train(0)$0"	[label=cuda];
	"x_val_fold(0)$0" -> "valid_idx(0)"	[label=cuda];
	"y_val_fold(0)$0" -> "np(0)"	[label=cuda];
	"y_val_fold(0)$0" -> "torch(0)"	[label=cuda];
	"y_val_fold(0)$0" -> "y_train(0)$0"	[label=cuda];
	"y_val_fold(0)$0" -> "valid_idx(0)"	[label=cuda];
	"train(0)$7" -> "torch(0)"	[label=TensorDataset];
	"train(0)$7" -> "x_train_fold(0)$0"	[label=TensorDataset];
	"train(0)$7" -> "y_train_fold(0)$0"	[label=TensorDataset];
	"valid(0)$0" -> "torch(0)"	[label=TensorDataset];
	"valid(0)$0" -> "x_val_fold(0)$0"	[label=TensorDataset];
	"valid(0)$0" -> "y_val_fold(0)$0"	[label=TensorDataset];
	"train_loader(0)$0" -> "torch(0)"	[label=DataLoader];
	"train_loader(0)$0" -> "True(0)"	[label=DataLoader];
	"train_loader(0)$0" -> "batch_size(0)$0"	[label=DataLoader];
	"train_loader(0)$0" -> "train(0)$7"	[label=DataLoader];
	"valid_loader(0)$0" -> "torch(0)"	[label=DataLoader];
	"valid_loader(0)$0" -> "batch_size(0)$0"	[label=DataLoader];
	"valid_loader(0)$0" -> "False(0)"	[label=DataLoader];
	"valid_loader(0)$0" -> "valid(0)$0"	[label=DataLoader];
	"Fold (0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"print[408/4]" -> "1(0)"	[label=print];
	"print[408/4]" -> "i(0)"	[label=print];
	"print[408/4]" -> "Fold (0)"	[label=print];
	"seed_everything[410/4]" -> "i(0)"	[label=seed_everything];
	"seed_everything[410/4]" -> "seed(0)$0"	[label=seed_everything];
	"model(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"model(0)$0" -> "model(0)"	[label=cuda];
	"valid_preds_fold(0)$0" -> "False(0)"	[label=train_model];
	"valid_preds_fold(0)$0" -> "x_train_fold(0)$0"	[label=train_model];
	"valid_preds_fold(0)$0" -> "y_train_fold(0)$0"	[label=train_model];
	"valid_preds_fold(0)$0" -> "x_val_fold(0)$0"	[label=train_model];
	"valid_preds_fold(0)$0" -> "y_val_fold(0)$0"	[label=train_model];
	"valid_preds_fold(0)$0" -> "model(0)$0"	[label=train_model];
	"test_preds_fold(0)$0" -> "False(0)"	[label=train_model];
	"test_preds_fold(0)$0" -> "x_train_fold(0)$0"	[label=train_model];
	"test_preds_fold(0)$0" -> "y_train_fold(0)$0"	[label=train_model];
	"test_preds_fold(0)$0" -> "x_val_fold(0)$0"	[label=train_model];
	"test_preds_fold(0)$0" -> "y_val_fold(0)$0"	[label=train_model];
	"test_preds_fold(0)$0" -> "model(0)$0"	[label=train_model];
	"train_preds(0)$1" -> "train_preds(0)$0"	[label=assignedFrom];
	"train_preds(0)$1" -> "valid_preds_fold(0)$0"	[label=assignedFrom];
	"test_preds(0)$1" -> "test_preds(0)$0"	[label=assignedFrom];
	"test_preds(0)$1" -> "test_preds_fold(0)$0"	[label=assignedFrom];
	"search_result(0)$0" -> "y_train(0)$0"	[label=threshold_search];
	"search_result(0)$0" -> "train_preds(0)$1"	[label=threshold_search];
	"sub(0)$1" -> "sub(0)$0"	[label=assignedFrom];
	"sub(0)$1" -> "1(0)"	[label=assignedFrom];
	"sub(0)$1" -> "test_preds(0)$1"	[label=assignedFrom];
	"sub(0)$1" -> "search_result(0)$0"	[label=assignedFrom];
	"sub(0)$1" -> "threshold(0)"	[label=assignedFrom];
	"threshold(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
	"sub(0)$2" -> "sub(0)$1"	[label=to_csv];
	"sub(0)$2" -> "submission.csv(0)"	[label=to_csv];
	"submission.csv(0)" -> "text-modelling-in-pytorch.ipynb"	[label=appearsIn];
}
