digraph "" {
	pandas -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=importedBy];
	"pd(0)" -> pandas	[label=assignedFrom];
	"pd(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	numpy -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=importedBy];
	"np(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"np(0)" -> numpy	[label=assignedFrom];
	operator -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=importedBy];
	"operator(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"operator(0)" -> operator	[label=assignedFrom];
	re -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=importedBy];
	"re(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"re(0)" -> re	[label=assignedFrom];
	gc -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=importedBy];
	"gc(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"gc(0)" -> gc	[label=assignedFrom];
	keras -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=importedBy];
	"keras(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"keras(0)" -> keras	[label=assignedFrom];
	seaborn -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=importedBy];
	"sns(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"sns(0)" -> seaborn	[label=assignedFrom];
	"matplotlib.pyplot" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=importedBy];
	"plt(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"plt(0)" -> "matplotlib.pyplot"	[label=assignedFrom];
	"sns(0)$0" -> "sns(0)"	[label=set_style];
	"sns(0)$0" -> "whitegrid(0)"	[label=set_style];
	"whitegrid(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"train(0)$0" -> "pd(0)"	[label=read_csv];
	"train(0)$0" -> "../input/train.csv(0)"	[label=read_csv];
	"../input/train.csv(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"test(0)$0" -> "pd(0)"	[label=read_csv];
	"test(0)$0" -> "../input/test.csv(0)"	[label=read_csv];
	"../input/test.csv(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"df(0)$0" -> "pd(0)"	[label=concat];
	"df(0)$0" -> "[<_ast.Name object at 0x7fd4c04ff7c0>, <_ast.Name object at 0x7fd4c04ffc40>](0)"	[label=concat];
	"[<_ast.Name object at 0x7fd4c04ff7c0>, <_ast.Name object at 0x7fd4c04ffc40>](0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"Number of texts: (0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"print[14/0]" -> "df(0)$0"	[label=print];
	"print[14/0]" -> "Number of texts: (0)"	[label=print];
	"print[14/0]" -> "0(0)"	[label=print];
	"0(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"file(1)" -> "load_embed[0]"	[label=_argToVar];
	"word(2)" -> "get_coefs[0]"	[label=_argToVar];
	"embeddings_index(1)$0" -> "file(1)"	[label=dict];
	"embeddings_index(1)$0" -> "get_coefs(1)"	[label=dict];
	"embeddings_index(1)$0" -> "o(1)"	[label=dict];
	"embeddings_index(1)$0" -> " (1)"	[label=dict];
	"embeddings_index(1)$0" -> "open(1)"	[label=dict];
	"embeddings_index(1)$0" -> "len(1)"	[label=dict];
	"embeddings_index(1)$0" -> "100(1)"	[label=dict];
	"embeddings_index(1)$1" -> "file(1)"	[label=dict];
	"embeddings_index(1)$1" -> "get_coefs(1)"	[label=dict];
	"embeddings_index(1)$1" -> "o(1)"	[label=dict];
	"embeddings_index(1)$1" -> " (1)"	[label=dict];
	"embeddings_index(1)$1" -> "open(1)"	[label=dict];
	"embeddings_index(1)$1" -> "latin(1)"	[label=dict];
	"../input/embeddings/glove.840B.300d/glove.840B.300d.txt(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"glove(0)$0" -> "../input/embeddings/glove.840B.300d/glove.840B.300d.txt(0)"	[label=assignedFrom];
	"Extracting GloVe embedding(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"print[26/0]" -> "Extracting GloVe embedding(0)"	[label=print];
	"embed_glove(0)$0" -> "glove(0)$0"	[label=load_embed];
	"texts(3)" -> "build_vocab[0]"	[label=_argToVar];
	"sentences(3)$0" -> "texts(3)"	[label=assignedFrom];
	"sentences(3)$0" -> "x(3)"	[label=assignedFrom];
	"sentence(3)" -> "sentences(3)$0"	[label=iteratorOf];
	"word(3)" -> "sentence(3)"	[label=iteratorOf];
	"vocab(3)$0" -> "1(3)"	[label=Add];
	"vocab(3)$0" -> "vocab(3)"	[label=Add];
	"vocab(3)$1" -> "vocab(3)$0"	[label=assignedFrom];
	"vocab(3)$1" -> "1(3)"	[label=assignedFrom];
	"vocab(4)" -> "check_coverage[0]"	[label=_argToVar];
	"embeddings_index(4)" -> "check_coverage[1]"	[label=_argToVar];
	"nb_known_words(4)$0" -> "0(4)"	[label=assignedFrom];
	"nb_unknown_words(4)$0" -> "0(4)"	[label=assignedFrom];
	"word(4)" -> "vocab(4)"	[label=iteratorOf];
	"known_words(4)$0" -> "embeddings_index(4)"	[label=assignedFrom];
	"known_words(4)$0" -> "word(4)"	[label=assignedFrom];
	"known_words(4)$0" -> "known_words(4)"	[label=assignedFrom];
	"nb_known_words(4)$1" -> "vocab(4)"	[label=Add];
	"nb_known_words(4)$1" -> "nb_known_words(4)$0"	[label=Add];
	"nb_known_words(4)$1" -> "word(4)"	[label=Add];
	"unknown_words(4)$0" -> "vocab(4)"	[label=assignedFrom];
	"unknown_words(4)$0" -> "word(4)"	[label=assignedFrom];
	"unknown_words(4)$0" -> "unknown_words(4)"	[label=assignedFrom];
	"nb_unknown_words(4)$1" -> "vocab(4)"	[label=Add];
	"nb_unknown_words(4)$1" -> "nb_unknown_words(4)$0"	[label=Add];
	"nb_unknown_words(4)$1" -> "word(4)"	[label=Add];
	"print[52/4]" -> "vocab(4)"	[label=print];
	"print[52/4]" -> "known_words(4)$0"	[label=print];
	"print[52/4]" -> "Found embeddings for {:.3\%} of vocab(4)"	[label=print];
	"print[52/4]" -> "len(4)"	[label=print];
	"print[53/4]" -> "nb_known_words(4)$1"	[label=print];
	"print[53/4]" -> "nb_unknown_words(4)$1"	[label=print];
	"print[53/4]" -> "Found embeddings for  {:.3\%} of all text(4)"	[label=print];
	"unknown_words(4)$1" -> "unknown_words(4)$1"	[label=assignedFrom];
	"unknown_words(4)$1" -> "sorted(4)"	[label=assignedFrom];
	"unknown_words(4)$1" -> "operator(4)"	[label=assignedFrom];
	"unknown_words(4)$1" -> "1(4)"	[label=assignedFrom];
	"vocab(0)$0" -> "df(0)$0"	[label=build_vocab];
	"vocab(0)$0" -> "question_text(0)"	[label=build_vocab];
	"question_text(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"Glove : (0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"print[58/0]" -> "Glove : (0)"	[label=print];
	"oov_glove(0)$0" -> "embed_glove(0)$0"	[label=check_coverage];
	"oov_glove(0)$0" -> "vocab(0)$0"	[label=check_coverage];
	"df(0)$1" -> "df(0)$0"	[label=apply];
	"df(0)$1" -> "question_text(0)"	[label=apply];
	"df(0)$1" -> "x(0)"	[label=apply];
	"x(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"embedding(5)" -> "add_lower[0]"	[label=_argToVar];
	"vocab(5)" -> "add_lower[1]"	[label=_argToVar];
	"count(5)$0" -> "0(5)"	[label=assignedFrom];
	"word(5)" -> "vocab(5)"	[label=iteratorOf];
	"embedding(5)$0" -> "embedding(5)"	[label=assignedFrom];
	"embedding(5)$0" -> "word(5)"	[label=assignedFrom];
	"count(5)$1" -> "count(5)$0"	[label=Add];
	"count(5)$1" -> "1(5)"	[label=Add];
	"print[67/4]" -> "count(5)$1"	[label=print];
	"print[67/4]" -> "Added (5)"	[label=print];
	"print[67/4]" -> " words to embedding(5)"	[label=print];
	"print[68/0]" -> "Glove : (0)"	[label=print];
	"oov_glove(0)$1" -> "embed_glove(0)$0"	[label=check_coverage];
	"oov_glove(0)$1" -> "vocab(0)$0"	[label=check_coverage];
	"add_lower[70/0]" -> "embed_glove(0)$0"	[label=add_lower];
	"add_lower[70/0]" -> "vocab(0)$0"	[label=add_lower];
	"oov_glove(0)$2" -> "embed_glove(0)$0"	[label=check_coverage];
	"oov_glove(0)$2" -> "vocab(0)$0"	[label=check_coverage];
	"ain't(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"contraction_mapping(0)$0" -> "ain't(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "aren't(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "can't(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "'cause(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "could've(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "couldn't(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "didn't(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "doesn't(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "don't(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "hadn't(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "hasn't(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "haven't(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "he'd(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "he'll(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "he's(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "how'd(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "how'd'y(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "how'll(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "how's(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "I'd(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "I'd've(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "I'll(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "I'll've(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "I'm(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "I've(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "i'd(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "i'd've(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "i'll(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "i'll've(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "i'm(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "i've(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "isn't(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "it'd(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "it'd've(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "it'll(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "it'll've(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "it's(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "let's(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "ma'am(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "mayn't(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "might've(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "mightn't(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "mightn't've(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "must've(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "mustn't(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "mustn't've(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "needn't(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "needn't've(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "o'clock(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "oughtn't(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "oughtn't've(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "shan't(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "sha'n't(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "shan't've(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "she'd(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "she'd've(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "she'll(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "she'll've(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "she's(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "should've(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "shouldn't(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "shouldn't've(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "so've(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "so's(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "this's(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "that'd(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "that'd've(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "that's(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "there'd(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "there'd've(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "there's(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "here's(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "they'd(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "they'd've(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "they'll(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "they'll've(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "they're(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "they've(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "to've(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "wasn't(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "we'd(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "we'd've(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "we'll(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "we'll've(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "we're(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "we've(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "weren't(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "what'll(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "what'll've(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "what're(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "what's(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "what've(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "when's(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "when've(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "where'd(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "where's(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "where've(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "who'll(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "who'll've(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "who's(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "who've(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "why's(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "why've(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "will've(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "won't(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "won't've(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "would've(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "wouldn't(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "wouldn't've(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "y'all(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "y'all'd(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "y'all'd've(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "y'all're(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "y'all've(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "you'd(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "you'd've(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "you'll(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "you'll've(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "you're(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "you've(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "is not(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "are not(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "cannot(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "because(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "could have(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "could not(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "did not(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "does not(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "do not(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "had not(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "has not(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "have not(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "he would(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "he will(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "he is(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "how did(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "how do you(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "how will(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "how is(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "I would(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "I would have(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "I will(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "I will have(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "I am(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "I have(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "i would(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "i would have(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "i will(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "i will have(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "i am(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "i have(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "it would(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "it would have(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "it will(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "it will have(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "it is(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "let us(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "madam(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "may not(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "might have(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "might not(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "might not have(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "must have(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "must not(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "must not have(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "need not(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "need not have(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "of the clock(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "ought not(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "ought not have(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "shall not(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "shall not have(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "she would(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "she would have(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "she will(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "she will have(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "she is(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "should have(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "should not(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "should not have(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "so have(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "so as(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "this is(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "that would(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "that would have(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "that is(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "there would(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "there would have(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "there is(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "here is(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "they would(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "they would have(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "they will(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "they will have(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "they are(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "they have(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "to have(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "was not(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "we would(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "we would have(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "we will(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "we will have(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "we are(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "we have(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "were not(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "what will(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "what will have(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "what are(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "what is(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "what have(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "when is(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "when have(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "where did(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "where is(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "where have(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "who will(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "who will have(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "who is(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "who have(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "why is(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "why have(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "will have(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "will not(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "will not have(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "would have(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "would not(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "would not have(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "you all(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "you all would(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "you all would have(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "you all are(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "you all have(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "you would(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "you would have(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "you will(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "you will have(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "you are(0)"	[label=assignedFrom];
	"contraction_mapping(0)$0" -> "you have(0)"	[label=assignedFrom];
	"aren't(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"can't(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"'cause(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"could've(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"couldn't(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"didn't(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"doesn't(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"don't(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"hadn't(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"hasn't(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"haven't(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"he'd(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"he'll(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"he's(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"how'd(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"how'd'y(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"how'll(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"how's(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"I'd(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"I'd've(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"I'll(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"I'll've(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"I'm(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"I've(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"i'd(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"i'd've(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"i'll(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"i'll've(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"i'm(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"i've(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"isn't(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"it'd(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"it'd've(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"it'll(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"it'll've(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"it's(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"let's(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"ma'am(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"mayn't(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"might've(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"mightn't(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"mightn't've(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"must've(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"mustn't(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"mustn't've(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"needn't(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"needn't've(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"o'clock(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"oughtn't(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"oughtn't've(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"shan't(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"sha'n't(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"shan't've(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"she'd(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"she'd've(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"she'll(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"she'll've(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"she's(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"should've(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"shouldn't(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"shouldn't've(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"so've(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"so's(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"this's(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"that'd(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"that'd've(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"that's(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"there'd(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"there'd've(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"there's(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"here's(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"they'd(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"they'd've(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"they'll(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"they'll've(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"they're(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"they've(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"to've(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"wasn't(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"we'd(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"we'd've(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"we'll(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"we'll've(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"we're(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"we've(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"weren't(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"what'll(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"what'll've(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"what're(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"what's(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"what've(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"when's(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"when've(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"where'd(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"where's(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"where've(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"who'll(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"who'll've(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"who's(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"who've(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"why's(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"why've(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"will've(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"won't(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"won't've(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"would've(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"wouldn't(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"wouldn't've(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"y'all(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"y'all'd(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"y'all'd've(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"y'all're(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"y'all've(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"you'd(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"you'd've(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"you'll(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"you'll've(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"you're(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"you've(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"is not(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"are not(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"cannot(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"because(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"could have(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"could not(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"did not(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"does not(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"do not(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"had not(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"has not(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"have not(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"he would(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"he will(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"he is(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"how did(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"how do you(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"how will(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"how is(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"I would(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"I would have(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"I will(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"I will have(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"I am(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"I have(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"i would(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"i would have(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"i will(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"i will have(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"i am(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"i have(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"it would(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"it would have(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"it will(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"it will have(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"it is(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"let us(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"madam(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"may not(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"might have(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"might not(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"might not have(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"must have(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"must not(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"must not have(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"need not(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"need not have(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"of the clock(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"ought not(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"ought not have(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"shall not(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"shall not have(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"she would(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"she would have(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"she will(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"she will have(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"she is(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"should have(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"should not(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"should not have(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"so have(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"so as(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"this is(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"that would(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"that would have(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"that is(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"there would(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"there would have(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"there is(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"here is(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"they would(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"they would have(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"they will(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"they will have(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"they are(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"they have(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"to have(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"was not(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"we would(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"we would have(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"we will(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"we will have(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"we are(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"we have(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"were not(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"what will(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"what will have(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"what are(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"what is(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"what have(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"when is(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"when have(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"where did(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"where is(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"where have(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"who will(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"who will have(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"who is(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"who have(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"why is(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"why have(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"will have(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"will not(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"will not have(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"would have(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"would not(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"would not have(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"you all(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"you all would(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"you all would have(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"you all are(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"you all have(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"you would(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"you would have(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"you will(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"you will have(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"you are(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"you have(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"embed(6)" -> "known_contractions[0]"	[label=_argToVar];
	"known(6)$0" -> "[](6)"	[label=assignedFrom];
	"contract(6)" -> "contraction_mapping(6)"	[label=iteratorOf];
	"known(6)$1" -> "known(6)$0"	[label=append];
	"known(6)$1" -> "contract(6)"	[label=append];
	"- Known Contractions -(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"print[80/0]" -> "- Known Contractions -(0)"	[label=print];
	"   Glove :(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"print[81/0]" -> "   Glove :(0)"	[label=print];
	"known_contractions(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"print[82/0]" -> "embed_glove(0)$0"	[label=print];
	"print[82/0]" -> "known_contractions(0)"	[label=print];
	"text(7)" -> "clean_contractions[0]"	[label=_argToVar];
	"mapping(7)" -> "clean_contractions[1]"	[label=_argToVar];
	"specials(7)$0" -> "[<_ast.Constant object at 0x7fd4c05b2c40>, <_ast.Constant object at 0x7fd4c05b21f0>, <_ast.Constant object at 0x7fd4c05b2220>, <_\
ast.Constant object at 0x7fd4c05b2130>](7)"	[label=assignedFrom];
	"s(7)" -> "specials(7)$0"	[label=iteratorOf];
	"text(7)$0" -> "text(7)"	[label=replace];
	"text(7)$0" -> "s(7)"	[label=replace];
	"text(7)$0" -> "'(7)"	[label=replace];
	"text(7)$1" -> "mapping(7)"	[label=join];
	"text(7)$1" -> "text(7)$1"	[label=join];
	"text(7)$1" -> " (7)"	[label=join];
	"text(7)$1" -> "t(7)"	[label=join];
	"df(0)$2" -> "df(0)$1"	[label=apply];
	"df(0)$2" -> "x(0)"	[label=apply];
	"df(0)$2" -> "contraction_mapping(0)$0"	[label=apply];
	"df(0)$2" -> "lowered_question(0)"	[label=apply];
	"df(0)$2" -> "clean_contractions(0)"	[label=apply];
	"lowered_question(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"clean_contractions(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"vocab(0)$1" -> "df(0)$2"	[label=build_vocab];
	"vocab(0)$1" -> "treated_question(0)"	[label=build_vocab];
	"treated_question(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"print[91/0]" -> "Glove : (0)"	[label=print];
	"oov_glove(0)$3" -> "embed_glove(0)$0"	[label=check_coverage];
	"oov_glove(0)$3" -> "vocab(0)$1"	[label=check_coverage];
	"/-'?!.,#$\%'()*+-/:;<=>@[\]^_`{|}~(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"punct(0)$0" -> "/-'?!.,#$\%'()*+-/:;<=>@[\]^_`{|}~(0)"	[label=Add];
	"punct(0)$0" -> "\"\"“”’(0)"	[label=Add];
	"punct(0)$0" -> "∞θ÷α•à−β∅³π‘₹´°£€\×™√²—–&(0)"	[label=Add];
	"\"\"“”’(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"∞θ÷α•à−β∅³π‘₹´°£€\×™√²—–&(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"embed(8)" -> "unknown_punct[0]"	[label=_argToVar];
	"punct(8)" -> "unknown_punct[1]"	[label=_argToVar];
	"unknown(8)$0" -> "(8)"	[label=assignedFrom];
	"p(8)" -> "punct(8)"	[label=iteratorOf];
	"unknown(8)$1" -> "unknown(8)$0"	[label=Add];
	"unknown(8)$1" -> "p(8)"	[label=Add];
	"unknown(8)$2" -> "unknown(8)$1"	[label=Add];
	"unknown(8)$2" -> " (8)"	[label=Add];
	"Glove :(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"print[101/0]" -> "Glove :(0)"	[label=print];
	"unknown_punct(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"print[102/0]" -> "embed_glove(0)$0"	[label=print];
	"print[102/0]" -> "punct(0)$0"	[label=print];
	"print[102/0]" -> "unknown_punct(0)"	[label=print];
	"‘(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"punct_mapping(0)$0" -> "x(0)"	[label=assignedFrom];
	"punct_mapping(0)$0" -> "‘(0)"	[label=assignedFrom];
	"punct_mapping(0)$0" -> "₹(0)"	[label=assignedFrom];
	"punct_mapping(0)$0" -> "´(0)"	[label=assignedFrom];
	"punct_mapping(0)$0" -> "°(0)"	[label=assignedFrom];
	"punct_mapping(0)$0" -> "€(0)"	[label=assignedFrom];
	"punct_mapping(0)$0" -> "™(0)"	[label=assignedFrom];
	"punct_mapping(0)$0" -> "√(0)"	[label=assignedFrom];
	"punct_mapping(0)$0" -> "×(0)"	[label=assignedFrom];
	"punct_mapping(0)$0" -> "²(0)"	[label=assignedFrom];
	"punct_mapping(0)$0" -> "—(0)"	[label=assignedFrom];
	"punct_mapping(0)$0" -> "–(0)"	[label=assignedFrom];
	"punct_mapping(0)$0" -> "’(0)"	[label=assignedFrom];
	"punct_mapping(0)$0" -> "_(0)"	[label=assignedFrom];
	"punct_mapping(0)$0" -> "`(0)"	[label=assignedFrom];
	"punct_mapping(0)$0" -> "“(0)"	[label=assignedFrom];
	"punct_mapping(0)$0" -> "”(0)"	[label=assignedFrom];
	"punct_mapping(0)$0" -> "£(0)"	[label=assignedFrom];
	"punct_mapping(0)$0" -> "∞(0)"	[label=assignedFrom];
	"punct_mapping(0)$0" -> "θ(0)"	[label=assignedFrom];
	"punct_mapping(0)$0" -> "÷(0)"	[label=assignedFrom];
	"punct_mapping(0)$0" -> "α(0)"	[label=assignedFrom];
	"punct_mapping(0)$0" -> "•(0)"	[label=assignedFrom];
	"punct_mapping(0)$0" -> "à(0)"	[label=assignedFrom];
	"punct_mapping(0)$0" -> "−(0)"	[label=assignedFrom];
	"punct_mapping(0)$0" -> "β(0)"	[label=assignedFrom];
	"punct_mapping(0)$0" -> "∅(0)"	[label=assignedFrom];
	"punct_mapping(0)$0" -> "³(0)"	[label=assignedFrom];
	"punct_mapping(0)$0" -> "π(0)"	[label=assignedFrom];
	"punct_mapping(0)$0" -> "'(0)"	[label=assignedFrom];
	"punct_mapping(0)$0" -> "e(0)"	[label=assignedFrom];
	"punct_mapping(0)$0" -> "(0)"	[label=assignedFrom];
	"punct_mapping(0)$0" -> "tm(0)"	[label=assignedFrom];
	"punct_mapping(0)$0" -> " sqrt (0)"	[label=assignedFrom];
	"punct_mapping(0)$0" -> "2(0)"	[label=assignedFrom];
	"punct_mapping(0)$0" -> "-(0)"	[label=assignedFrom];
	"punct_mapping(0)$0" -> "\"(0)"	[label=assignedFrom];
	"punct_mapping(0)$0" -> "infinity(0)"	[label=assignedFrom];
	"punct_mapping(0)$0" -> "theta(0)"	[label=assignedFrom];
	"punct_mapping(0)$0" -> "/(0)"	[label=assignedFrom];
	"punct_mapping(0)$0" -> "alpha(0)"	[label=assignedFrom];
	"punct_mapping(0)$0" -> ".(0)"	[label=assignedFrom];
	"punct_mapping(0)$0" -> "a(0)"	[label=assignedFrom];
	"punct_mapping(0)$0" -> "beta(0)"	[label=assignedFrom];
	"punct_mapping(0)$0" -> "3(0)"	[label=assignedFrom];
	"punct_mapping(0)$0" -> "pi(0)"	[label=assignedFrom];
	"₹(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"´(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"°(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"€(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"™(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"√(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"×(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"²(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"—(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"–(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"’(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"_(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"`(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"“(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"”(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"£(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"∞(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"θ(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"÷(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"α(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"•(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"à(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"−(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"β(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"∅(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"³(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"π(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"'(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"e(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"tm(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	" sqrt (0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"2(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"-(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"\"(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"infinity(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"theta(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"/(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"alpha(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	".(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"a(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"beta(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"3(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"pi(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"text(9)" -> "clean_special_chars[0]"	[label=_argToVar];
	"punct(9)" -> "clean_special_chars[1]"	[label=_argToVar];
	"mapping(9)" -> "clean_special_chars[2]"	[label=_argToVar];
	"p(9)" -> "punct(9)"	[label=iteratorOf];
	"p(9)" -> "mapping(9)"	[label=iteratorOf];
	"text(9)$0" -> "text(9)"	[label=replace];
	"text(9)$0" -> "mapping(9)"	[label=replace];
	"text(9)$0" -> "p(9)"	[label=replace];
	"text(9)$1" -> "p(9)"	[label=replace];
	"text(9)$1" -> "text(9)$0"	[label=replace];
	"text(9)$1" -> " (9)"	[label=replace];
	"specials(9)$0" -> " (9)"	[label=assignedFrom];
	"specials(9)$0" -> "​(9)"	[label=assignedFrom];
	"specials(9)$0" -> "…(9)"	[label=assignedFrom];
	"specials(9)$0" -> "﻿(9)"	[label=assignedFrom];
	"specials(9)$0" -> "करना(9)"	[label=assignedFrom];
	"specials(9)$0" -> "है(9)"	[label=assignedFrom];
	"specials(9)$0" -> " ... (9)"	[label=assignedFrom];
	"specials(9)$0" -> "(9)"	[label=assignedFrom];
	"s(9)" -> "specials(9)$0"	[label=iteratorOf];
	"text(9)$2" -> "text(9)$1"	[label=replace];
	"text(9)$2" -> "specials(9)$0"	[label=replace];
	"text(9)$2" -> "s(9)"	[label=replace];
	"df(0)$3" -> "x(0)"	[label=apply];
	"df(0)$3" -> "df(0)$2"	[label=apply];
	"df(0)$3" -> "treated_question(0)"	[label=apply];
	"df(0)$3" -> "punct(0)$0"	[label=apply];
	"df(0)$3" -> "punct_mapping(0)$0"	[label=apply];
	"df(0)$3" -> "clean_special_chars(0)"	[label=apply];
	"clean_special_chars(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"vocab(0)$2" -> "treated_question(0)"	[label=build_vocab];
	"vocab(0)$2" -> "df(0)$3"	[label=build_vocab];
	"print[118/0]" -> "Glove : (0)"	[label=print];
	"oov_glove(0)$4" -> "embed_glove(0)$0"	[label=check_coverage];
	"oov_glove(0)$4" -> "vocab(0)$2"	[label=check_coverage];
	"colour(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"mispell_dict(0)$0" -> "what are(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "colour(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "centre(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "favourite(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "travelling(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "counselling(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "theatre(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "cancelled(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "labour(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "organisation(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "wwii(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "citicise(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "youtu (0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "Qoura(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "sallary(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "Whta(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "narcisist(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "howdo(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "whatare(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "howcan(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "howmuch(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "howmany(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "whydo(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "doI(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "theBest(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "howdoes(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "mastrubation(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "mastrubate(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "mastrubating(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "pennis(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "Etherium(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "narcissit(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "bigdata(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "2k17(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "2k18(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "qouta(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "exboyfriend(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "airhostess(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "whst(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "watsapp(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "demonitisation(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "demonitization(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "demonetisation(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "pokémon(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "color(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "center(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "favorite(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "traveling(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "counseling(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "theater(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "canceled(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "labor(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "organization(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "world war 2(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "criticize(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "youtube (0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "Quora(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "salary(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "What(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "narcissist(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "how do(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "how can(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "how much(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "how many(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "why do(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "do I(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "the best(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "how does(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "masturbation(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "masturbate(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "masturbating(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "penis(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "Ethereum(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "big data(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "2017(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "2018(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "quota(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "ex boyfriend(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "air hostess(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "what(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "whatsapp(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "demonetization(0)"	[label=assignedFrom];
	"mispell_dict(0)$0" -> "pokemon(0)"	[label=assignedFrom];
	"centre(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"favourite(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"travelling(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"counselling(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"theatre(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"cancelled(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"labour(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"organisation(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"wwii(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"citicise(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"youtu (0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"Qoura(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"sallary(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"Whta(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"narcisist(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"howdo(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"whatare(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"howcan(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"howmuch(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"howmany(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"whydo(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"doI(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"theBest(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"howdoes(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"mastrubation(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"mastrubate(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"mastrubating(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"pennis(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"Etherium(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"narcissit(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"bigdata(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"2k17(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"2k18(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"qouta(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"exboyfriend(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"airhostess(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"whst(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"watsapp(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"demonitisation(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"demonitization(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"demonetisation(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"pokémon(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"color(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"center(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"favorite(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"traveling(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"counseling(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"theater(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"canceled(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"labor(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"organization(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"world war 2(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"criticize(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"youtube (0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"Quora(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"salary(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"What(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"narcissist(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"how do(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"how can(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"how much(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"how many(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"why do(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"do I(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"the best(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"how does(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"masturbation(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"masturbate(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"masturbating(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"penis(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"Ethereum(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"big data(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"2017(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"2018(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"quota(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"ex boyfriend(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"air hostess(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"what(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"whatsapp(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"demonetization(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"pokemon(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"x(10)" -> "correct_spelling[0]"	[label=_argToVar];
	"dic(10)" -> "correct_spelling[1]"	[label=_argToVar];
	"word(10)" -> "dic(10)"	[label=iteratorOf];
	"x(10)$0" -> "x(10)"	[label=replace];
	"x(10)$0" -> "dic(10)"	[label=replace];
	"x(10)$0" -> "word(10)"	[label=replace];
	"df(0)$4" -> "x(0)"	[label=apply];
	"df(0)$4" -> "treated_question(0)"	[label=apply];
	"df(0)$4" -> "df(0)$3"	[label=apply];
	"df(0)$4" -> "mispell_dict(0)$0"	[label=apply];
	"df(0)$4" -> "correct_spelling(0)"	[label=apply];
	"correct_spelling(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"vocab(0)$3" -> "treated_question(0)"	[label=build_vocab];
	"vocab(0)$3" -> "df(0)$4"	[label=build_vocab];
	"print[128/0]" -> "Glove : (0)"	[label=print];
	"oov_glove(0)$5" -> "embed_glove(0)$0"	[label=check_coverage];
	"oov_glove(0)$5" -> "vocab(0)$3"	[label=check_coverage];
	"gc(0)$0" -> "gc(0)"	[label=collect];
	"train(0)$1" -> "train(0)$0"	[label=apply];
	"train(0)$1" -> "question_text(0)"	[label=apply];
	"train(0)$1" -> "x(0)"	[label=apply];
	"train(0)$2" -> "x(0)"	[label=apply];
	"train(0)$2" -> "contraction_mapping(0)$0"	[label=apply];
	"train(0)$2" -> "clean_contractions(0)"	[label=apply];
	"train(0)$2" -> "treated_question(0)"	[label=apply];
	"train(0)$2" -> "train(0)$1"	[label=apply];
	"train(0)$3" -> "x(0)"	[label=apply];
	"train(0)$3" -> "treated_question(0)"	[label=apply];
	"train(0)$3" -> "punct(0)$0"	[label=apply];
	"train(0)$3" -> "punct_mapping(0)$0"	[label=apply];
	"train(0)$3" -> "clean_special_chars(0)"	[label=apply];
	"train(0)$3" -> "train(0)$2"	[label=apply];
	"train(0)$4" -> "x(0)"	[label=apply];
	"train(0)$4" -> "treated_question(0)"	[label=apply];
	"train(0)$4" -> "mispell_dict(0)$0"	[label=apply];
	"train(0)$4" -> "correct_spelling(0)"	[label=apply];
	"train(0)$4" -> "train(0)$3"	[label=apply];
	"95000(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"len_voc(0)$0" -> "95000(0)"	[label=assignedFrom];
	"60(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"max_len(0)$0" -> "60(0)"	[label=assignedFrom];
	"keras.preprocessing.text" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=importedBy];
	Tokenizer -> "keras.preprocessing.text"	[label=importedBy];
	"Tokenizer(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"Tokenizer(0)" -> Tokenizer	[label=assignedFrom];
	"keras.preprocessing.sequence" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=importedBy];
	pad_sequences -> "keras.preprocessing.sequence"	[label=importedBy];
	"pad_sequences(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"pad_sequences(0)" -> pad_sequences	[label=assignedFrom];
	"X(11)" -> "make_data[0]"	[label=_argToVar];
	"t(11)$0" -> "len_voc(11)"	[label=Tokenizer];
	"t(11)$1" -> "X(11)"	[label=fit_on_texts];
	"t(11)$1" -> "t(11)$0"	[label=fit_on_texts];
	"X(11)$0" -> "t(11)$1"	[label=texts_to_sequences];
	"X(11)$0" -> "X(11)$0"	[label=texts_to_sequences];
	"X(11)$1" -> "X(11)$0"	[label=pad_sequences];
	"X(11)$1" -> "max_len(11)"	[label=pad_sequences];
	"X(0)$0" -> "question_text(0)"	[label=make_data];
	"X(0)$0" -> "train(0)$4"	[label=make_data];
	"word_index(0)$0" -> "question_text(0)"	[label=make_data];
	"word_index(0)$0" -> "train(0)$4"	[label=make_data];
	"X(12)" -> "make_treated_data[0]"	[label=_argToVar];
	"t(12)$0" -> "len_voc(12)"	[label=Tokenizer];
	"t(12)$0" -> "(12)"	[label=Tokenizer];
	"t(12)$1" -> "X(12)"	[label=fit_on_texts];
	"t(12)$1" -> "t(12)$0"	[label=fit_on_texts];
	"X(12)$0" -> "t(12)$1"	[label=texts_to_sequences];
	"X(12)$0" -> "X(12)$0"	[label=texts_to_sequences];
	"X(12)$1" -> "X(12)$0"	[label=pad_sequences];
	"X(12)$1" -> "max_len(12)"	[label=pad_sequences];
	"X_treated(0)$0" -> "treated_question(0)"	[label=make_data];
	"X_treated(0)$0" -> "train(0)$4"	[label=make_data];
	"word_index_treated(0)$0" -> "treated_question(0)"	[label=make_data];
	"word_index_treated(0)$0" -> "train(0)$4"	[label=make_data];
	"sklearn.model_selection" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=importedBy];
	train_test_split -> "sklearn.model_selection"	[label=importedBy];
	"train_test_split(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"train_test_split(0)" -> train_test_split	[label=assignedFrom];
	"y(0)$0" -> "train(0)$4"	[label=assignedFrom];
	"y(0)$0" -> "target(0)"	[label=assignedFrom];
	"target(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"X_train(0)$0" -> "X(0)$0"	[label=train_test_split];
	"X_train(0)$0" -> "y(0)$0"	[label=train_test_split];
	"X_train(0)$0" -> "0.1(0)"	[label=train_test_split];
	"X_train(0)$0" -> "420(0)"	[label=train_test_split];
	"0.1(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"420(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"X_val(0)$0" -> "X(0)$0"	[label=train_test_split];
	"X_val(0)$0" -> "y(0)$0"	[label=train_test_split];
	"X_val(0)$0" -> "0.1(0)"	[label=train_test_split];
	"X_val(0)$0" -> "420(0)"	[label=train_test_split];
	"y_train(0)$0" -> "X(0)$0"	[label=train_test_split];
	"y_train(0)$0" -> "y(0)$0"	[label=train_test_split];
	"y_train(0)$0" -> "0.1(0)"	[label=train_test_split];
	"y_train(0)$0" -> "420(0)"	[label=train_test_split];
	"y_val(0)$0" -> "X(0)$0"	[label=train_test_split];
	"y_val(0)$0" -> "y(0)$0"	[label=train_test_split];
	"y_val(0)$0" -> "0.1(0)"	[label=train_test_split];
	"y_val(0)$0" -> "420(0)"	[label=train_test_split];
	"X_t_train(0)$0" -> "X_treated(0)$0"	[label=train_test_split];
	"X_t_train(0)$0" -> "y(0)$0"	[label=train_test_split];
	"X_t_train(0)$0" -> "0.1(0)"	[label=train_test_split];
	"X_t_train(0)$0" -> "420(0)"	[label=train_test_split];
	"X_t_val(0)$0" -> "X_treated(0)$0"	[label=train_test_split];
	"X_t_val(0)$0" -> "y(0)$0"	[label=train_test_split];
	"X_t_val(0)$0" -> "0.1(0)"	[label=train_test_split];
	"X_t_val(0)$0" -> "420(0)"	[label=train_test_split];
	"_(0)$0" -> "X_treated(0)$0"	[label=train_test_split];
	"_(0)$0" -> "y(0)$0"	[label=train_test_split];
	"_(0)$0" -> "0.1(0)"	[label=train_test_split];
	"_(0)$0" -> "420(0)"	[label=train_test_split];
	"Training on (0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"print[162/0]" -> "0(0)"	[label=print];
	"print[162/0]" -> "X_train(0)$0"	[label=print];
	"print[162/0]" -> "Training on (0)"	[label=print];
	"print[162/0]" -> " texts(0)"	[label=print];
	" texts(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"embeddings_index(13)" -> "make_embed_matrix[0]"	[label=_argToVar];
	"word_index(13)" -> "make_embed_matrix[1]"	[label=_argToVar];
	"len_voc(13)" -> "make_embed_matrix[2]"	[label=_argToVar];
	"all_embs(13)$0" -> "embeddings_index(13)"	[label=stack];
	"all_embs(13)$0" -> "np(13)"	[label=stack];
	"emb_mean(13)$0" -> "all_embs(13)$0"	[label=assignedFrom];
	"emb_std(13)$0" -> "all_embs(13)$0"	[label=assignedFrom];
	"embed_size(13)$0" -> "all_embs(13)$0"	[label=assignedFrom];
	"embed_size(13)$0" -> "1(13)"	[label=assignedFrom];
	"word_index(13)$0" -> "word_index(13)"	[label=assignedFrom];
	"embedding_matrix(13)$0" -> "len_voc(13)"	[label=normal];
	"embedding_matrix(13)$0" -> "np(13)"	[label=normal];
	"embedding_matrix(13)$0" -> "emb_mean(13)$0"	[label=normal];
	"embedding_matrix(13)$0" -> "emb_std(13)$0"	[label=normal];
	"embedding_matrix(13)$0" -> "embed_size(13)$0"	[label=normal];
	"word(13)" -> "word_index(13)$0"	[label=iteratorOf];
	"i(13)" -> "word_index(13)$0"	[label=iteratorOf];
	"embedding_vector(13)$0" -> "embeddings_index(13)"	[label=get];
	"embedding_vector(13)$0" -> "word(13)"	[label=get];
	"embedding_matrix(13)$1" -> "embedding_matrix(13)$0"	[label=assignedFrom];
	"embedding_matrix(13)$1" -> "embedding_vector(13)$0"	[label=assignedFrom];
	"embedding(0)$0" -> "embed_glove(0)$0"	[label=make_embed_matrix];
	"embedding(0)$0" -> "len_voc(0)$0"	[label=make_embed_matrix];
	"embedding(0)$0" -> "word_index(0)$0"	[label=make_embed_matrix];
	"gc(0)$1" -> "gc(0)$0"	[label=collect];
	"embedding_treated(0)$0" -> "embed_glove(0)$0"	[label=make_embed_matrix];
	"embedding_treated(0)$0" -> "len_voc(0)$0"	[label=make_embed_matrix];
	"embedding_treated(0)$0" -> "word_index_treated(0)$0"	[label=make_embed_matrix];
	"gc(0)$2" -> "gc(0)$1"	[label=collect];
	backend -> keras	[label=importedBy];
	"K(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"K(0)" -> backend	[label=assignedFrom];
	"y_true(14)" -> "f1[0]"	[label=_argToVar];
	"y_pred(14)" -> "f1[1]"	[label=_argToVar];
	"y_true(15)" -> "recall[0]"	[label=_argToVar];
	"y_pred(15)" -> "recall[1]"	[label=_argToVar];
	"true_positives(15)$0" -> "y_true(15)"	[label=sum];
	"true_positives(15)$0" -> "y_pred(15)"	[label=sum];
	"true_positives(15)$0" -> "K(15)"	[label=sum];
	"true_positives(15)$0" -> "0(15)"	[label=sum];
	"true_positives(15)$0" -> "1(15)"	[label=sum];
	"possible_positives(15)$0" -> "y_true(15)"	[label=sum];
	"possible_positives(15)$0" -> "K(15)"	[label=sum];
	"possible_positives(15)$0" -> "0(15)"	[label=sum];
	"possible_positives(15)$0" -> "1(15)"	[label=sum];
	"recall(15)$0" -> "true_positives(15)$0"	[label=Div];
	"recall(15)$0" -> "K(15)"	[label=Div];
	"recall(15)$0" -> "possible_positives(15)$0"	[label=Div];
	"y_true(16)" -> "precision[0]"	[label=_argToVar];
	"y_pred(16)" -> "precision[1]"	[label=_argToVar];
	"true_positives(16)$0" -> "y_true(16)"	[label=sum];
	"true_positives(16)$0" -> "y_pred(16)"	[label=sum];
	"true_positives(16)$0" -> "K(16)"	[label=sum];
	"true_positives(16)$0" -> "0(16)"	[label=sum];
	"true_positives(16)$0" -> "1(16)"	[label=sum];
	"predicted_positives(16)$0" -> "y_pred(16)"	[label=sum];
	"predicted_positives(16)$0" -> "K(16)"	[label=sum];
	"predicted_positives(16)$0" -> "0(16)"	[label=sum];
	"predicted_positives(16)$0" -> "1(16)"	[label=sum];
	"precision(16)$0" -> "true_positives(16)$0"	[label=Div];
	"precision(16)$0" -> "K(16)"	[label=Div];
	"precision(16)$0" -> "predicted_positives(16)$0"	[label=Div];
	"precision(14)$0" -> "y_true(14)"	[label=precision];
	"precision(14)$0" -> "y_pred(14)"	[label=precision];
	"recall(14)$0" -> "y_true(14)"	[label=recall];
	"recall(14)$0" -> "y_pred(14)"	[label=recall];
	"keras.models" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=importedBy];
	Model -> "keras.models"	[label=importedBy];
	"Model(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"Model(0)" -> Model	[label=assignedFrom];
	"keras.layers" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=importedBy];
	Dense -> "keras.layers"	[label=importedBy];
	"Dense(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"Dense(0)" -> Dense	[label=assignedFrom];
	Embedding -> "keras.layers"	[label=importedBy];
	"Embedding(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"Embedding(0)" -> Embedding	[label=assignedFrom];
	Bidirectional -> "keras.layers"	[label=importedBy];
	"Bidirectional(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"Bidirectional(0)" -> Bidirectional	[label=assignedFrom];
	CuDNNGRU -> "keras.layers"	[label=importedBy];
	"CuDNNGRU(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"CuDNNGRU(0)" -> CuDNNGRU	[label=assignedFrom];
	GlobalAveragePooling1D -> "keras.layers"	[label=importedBy];
	"GlobalAveragePooling1D(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"GlobalAveragePooling1D(0)" -> GlobalAveragePooling1D	[label=assignedFrom];
	GlobalMaxPooling1D -> "keras.layers"	[label=importedBy];
	"GlobalMaxPooling1D(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"GlobalMaxPooling1D(0)" -> GlobalMaxPooling1D	[label=assignedFrom];
	concatenate -> "keras.layers"	[label=importedBy];
	"concatenate(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"concatenate(0)" -> concatenate	[label=assignedFrom];
	Input -> "keras.layers"	[label=importedBy];
	"Input(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"Input(0)" -> Input	[label=assignedFrom];
	Dropout -> "keras.layers"	[label=importedBy];
	"Dropout(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"Dropout(0)" -> Dropout	[label=assignedFrom];
	"keras.optimizers" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=importedBy];
	Adam -> "keras.optimizers"	[label=importedBy];
	"Adam(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"Adam(0)" -> Adam	[label=assignedFrom];
	"embedding_matrix(17)" -> "make_model[0]"	[label=_argToVar];
	"embed_size(17)" -> "make_model[1]"	[label=_argToVar];
	"loss(17)" -> "make_model[2]"	[label=_argToVar];
	"inp(17)$0" -> "max_len(17)"	[label=Input];
	"x(17)$0" -> "embed_size(17)"	[label=assignedFrom];
	"x(17)$0" -> "inp(17)$0"	[label=assignedFrom];
	"x(17)$0" -> "Embedding(17)"	[label=assignedFrom];
	"x(17)$0" -> "len_voc(17)"	[label=assignedFrom];
	"x(17)$0" -> "[<_ast.Name object at 0x7fd500824df0>](17)"	[label=assignedFrom];
	"x(17)$0" -> "False(17)"	[label=assignedFrom];
	"x(17)$1" -> "x(17)$1"	[label=assignedFrom];
	"x(17)$1" -> "Bidirectional(17)"	[label=assignedFrom];
	"x(17)$1" -> "CuDNNGRU(17)"	[label=assignedFrom];
	"x(17)$1" -> "128(17)"	[label=assignedFrom];
	"x(17)$1" -> "True(17)"	[label=assignedFrom];
	"x(17)$2" -> "Bidirectional(17)"	[label=assignedFrom];
	"x(17)$2" -> "CuDNNGRU(17)"	[label=assignedFrom];
	"x(17)$2" -> "True(17)"	[label=assignedFrom];
	"x(17)$2" -> "x(17)$2"	[label=assignedFrom];
	"x(17)$2" -> "64(17)"	[label=assignedFrom];
	"avg_pl(17)$0" -> "x(17)$2"	[label=assignedFrom];
	"avg_pl(17)$0" -> "GlobalAveragePooling1D(17)"	[label=assignedFrom];
	"max_pl(17)$0" -> "x(17)$2"	[label=assignedFrom];
	"max_pl(17)$0" -> "GlobalMaxPooling1D(17)"	[label=assignedFrom];
	"concat(17)$0" -> "[<_ast.Name object at 0x7fd500828850>, <_ast.Name object at 0x7fd500828880>](17)"	[label=concatenate];
	"dense(17)$0" -> "64(17)"	[label=assignedFrom];
	"dense(17)$0" -> "concat(17)$0"	[label=assignedFrom];
	"dense(17)$0" -> "Dense(17)"	[label=assignedFrom];
	"dense(17)$0" -> "relu(17)"	[label=assignedFrom];
	"drop(17)$0" -> "concat(17)$0"	[label=assignedFrom];
	"drop(17)$0" -> "Dropout(17)"	[label=assignedFrom];
	"drop(17)$0" -> "0.1(17)"	[label=assignedFrom];
	"output(17)$0" -> "concat(17)$0"	[label=assignedFrom];
	"output(17)$0" -> "Dense(17)"	[label=assignedFrom];
	"output(17)$0" -> "1(17)"	[label=assignedFrom];
	"output(17)$0" -> "sigmoid(17)"	[label=assignedFrom];
	"model(17)$0" -> "inp(17)$0"	[label=Model];
	"model(17)$0" -> "output(17)$0"	[label=Model];
	"model(17)$1" -> "model(17)$0"	[label=compile];
	"model(0)$0" -> "embedding(0)$0"	[label=make_model];
	"model_treated(0)$0" -> "embedding_treated(0)$0"	[label=make_model];
	"model(0)$1" -> "model(0)$0"	[label=summary];
	"keras.callbacks" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=importedBy];
	ModelCheckpoint -> "keras.callbacks"	[label=importedBy];
	"ModelCheckpoint(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"ModelCheckpoint(0)" -> ModelCheckpoint	[label=assignedFrom];
	ReduceLROnPlateau -> "keras.callbacks"	[label=importedBy];
	"ReduceLROnPlateau(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"ReduceLROnPlateau(0)" -> ReduceLROnPlateau	[label=assignedFrom];
	"weights.hdf5(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"checkpoints(0)$0" -> "weights.hdf5(0)"	[label=ModelCheckpoint];
	"checkpoints(0)$0" -> "val_f1(0)"	[label=ModelCheckpoint];
	"checkpoints(0)$0" -> "max(0)"	[label=ModelCheckpoint];
	"checkpoints(0)$0" -> "True(0)"	[label=ModelCheckpoint];
	"val_f1(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"max(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"True(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"reduce_lr(0)$0" -> "2(0)"	[label=ReduceLROnPlateau];
	"reduce_lr(0)$0" -> "0.1(0)"	[label=ReduceLROnPlateau];
	"reduce_lr(0)$0" -> "val_f1(0)"	[label=ReduceLROnPlateau];
	"reduce_lr(0)$0" -> "1(0)"	[label=ReduceLROnPlateau];
	"reduce_lr(0)$0" -> "1e-06(0)"	[label=ReduceLROnPlateau];
	"1(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"1e-06(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"treated_weights.hdf5(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"checkpoints_treated(0)$0" -> "val_f1(0)"	[label=ModelCheckpoint];
	"checkpoints_treated(0)$0" -> "max(0)"	[label=ModelCheckpoint];
	"checkpoints_treated(0)$0" -> "True(0)"	[label=ModelCheckpoint];
	"checkpoints_treated(0)$0" -> "treated_weights.hdf5(0)"	[label=ModelCheckpoint];
	"reduce_lr_treated(0)$0" -> "2(0)"	[label=ReduceLROnPlateau];
	"reduce_lr_treated(0)$0" -> "0.1(0)"	[label=ReduceLROnPlateau];
	"reduce_lr_treated(0)$0" -> "val_f1(0)"	[label=ReduceLROnPlateau];
	"reduce_lr_treated(0)$0" -> "1(0)"	[label=ReduceLROnPlateau];
	"reduce_lr_treated(0)$0" -> "1e-06(0)"	[label=ReduceLROnPlateau];
	"8(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"epochs(0)$0" -> "8(0)"	[label=assignedFrom];
	"512(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"batch_size(0)$0" -> "512(0)"	[label=assignedFrom];
	"history(0)$0" -> "X_train(0)$0"	[label=fit];
	"history(0)$0" -> "y_train(0)$0"	[label=fit];
	"history(0)$0" -> "model(0)$1"	[label=fit];
	"history(0)$0" -> "epochs(0)$0"	[label=fit];
	"history(0)$0" -> "batch_size(0)$0"	[label=fit];
	"history(0)$0" -> "[<_ast.Name object at 0x7fd500819a00>, <_ast.Name object at 0x7fd500819ac0>](0)"	[label=fit];
	"history(0)$0" -> "[<_ast.Name object at 0x7fd500819b80>, <_ast.Name object at 0x7fd500819be0>](0)"	[label=fit];
	"[<_ast.Name object at 0x7fd500819a00>, <_ast.Name object at 0x7fd500819ac0>](0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"[<_ast.Name object at 0x7fd500819b80>, <_ast.Name object at 0x7fd500819be0>](0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"plt(0)$0" -> "plt(0)"	[label=figure];
	"plt(0)$1" -> "history(0)$0"	[label=plot];
	"plt(0)$1" -> "plt(0)$0"	[label=plot];
	"plt(0)$1" -> "acc(0)"	[label=plot];
	"acc(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"plt(0)$2" -> "history(0)$0"	[label=plot];
	"plt(0)$2" -> "plt(0)$1"	[label=plot];
	"plt(0)$2" -> "val_acc(0)"	[label=plot];
	"val_acc(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"plt(0)$3" -> "plt(0)$2"	[label=show];
	"history(0)$1" -> "y_train(0)$0"	[label=fit];
	"history(0)$1" -> "X_t_train(0)$0"	[label=fit];
	"history(0)$1" -> "model_treated(0)$0"	[label=fit];
	"history(0)$1" -> "epochs(0)$0"	[label=fit];
	"history(0)$1" -> "batch_size(0)$0"	[label=fit];
	"history(0)$1" -> "[<_ast.Name object at 0x7fd50080f6a0>, <_ast.Name object at 0x7fd50080f6d0>](0)"	[label=fit];
	"history(0)$1" -> "[<_ast.Name object at 0x7fd50080f820>, <_ast.Name object at 0x7fd50080f850>](0)"	[label=fit];
	"[<_ast.Name object at 0x7fd50080f6a0>, <_ast.Name object at 0x7fd50080f6d0>](0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"[<_ast.Name object at 0x7fd50080f820>, <_ast.Name object at 0x7fd50080f850>](0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"plt(0)$4" -> "plt(0)$3"	[label=figure];
	"plt(0)$5" -> "acc(0)"	[label=plot];
	"plt(0)$5" -> "history(0)$1"	[label=plot];
	"plt(0)$5" -> "plt(0)$4"	[label=plot];
	"plt(0)$6" -> "val_acc(0)"	[label=plot];
	"plt(0)$6" -> "history(0)$1"	[label=plot];
	"plt(0)$6" -> "plt(0)$5"	[label=plot];
	"plt(0)$7" -> "plt(0)$6"	[label=show];
	"model(0)$2" -> "model(0)$1"	[label=load_weights];
	"model(0)$2" -> "weights.hdf5(0)"	[label=load_weights];
	"model_treated(0)$1" -> "model_treated(0)$0"	[label=load_weights];
	"model_treated(0)$1" -> "treated_weights.hdf5(0)"	[label=load_weights];
	"pred_val(0)$0" -> "X_val(0)$0"	[label=predict];
	"pred_val(0)$0" -> "1(0)"	[label=predict];
	"pred_val(0)$0" -> "512(0)"	[label=predict];
	"pred_val(0)$0" -> "model(0)$2"	[label=predict];
	"pred_t_val(0)$0" -> "X_t_val(0)$0"	[label=predict];
	"pred_t_val(0)$0" -> "1(0)"	[label=predict];
	"pred_t_val(0)$0" -> "512(0)"	[label=predict];
	"pred_t_val(0)$0" -> "model_treated(0)$1"	[label=predict];
	"sklearn.metrics" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=importedBy];
	f1_score -> "sklearn.metrics"	[label=importedBy];
	"f1_score(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"f1_score(0)" -> f1_score	[label=assignedFrom];
	"pred(18)" -> "tweak_threshold[0]"	[label=_argToVar];
	"truth(18)" -> "tweak_threshold[1]"	[label=_argToVar];
	"thresholds(18)$0" -> "[](18)"	[label=assignedFrom];
	"scores(18)$0" -> "[](18)"	[label=assignedFrom];
	"thresh(18)" -> "np(18)"	[label=iteratorOf];
	"thresh(18)" -> "0.1(18)"	[label=iteratorOf];
	"thresh(18)" -> "0.501(18)"	[label=iteratorOf];
	"thresh(18)" -> "0.01(18)"	[label=iteratorOf];
	"thresh(18)$0" -> "np(18)"	[label=round];
	"thresh(18)$0" -> "thresh(18)$0"	[label=round];
	"thresh(18)$0" -> "2(18)"	[label=round];
	"thresholds(18)$1" -> "thresholds(18)$0"	[label=append];
	"thresholds(18)$1" -> "thresh(18)$0"	[label=append];
	"score(18)$0" -> "pred(18)"	[label=f1_score];
	"score(18)$0" -> "truth(18)"	[label=f1_score];
	"score(18)$0" -> "thresh(18)$0"	[label=f1_score];
	"score(18)$0" -> "int(18)"	[label=f1_score];
	"scores(18)$1" -> "scores(18)$0"	[label=append];
	"scores(18)$1" -> "score(18)$0"	[label=append];
	"score_val(0)$0" -> "y_val(0)$0"	[label=tweak_threshold];
	"score_val(0)$0" -> "pred_val(0)$0"	[label=tweak_threshold];
	"threshold_val(0)$0" -> "y_val(0)$0"	[label=tweak_threshold];
	"threshold_val(0)$0" -> "pred_val(0)$0"	[label=tweak_threshold];
	"Scored (0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"print[259/0]" -> "score_val(0)$0"	[label=print];
	"print[259/0]" -> "threshold_val(0)$0"	[label=print];
	"print[259/0]" -> "Scored (0)"	[label=print];
	"print[259/0]" -> "round(0)"	[label=print];
	"print[259/0]" -> "4(0)"	[label=print];
	"print[259/0]" -> " for threshold (0)"	[label=print];
	"print[259/0]" -> " with untreated texts on validation data(0)"	[label=print];
	"round(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"4(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	" for threshold (0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	" with untreated texts on validation data(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
	"score_t_val(0)$0" -> "y_val(0)$0"	[label=tweak_threshold];
	"score_t_val(0)$0" -> "pred_t_val(0)$0"	[label=tweak_threshold];
	"threshold_t_val(0)$0" -> "y_val(0)$0"	[label=tweak_threshold];
	"threshold_t_val(0)$0" -> "pred_t_val(0)$0"	[label=tweak_threshold];
	"print[262/0]" -> "Scored (0)"	[label=print];
	"print[262/0]" -> "round(0)"	[label=print];
	"print[262/0]" -> "4(0)"	[label=print];
	"print[262/0]" -> " for threshold (0)"	[label=print];
	"print[262/0]" -> "score_t_val(0)$0"	[label=print];
	"print[262/0]" -> "threshold_t_val(0)$0"	[label=print];
	"print[262/0]" -> " with treated texts on validation data(0)"	[label=print];
	" with treated texts on validation data(0)" -> "improve-your-score-with-text-preprocessing-v2.ipynb"	[label=appearsIn];
}
